{"file_name": "/home/qj213/afp-2021-10-22/thys/PLM/Thesis.thy", "working_directory": "/home/qj213/afp-2021-10-22/thys/PLM", "problem_names": ["lemma embedded_meta_def: \"(A \\<equiv> B) \\<Longrightarrow> (embedded_style A) = B\"", "lemma embedded_meta_eq: \"(A = B) \\<Longrightarrow> (embedded_style A) = B\"", "lemma embedded_def: \"(A \\<equiv> B) \\<Longrightarrow> (embedded_style A) = (embedded_style B)\"", "lemma embedded_eq: \"(A = B) \\<Longrightarrow> (embedded_style A) = (embedded_style B)\"", "lemma expand_def1: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x . p x = q x)\"", "lemma expand_def2: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x y . p x y = q x y)\"", "lemma expand_def3: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x y z . p x y z = q x y z)\"", "lemma \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow> ((\\<^bold>\\<not>\\<^bold>\\<box>\\<phi>) \\<^bold>\\<equiv> (\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>))) in v]\"", "lemma \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow> ((\\<^bold>\\<not>\\<^bold>\\<box>\\<phi>) \\<^bold>\\<equiv> (\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>))) in v]\""], "translations": [["", "lemma embedded_meta_def: \"(A \\<equiv> B) \\<Longrightarrow> (embedded_style A) = B\""], ["proof (prove)\ngoal (1 subgoal):\n 1. A \\<equiv> B \\<Longrightarrow> embedded_style A = B", "unfolding embedded_style_def"], ["proof (prove)\ngoal (1 subgoal):\n 1. A \\<equiv> B \\<Longrightarrow> id B = B", "by auto"], ["", "lemma embedded_meta_eq: \"(A = B) \\<Longrightarrow> (embedded_style A) = B\""], ["proof (prove)\ngoal (1 subgoal):\n 1. A = B \\<Longrightarrow> embedded_style A = B", "unfolding embedded_style_def"], ["proof (prove)\ngoal (1 subgoal):\n 1. A = B \\<Longrightarrow> id A = B", "by auto"], ["", "lemma embedded_def: \"(A \\<equiv> B) \\<Longrightarrow> (embedded_style A) = (embedded_style B)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. A \\<equiv> B \\<Longrightarrow> embedded_style A = embedded_style B", "unfolding embedded_style_def"], ["proof (prove)\ngoal (1 subgoal):\n 1. A \\<equiv> B \\<Longrightarrow> id B = id B", "by auto"], ["", "lemma embedded_eq: \"(A = B) \\<Longrightarrow> (embedded_style A) = (embedded_style B)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. A = B \\<Longrightarrow> embedded_style A = embedded_style B", "unfolding embedded_style_def"], ["proof (prove)\ngoal (1 subgoal):\n 1. A = B \\<Longrightarrow> id A = id B", "by auto"], ["", "notation (latex output)\n  embedded_style (\"\\<^latex>\\<open>\\\\embeddedstyle{\\<close>_\\<^latex>\\<open>}\\<close>\")"], ["", "translations\n  \"x\" <= \"CONST make\\<kappa> x\""], ["", "translations\n  \"p\" <= \"CONST make\\<o> p\""], ["", "translations\n  \"p\" <= \"CONST make\\<Pi>\\<^sub>1 p\""], ["", "translations\n  \"p\" <= \"CONST make\\<Pi>\\<^sub>2 p\""], ["", "translations\n  \"p\" <= \"CONST make\\<Pi>\\<^sub>3 p\""], ["", "translations\n  \"x\" <= \"CONST eval\\<kappa> x\""], ["", "translations\n  \"p\" <= \"CONST eval\\<o> p\""], ["", "translations\n  \"p\" <= \"CONST eval\\<Pi>\\<^sub>1 p\""], ["", "translations\n  \"p\" <= \"CONST eval\\<Pi>\\<^sub>2 p\""], ["", "translations\n  \"p\" <= \"CONST eval\\<Pi>\\<^sub>3 p\""], ["", "notation (latex output)\n  that (\"\\<^bold>\\<iota>x . _ x\")"], ["", "notation (latex output)\n  forall\\<^sub>\\<nu> (\"\\<^bold>\\<forall>\\<^sub>\\<nu> x . _ x\")"], ["", "notation (latex output)\n  forall\\<^sub>0 (\"\\<^bold>\\<forall>\\<^sub>0 p . _ p\")"], ["", "notation (latex output)\n  forall\\<^sub>1 (\"\\<^bold>\\<forall>\\<^sub>1 F . _ F\")"], ["", "notation (latex output)\n  forall\\<^sub>2 (\"\\<^bold>\\<forall>\\<^sub>2 F . _ F\")"], ["", "notation (latex output)\n  forall\\<^sub>3 (\"\\<^bold>\\<forall>\\<^sub>3 F . _ F\")"], ["", "notation (latex output)\n  forall (\"\\<^bold>\\<forall> \\<alpha> . _ \\<alpha>\")"], ["", "notation (latex output)\n  exists (\"\\<^bold>\\<exists> \\<alpha> . _ \\<alpha>\")"], ["", "notation (latex output)\n  exists_unique (\"\\<^bold>\\<exists>! \\<alpha> . _ \\<alpha>\")"], ["", "notation (latex output)\n  lambdabinder1 (\"\\<^bold>\\<lambda>x. _ x\")"], ["", "translations\n  (type) \"\\<alpha>\" <= (type) \"\\<Pi>\\<^sub>1 set\""], ["", "(* auxiliary lemmata and attributes to aid in pretty printing *)"], ["", "lemma expand_def1: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x . p x = q x)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. p \\<equiv> q \\<Longrightarrow> (\\<And>x. p x = q x)", "by simp"], ["", "lemma expand_def2: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x y . p x y = q x y)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. p \\<equiv> q \\<Longrightarrow> (\\<And>x y. p x y = q x y)", "by simp"], ["", "lemma expand_def3: \"p \\<equiv> q \\<Longrightarrow> (\\<And>x y z . p x y z = q x y z)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. p \\<equiv> q \\<Longrightarrow> (\\<And>x y z. p x y z = q x y z)", "by simp"], ["", "attribute_setup expand1 = \\<open>\n  Scan.succeed (Thm.rule_attribute [] \n    (fn _ => fn thm => thm RS @{thm expand_def1}))\n\\<close>"], ["", "attribute_setup expand2 = \\<open>\n  Scan.succeed (Thm.rule_attribute [] \n    (fn _ => fn thm => thm RS @{thm expand_def2}))\n\\<close>"], ["", "attribute_setup expand3 = \\<open>\n  Scan.succeed (Thm.rule_attribute [] \n    (fn _ => fn thm => thm RS @{thm expand_def3}))\n\\<close>"], ["", "no_syntax \"_list\" :: \"args \\<Rightarrow> 'a list\" (\"[(_)]\")"], ["", "no_syntax \"__listcompr\" :: \"args \\<Rightarrow> 'a list\" (\"[(_)]\")"], ["", "(*>*)\n  \n(* abstract in thesis/root.tex *)"], ["", "chapter\\<open>Introduction\\<close>"], ["", "text\\<open>\n\\epigraph{Calculemus!}{\\textit{Leibniz}}\n\\<close>"], ["", "section\\<open>Universal Logical Reasoning\\footnote{This introductory section is based on the description of the topic in @{cite UniversalReasoning}.}\\<close>"], ["", "text\\<open>\n\nThe concept of understanding rational argumentation and reasoning using formal logical systems\nhas a long tradition and can already be found in the study of syllogistic arguments by\nAristotle. Since then a large variety of formal systems has evolved, each using different syntactical\nand semantical structures to capture specific aspects of logical reasoning (e.g. propositional logic,\nfirst-order/higher-order logic, modal logic, free logic, etc.). This diversity of formal systems\ngives rise to the question, whether a \\emph{universal} logic can be devised, that would be capable\nof expressing statements of all existing specialized logical systems and provide a basis for\nmeta-logical considerations like the equivalence of or relations between those systems.\n\nThe idea of a universal logical framework is very prominent in the works of Gottfried Wilhelm Leibniz\n(1646-1716) with his concept of a \\emph{characteristica universalis}, i.e. a universal formal language\nable to express metaphysical, scientific and mathematical concepts. Based thereupon he envisioned \nthe \\emph{calculus ratiocinator}, a universal logical calculus with which the truth of statements\nformulated in the characteristica universalis could be decided purely by formal calculation and thereby\nin an automated fashion, an idea that became famous under the slogan: \\emph{Calculemus!}\n\nNowadays with the rise of powerful computer systems such a universal logical framework could have\nrepercussions throughout the sciences and may be a vital part of human-machine interaction in the\nfuture. Leibniz' ideas have inspired recent efforts to use functional higher-order logic (HOL) as\nsuch a universal logical language and to represent various logical systems by the use of\n\\emph{shallow semantical embeddings}@{cite UniversalReasoning}.\n\nNotably this approach received attention due to the formalization, validation and analysis\nof G\\\"odel's ontological proof of the existence of God by Christoph Benzm\\\"uller@{cite GoedelGod},\nfor which higher-order modal logic was embedded in the computerized logic framework Isabelle/HOL.\n\\<close>"], ["", "section\\<open>Shallow Semantical Embeddings in HOL\\<close>"], ["", "text\\<open>\nA semantic embedding of a target logical system defines the syntactic elements of the target language\nin a background logic (e.g. in a framework like Isabelle/HOL) based on their semantics.\nThis way the background logic can be used as meta-logic to argue about the semantic truth of syntactic statements\nin the embedded logic.\n\nA \\emph{deep} embedding represents the complete syntactic structure of the target language\nseparately from the background logic, i.e. every term, variable symbol, connective, etc. of the\ntarget language is represented as a syntactic object and then the background logic is used to\nevaluate a syntactic expression by quantifying over all models that can be associated with the\nsyntax. Variable symbols of the target logic for instance would be represented as constants in\nthe background logic and a proposition would be considered semantically valid if it holds for\nall possible denotations an interpretation function can assign to them.\n\nWhile this approach will work for most target logics, it has several drawbacks. It is likely that there are\nprinciples that are shared between the target logic and the background logic, such as \\<open>\\<alpha>\\<close>-conversion\nfor \\<open>\\<lambda>\\<close>-expressions or the equivalence of terms with renamed variables in general. In a deep\nembedding these principles usually have to be explicitly shown to hold for the syntactic representation\nof the target logic, which is usually connected with significant complexity. Furthermore if the\nframework used for the background logic allows automated reasoning, the degree of automation that\ncan be achieved in the embedded logic is limited, as any reasoning in the target logic will have\nto consider the meta-logical evaluation process in the background logic which will usually be complex.\n\nA \\emph{shallow} embedding uses a different approach based on the idea that most contemporary\nlogical systems are semantically characterized by the means of set theory. A shallow embedding\ndefines primitive syntactic objects of the target language such as variables or propositions\nusing a set theoretic representation. For example propositions in a modal logic can be represented\nas functions from possible worlds to truth values in a non-modal logic.\n\nThe shallow embedding aims to equationally define only the syntactic elements of the target logic\nthat are not already present in the background logic or whose semantics behaves differently than in\nthe background logic, while preserving as much of the logical structure of the background logic\nas possible. The modal box operator for example can be represented as a quantification over all\npossible worlds, satisfying an accessibility relation, while negation and quantification can be\ndirectly represented using the negation and quantification of the background logic (preserving\nthe dependency on possible worlds).\n\nThis way basic principles of the background logic (such as alpha conversion) can often be directly\napplied to the embedded logic and the equational, definitional nature of the representation preserves\na larger degree of automation. Furthermore, axioms in the embedded logic can often be equivalently\nstated in the background logic, which makes the construction of models for the system easier and again increases\nthe degree of automation that can be retained.\n\nThe shallow semantical embedding of modal logic was the basis for the analysis of\nG\\\"odel's ontological argument@{cite GoedelGod} and the general concept has shown great potential as a universal\ntool for logical embeddings while retaining the existing infrastructure for automation as for\nexample present in a framework like Isabelle/HOL\\footnote{See @{cite UniversalReasoning} for an\noverview and an description of the ambitions of the approach.}.\n\n\\<close>"], ["", "(* TODO: no new section? *)"], ["", "section\\<open>Relational Type Theory vs. Functional Type Theory\\<close>"], ["", "text\\<open>\nThe universality of this approach has since been challenged by Paul Oppenheimer and Edward Zalta\nwho argue in the paper \\emph{Relations Versus Functions at the Foundations of Logic: Type-Theoretic\nConsiderations}@{cite rtt} that relational type theory is more general than functional type theory.\nIn particular they argue that the Theory of Abstract Objects, which is founded in relational type\ntheory, cannot be properly characterized in functional type theory.\n\nThis has led to the question whether a shallow semantical embedding of the Theory of Abstract Objects\nin a functional logic framework like Isabelle/HOL is at all possible, which is the core question\nthe work presented here attempts to examine and partially answer.\n\nOne of their main arguments is that unrestricted \\<open>\\<lambda>\\<close>-expressions as present in functional type\ntheory lead to an inconsistency when combined with one of the axioms of the theory and indeed it\nhas been shown for early attempts on embedding the theory that despite significant efforts\nto avoid the aforementioned inconsistency by excluding problematic \\<open>\\<lambda>\\<close>-expressions in the embedded\nlogic, it could still be reproduced using an appropriate construction in the background logic\\footnote{\nEarly attempts of an embedding by Christoph Benzm\\\"uller (see \\url{https://github.com/cbenzmueller/PrincipiaMetaphysica})\nwere discussed in his university lecture \\emph{Computational Metaphysics} (FU Berlin, SS2016) and the proof of\ntheir inconsistency in the author's final project for the course inspired the continued research\nin this master's thesis.}.\n\nThe solution presented here circumvents this problem by identifying \\<open>\\<lambda>\\<close>-expressions as one element of the\ntarget language that behaves differently than their counterparts in the background logic and\nconsequently by representing \\<open>\\<lambda>\\<close>-expressions of the target logic using a new \\emph{defined}\nkind of \\<open>\\<lambda>\\<close>-expressions. This forces \\<open>\\<lambda>\\<close>-expressions in the embedded logic to have a particular\nsemantics that is inspired by the \\emph{Aczel-model} of the target theory (see \\ref{aczel-model})\nand avoids prior inconsistencies. The mentioned issue and the employed solution is discussed in\nmore detail in sections~\\ref{russell-paradox} and~\\ref{lambda-expressions}.\n\n\\pagebreak\n\\<close>"], ["", "section\\<open>Overview of the following Chapters\\<close>"], ["", "text\\<open>\n  The following chapters are structured as follows:\n  \\begin{itemize}\n    \\item The second chapter gives an overview of the motivation and structure of\n          the target theory of the embedding, the Theory of Abstract Objects. It also\n          introduces the \\emph{Aczel-model} of the theory, that was adapted as the basis\n          for the embedding.\n  \n    \\item The third chapter is a detailed documentation of the concepts and\n          technical structure of the embedding. This chapter references the\n          Isabelle theory that can be found in the appendix.\n  \n    \\item The fourth chapter consists of a technical discussion about some of the issues encountered\n          during the construction of the embedding due to limitations of the logic framework\n          Isabelle/HOL and the solutions that were employed.\n  \n    \\item The last chapter discusses the relation between the embedding and the target theory\n          of PLM and describes some of the results achieved using the embedding. Furthermore it\n          states some open questions for future research.\n  \\end{itemize}\n\n  This entire document is generated from an Isabelle theory file and thereby in particular\n  all formal statements in the third chapter are well-formed terms, resp. verified valid theorems\n  in the constructed embedding unless the contrary is stated explicitly.\n\\<close>"], ["", "chapter\\<open>The Theory of Abstract Objects\\<close>"], ["", "text\\<open>\n  \\epigraph{\nIt is widely supposed that every entity falls into one of two categories:\nSome are concrete; the rest abstract. The distinction is supposed to be\nof fundamental significance for metaphysics and epistemology.\n}{\\textit{Stanford Encyclopedia of Philosophy\\cite{sep-abstract-objects}}}\n\\<close>"], ["", "section\\<open>Motivation\\<close>"], ["", "text\\<open>\n\nAs the name suggests the Theory of Abstract Objects revolves around \\emph{abstract objects} and\nis thereby a metaphysical theory.\nAs Zalta puts it: \\textquote{Whereas physics attempts a systematic description of fundamental\nand complex concrete objects, metaphysics attempts a systematic description of fundamental\nand complex abstract objects. \\textelp{} The theory of abstract objects attempts to organize\nthese objects within a systematic and axiomatic framework. \\textelp{We can} think of abstract\nobjects as possible and actual property-patterns. \\textelp{} Our theory of abstract\nobjects will \\emph{objectify} or \\emph{reify} the group of properties satisfying \\textins{such a}\npattern.}\\cite{MallyTheory}\\footnote{The introduction to the theory\nin this and the next section is based on the documentation of the theory in @{cite MallyTheory} and @{cite MallyDistinction}, which\nis paraphrased and summarized throughout the sections. Further references about the topic include @{cite PM},\n@{cite zalta1988intensional}, @{cite zalta1983abstract}.}\n\nSo what is the fundamental distinction between abstract and concrete objects? The analysis\nin the Theory of Abstract Objects is based on a distinction between two fundamental modes of\npredication that is based on the ideas of Ernst Mally.\nWhereas objects that are concrete (the Theory of Abstract Objects calls them \\emph{ordinary objects})\nare characterized by the classical mode of predication, i.e. \\emph{exemplification},\na second mode of predication is introduced that is reserved for abstract objects. This new mode of\npredication is called \\emph{encoding} and formally written as \\<open>xF\\<close> (\\<open>x\\<close>\n\\emph{encodes} \\<open>F\\<close>) in contrast to \\<open>Fx\\<close> (\\<open>x\\<close> \\emph{exemplifies} \\<open>F\\<close>).\n\nMally informally introduces this second mode of predication in order to represent sentences about\nfictional objects. In his thinking, concrete objects, that for example have a fixed spatiotemporal\nlocation, a body and shape, etc., only \\emph{exemplify} their properties and are characterized\nby the properties they exemplify. Sentences about fictional objects such as \\textquote{Sherlock Holmes\nis a detective} have a different meaning. Stating that \\textquote{Sherlock Holmes is a detective} \ndoes not imply that there is some concrete object that is Sherlock Holmes and this object exemplifies\nthe property of being a detective - it rather states that the concept we have of the fictional\ncharacter Sherlock Holmes includes the property of being a detective. Sherlock Holmes is not concrete,\nbut an abstract object that is \\emph{determined} by the properties Sherlock Holmes is given by the\nfictional works involving him as character. This is expressed using the second mode of predication\n\\emph{Sherlock Holmes encodes the property of being a detective}.\n\nTo clarify the difference between the two concepts note that any object either exemplifies a property\nor its negation. The same is not true for encoding. For example it is not determinate whether \nSherlock Holmes has a mole on his left foot. Therefore the abstract object Sherlock Holmes neither\nencodes the property of having a mole on his left foot, nor the property of not having a mole on\nhis left foot\\footnote{see @{cite MallyDistinction}}.\n\nThe theory even allows for an abstract object to encode properties that no object\ncould possibly exemplify and reason about them, for example the quadratic circle. In classical logic\nmeaningful reasoning about a quadratic circle is impossible - as soon as I suppose that an object\n\\emph{exemplifies} the properties of being a circle and of being quadratic, this will lead to a\ncontradiction and every statement becomes derivable.\n\nIn the Theory of Abstract Objects on the other hand\nthere is an abstract object that encodes exactly these two properties and it is possible to reason\nabout it. For example we can state that this object \\emph{exemplifies} the property of \\emph{being\nthought about by the reader of this paragraph}. This shows that the Theory of Abstract Objects provides\nthe means to reason about processes of human thought in a much broader sense than classical logic\nwould allow.\n\nIt turns out that by the means of abstract objects and encoding  the Theory of Abstract Objects\n  can be used to represent and reason about a large variety of concepts that\nregularly occur in philosophy, mathematics or linguistics.\n\nIn \\cite{MallyTheory} the principal objectives of the theory are summarized as follows:\n\\begin{itemize}\n  \\item To describe the logic underlying (scientific) thought and reasoning by extending\n        classical propositional, predicate, and modal logic.\n  \\item To describe the laws governing universal entities such as properties, relations,\n        and propositions (i.e., states of affairs).\n  \\item To identify \\emph{theoretical} mathematical objects and relations as well as\n        the \\emph{natural} mathematical objects such as natural numbers and natural sets.\n  \\item To analyze the distinction between fact and fiction and systematize the various\n        relationships between stories, characters, and other fictional objects.\n  \\item To systematize our modal thoughts about possible (actual, necessary) objects,\n        states of affairs, situations and worlds.\n  \\item To account for the deviant logic of propositional attitude reports, explain the\n        informativeness of identity statements, and give a general account of the objective\n        and cognitive content of natural language.\n  \\item To axiomatize philosophical objects postulated by other philosophers, such as Forms (Plato),\n        concepts (Leibniz), monads (Leibniz), possible worlds (Leibniz), nonexistent objects (Meinong),\n        senses (Frege), extensions of concepts (Frege), noematic senses (Husserl), the world as a\n        state of affairs (early Wittgenstein), moments of time, etc.\n\\end{itemize}\n\nThe Theory of Abstract Objects has therefore the ambition and the potential to serve as a foundational\ntheory of metaphysics as well as mathematics and can provide a simple unified axiomatic framework that\nallows reasoning about a huge variety of concepts throughout the sciences. This makes the attempt to represent the\ntheory using the universal reasoning approach of shallow semantical embeddings outlined in the previous\nchapter particularly challenging and at the same time rewarding, if successful.\n\nA successful implementation of\nthe theory which allows to utilize the existing sophisticated infrastructure for automated reasoning \npresent in a framework like Isabelle/HOL would not only strongly support the applicability of shallow\nsemantical embeddings as a universal reasoning tool, but could also aid in spreading\nthe utilization of the theory itself as a foundational theory for various scientific fields by\nenabling convenient interactive and automated reasoning in a verified framework.\n\n\\<close>"], ["", "section\\<open>Basic Principles\\<close>"], ["", "text\\<open>\n  Although the formal language of the theory is introduced in the next section,\n  some of the basic concepts of the theory are presented in advance to provide\n  further motivation for the formalism.\n\n  The following are the two most important principles of the theory (see~@{cite MallyTheory}):\n\n  \\begin{itemize}\n    \\item \\<open>\\<exists>x(A!x & \\<forall>F(xF \\<equiv> \\<phi>))\\<close>\n    \\item \\<open>x = y \\<equiv> \\<box>\\<forall>F(xF \\<equiv> yF)\\<close>\n  \\end{itemize}\n\n  The first statement asserts that for every condition on properties \\<open>\\<phi>\\<close> there exists\n  an abstract object that encodes exactly those properties satisfying \\<open>\\<phi>\\<close>, whereas the\n  second statement holds for two abstract objects \\<open>x\\<close> and \\<open>y\\<close> and states that\n  they are equal, if and only if they necessarily encode the same properties.\n\n  Together these two principles clarify the notion of abstract objects as the reification\n  of property patterns: Any set of properties is objectified as a distinct abstract object.\n\n  Using these principles it is already possible to postulate interesting abstract objects.\n\n  For example the Leibnizian concept of an (ordinary) individual \\<open>u\\<close> can be \n  defined as \\emph{the (unique) abstract object that encodes all properties that \\<open>u\\<close> exemplifies},\n  formally: \\mbox{\\<open>\\<iota>x A!x & \\<forall>F (xF \\<equiv> Fu)\\<close>}\n  \n  Other interesting examples include possible worlds, Platonic Forms or even basic logical objects\n  like truth values. The theory allows to formulate purely \\emph{syntactic} definitions of\n  objects like possible worlds and truth values and\n  from these definitions it can be \\emph{derived} that there are two truth values\n  or that the application of the modal box operator to a proposition is equivalent to the proposition\n  being true in all possible worlds (where \\emph{being true in a possible world} is again defined\n  syntactically).\n\n  This is an impressive property of the Theory of Abstract Objects: it can \\emph{syntactically}\n  define objects that are usually only considered semantically.\n\\<close>"], ["", "section\\<open>The Language of PLM\\<close>"], ["", "text\\<open>\nThe target of the embedding is the second-order fragment of object theory as described\nin chapter 7 of Edward Zalta's upcoming \\emph{Principia Logico-Metaphysica} (PLM)@{cite PM}.\nThe logical foundation of the theory uses a second-order modal logic (without primitive identity)\nformulated using relational type theory that is modified to admit \\emph{encoding} as a second mode\nof predication besides the traditional \\emph{exemplification}.\nIn the following an informal description of the important aspects of the language is provided;\nfor a detailed and fully formal description and the type-theoretic background refer to the respective\nchapters of PLM@{cite PM}.\n\nA compact description of the language can be given in Backus-Naur Form (BNF)\\mbox{@{cite \\<open>Definition (6)\\<close> PM}},\nas shown in figure~\\ref{BNF}, in which the following grammatical categories are used:\n\n\\begin{tabular}[h]{ll}\n  \\<open>\\<delta>\\<close>   & individual constants \\\\\n  \\<open>\\<nu>\\<close>   & individual variables \\\\\n  \\<open>\\<Sigma>\\<^sup>n\\<close>  & $n$-place relation constants ($n \\geq 0$) \\\\\n  \\<open>\\<Omega>\\<^sup>n\\<close>  & $n$-place relation variables ($n \\geq 0$) \\\\\n  \\<open>\\<alpha>\\<close>   & variables \\\\\n  \\<open>\\<kappa>\\<close>   & individual terms \\\\\n  \\<open>\\<Pi>\\<^sup>n\\<close>  & $n$-place relation terms ($n \\geq 0$) \\\\\n  \\<open>\\<Phi>\\<^sup>*\\<close>  & propositional formulas \\\\\n  \\<open>\\<Phi>\\<close>   & formulas \\\\\n  \\<open>\\<tau>\\<close>   & terms\n\\end{tabular}\n\n\\begin{figure}[!h]\n  \\caption{BNF grammar of the language of PLM\\cite[p. 170]{PM}}\n  \\centering\n  \\includegraphics{BNF.pdf}\n  \\label{BNF}\n\\end{figure}\n\nThe language distinguishes between two types of basic formulas,\nnamely (non-propositional) \\emph{formulas} that \\emph{may} contain encoding subformulas and\n\\emph{propositional formulas} that \\emph{may not} contain encoding subformulas. Only propositional\nformulas may be used in \\<open>\\<lambda>\\<close>-expressions. The main reason for this distinction will be explained\nin section~\\ref{russell-paradox}.\n\nNote that there is a case in which propositional formulas \\emph{can} contain encoding\nexpressions. This is due to the fact that \\emph{subformula} is defined in such a\nway that \\<open>xQ\\<close> is \\emph{not} a subformula of \\<open>\\<iota>x(xQ)\\<close>\\footnote{For\na formal definition of subformula refer to definition (\\ref{PM-df-subformula}) in @{cite PM}.}.\nThereby \\<open>F\\<iota>x(xQ)\\<close> is a propositional formula and \\<open>[\\<lambda>y F\\<iota>x(xQ)]\\<close> a well-formed\n\\<open>\\<lambda>\\<close>-expression. On the other hand \\<open>xF\\<close> is not a propositional formula and therefore\n\\<open>[\\<lambda>x xF]\\<close> not a well-formed \\<open>\\<lambda>\\<close>-expression. This fact will become relevant in\nthe discussion in section~\\ref{paradox}, that describes a paradox in the formulation of\nthe theory in the draft of PLM at the time of writing\\footnote{At the time of writing several\noptions are being considered that can restore the consistency of the theory while retaining all\ntheorems of PLM.}.\n\nFurthermore the theory contains a designated relation constant \\<open>E!\\<close> to be read as\n\\emph{being concrete}. Using this constant the distinction between ordinary and abstract objects\nis defined as follows:\n\n  \\begin{itemize}\n    \\item \\<open>O! =\\<^sub>d\\<^sub>f [\\<lambda>x \\<^bold>\\<diamond>E!x]\\<close>\n    \\item \\<open>A! =\\<^sub>d\\<^sub>f [\\<lambda>x \\<^bold>\\<not>\\<^bold>\\<diamond>E!x]\\<close>\n  \\end{itemize}\n\nSo ordinary objects are possibly concrete, whereas abstract objects cannot possibly be concrete.\n\nThe language does not contain a primitive identity, but\n\\emph{defines} an identity for each type of term as follows:\n\n\\begin{tabular}{lc}\n  ordinary objects & \\<open>x =\\<^sub>E y =\\<^sub>d\\<^sub>f O!x & O!y & \\<box>(\\<forall>F Fx \\<equiv> Fy)\\<close>\\\\\n  individuals & \\<open>x = y =\\<^sub>d\\<^sub>f x =\\<^sub>E y \\<or> (A!x & A!y & \\<box>(\\<forall>F xF \\<equiv> yF))\\<close>\\\\\n  one-place relations & \\<open>F\\<^sup>1 = G\\<^sup>1 =\\<^sub>d\\<^sub>f \\<box>(\\<forall>x xF\\<^sup>1 \\<equiv> xG\\<^sup>1)\\<close>\\\\\n  zero-place relations & \\<open>F\\<^sup>0 = G\\<^sup>0 =\\<^sub>d\\<^sub>f [\\<lambda>y F\\<^sup>0] = [\\<lambda>y G\\<^sup>0]\\<close>\n\\end{tabular}\n\nThe identity for \\<open>n\\<close>-place relations for \\<open>n \\<ge> 2\\<close> is defined in terms of the\nidentity of one-place relations, see (\\ref{PM-p-identity})@{cite PM} for the full details.\n\nThe identity for ordinary objects follows Leibniz' law of the identity of indiscernibles:\nTwo ordinary objects that necessarily exemplify the same properties are identical.\nAbstract objects, however, are only identical if they necessarily \\emph{encode} the same\nproperties. As mentioned in the previous section this goes along with the concept of\nabstract objects as the reification of property patterns.\n\nNotably the identity for properties has a different definition than one would expect from\nclassical logic. Classically two properties are considered identical if and only if they\nnecessarily are \\emph{exemplified} by the same objects. The Theory of Abstract Objects, however,\ndefines two properties to be identical if and only if they are necessarily \\emph{encoded} by\nthe same (abstract) objects. This has some interesting consequences that will be described\nin more detail in section \\ref{hyperintensionality} which describes the \\emph{hyperintensionality}\nof relations in the theory.\n\\<close>"], ["", "section\\<open>The Axioms\\<close>"], ["", "text\\<open>\n\nBased on the language above, an axiom system is defined that constructs a S5 modal logic with\nan actuality operator, axioms for definite descriptions that go along with Russell's analysis\nof descriptions, the substitution of identicals as per the defined identity, \\<open>\\<alpha>\\<close>-,\n\\<open>\\<beta>\\<close>-, \\<open>\\<eta>\\<close>- and a special \\<open>\\<iota>\\<close>-conversion for \\<open>\\<lambda>\\<close>-expressions, as well\nas dedicated axioms for encoding. A full accounting of the axioms in their representation in the\nembedding is found in section~\\ref{axioms}. For the original axioms refer to @{cite \\<open>Chap. 8\\<close> PM}.\nAt this point the axioms of encoding are the most relevant, namely:\n\n  \\begin{itemize}\n    \\item \\<open>xF \\<rightarrow> \\<box>xF\\<close>\n    \\item \\<open>O!x \\<rightarrow> \\<not>\\<exists>F xF\\<close>\n    \\item \\<open>\\<exists>x (A!x & \\<forall>F (xF \\<equiv> \\<phi>))\\<close>,\\\\ provided x doesn't occur free in \\<open>\\<phi>\\<close>\n  \\end{itemize}\n\nSo encoding is modally rigid, ordinary objects do not encode properties and\nmost importantly the comprehension axiom for abstract objects that was already mentioned above:\n\nFor every condition on properties \\<open>\\<phi>\\<close> there exists an abstract object, that encodes exactly\nthose properties, that satisfy \\<open>\\<phi>\\<close>.\n\n\\<close>"], ["", "section\\<open>Hyperintensionality of Relations\\<close>"], ["", "text\\<open>\n\n\\label{hyperintensionality}\n\nAn interesting property of the Theory of Abstract Objects results from the definition\nof identity for one-place relations. Recall that two properties are defined to be identical\nif and only if they are \\emph{encoded} by the same (abstract) objects. The theory imposes no\nrestrictions whatsoever on which properties an abstract object encodes.\nLet for example \\<open>F\\<close> be the property \\emph{being the morning star} and \\<open>G\\<close> be the\nproperty \\emph{being the evening star}. Since the morning star and the evening star are\nactually both the planet Venus, every object that \\emph{exemplifies} \\<open>F\\<close> will also\n\\emph{exemplify} \\<open>G\\<close> and vice-versa: \\<open>\\<box>\\<forall>x Fx \\<equiv> Gx\\<close>. However the concept of being\nthe morning star is different from the concept of being the evening star. The Theory of Abstract\nObjects therefore does not prohibit the existence of an abstract object that \\emph{encodes} \\<open>F\\<close>,\nbut does \\emph{not} encode \\<open>G\\<close>. Therefore by the definition of identity for properties\nit does \\emph{not} hold that \\<open>F = G\\<close>. As a matter of fact the Theory of Abstract Objects\ndoes not force \\<open>F = G\\<close> for any \\<open>F\\<close> and \\<open>G\\<close>. It rather stipulates what needs\nto be proven, if \\<open>F = G\\<close> is to be established, namely that they are necessarily encoded by\nthe same objects. Therefore if two properties \\emph{should} be equal in some context an axiom has to be added\nto the theory that allows to prove that both properties are encoded by the same abstract objects.\n\nThe fact that the following relation terms do \\emph{not} necessarily denote the same relations illustrates\nthe extent of this \\emph{hyperintensionality}:\n\n\\begin{center}\n    \\<open>[\\<lambda>y p \\<or> \\<not>p]\\<close> and \\<open>[\\<lambda>y q \\<or> \\<not>q]\\<close>\\\\\n    \\<open>[\\<lambda>y p & q]\\<close> and \\<open>[\\<lambda>y q & p]\\<close>\n\\end{center}\n\nOf course the theory can be extended in such a way that these properties are equal.\nHowever, without additional axioms their equality is not derivable.\n\nAlthough the relations of object theory are hyperintensional entities,\npropositional reasoning is still governed by classical\nextensionality. For example properties that are necessarily exemplified by the same objects can be\nsubstituted for each other in an exemplification formula, the law of the excluded middle can be\nused in propositional reasoning, etc.\n\nThe Theory of Abstract Objects is an \\emph{extensional} theory of \\emph{intensional}\nentities\\mbox{@{cite \\<open>(\\ref{PM-prop-equiv})\\<close> PM}}.\n\n\\<close>"], ["", "section\\<open>The Aczel-Model\\<close>"], ["", "text\\<open>\n\\label{aczel-model}\n\nWhen thinking about a model for the theory one will quickly notice the following problem:\nThe comprehension axiom for abstract objects implies that for each set of properties there exists\nan abstract object encoding exactly those properties. Considering the definition of identity there therefore\nexists an injective map from the power set of properties to the set of abstract objects.\nOn the other hand for an object \\<open>y\\<close> the term \\mbox{\\<open>[\\<lambda>x Rxy]\\<close>} constitutes a property.\nIf for distinct abstract objects these properties were distinct, this would result in a violation of\nCantor's theorem, since this would mean that there is an injective map from the power set of properties\nto the set of properties. So does the Theory of Abstract Objects as constructed above have a model?\nAn answer to this question was provided by Peter Aczel\\footnote{In fact to our knowledge Dana Scott\nproposed a first model for the theory before Peter Aczel that we believe is a special case of an\nAczel-model with only one \\emph{special urelement}.} who proposed the model structure illustrated\nin figure~\\ref{aczel-model-graphic}.\n\n\\begin{figure}[!h]\n  \\caption{Illustration of the Aczel-Model, courtesy of Edward Zalta}\n  \\includegraphics[width=\\textwidth]{aczel-model.pdf}\n  \\label{aczel-model-graphic}\n\\end{figure}\n\nIn the Aczel-model abstract objects are represented by sets of properties. This of course validates\nthe comprehension axiom of abstract objects. Properties on the other hand are not naively represented\nby sets of objects, which would lead to a violation of Cantor's theorem, but rather as the sets of\n\\emph{urelements}. Urelements are partitioned into two groups, ordinary urelements\n(\\<open>C\\<close> in the illustration) and special urelements (\\<open>S\\<close> in the illustration).\nOrdinary urelements can serve as the denotations of ordinary objects. Every abstract object on\nthe other hand has a special urelement as its proxy. Which properties an abstract object exemplifies\ndepends solely on its proxy. However, the map from abstract objects to special urelements is\nnot injective; more than one abstract object can share the same proxy. This way a violation of\nCantor's theorem is avoided. As a consequence there are abstract objects, that\ncannot be distinguished by the properties they exemplify. Interestingly the existence of abstract objects\nthat are exemplification-indistinguishable is a theorem of PLM, see (\\ref{PM-aclassical2})@{cite PM}.\n\nAlthough the Aczel-model illustrated in figure~\\ref{aczel-model-graphic} is non-modal,\nthe extension to a modal version is straightforward by introducing primitive possible worlds\nas in the Kripke semantics of modal logic.\n\nFurther note that relations in the Aczel-model are \\emph{extensional}. Since properties are represented as the\npower set of urelements, two properties are in fact equal if they are exemplified by the same objects.\nConsequently statements like \\<open>[\\<lambda> p \\<or> \\<not>p] = [\\<lambda> q \\<or> \\<not>q]\\<close> are true in the model,\nalthough they are not derivable from the axioms of object theory as explained in the previous section.\n\nFor this reason an \\emph{intensional} variant of the Aczel-model is developed and used as the\nbasis of the embedding. The technicalities of this model are described in the next chapter\n(see~\\ref{hyper-aczel-model}).\n\n\\<close>"], ["", "chapter\\<open>The Embedding\\<close>"], ["", "text\\<open>\n  \\label{embedding}\n\\<close>"], ["", "section\\<open>The Framework Isabelle/HOL\\<close>"], ["", "text\\<open>\nThe embedding is implemented in Isabelle/HOL, that provides a functional higher-order logic\nthat serves as meta-logic. An introduction to Isabelle/HOL can be found in @{cite Isabelle}\\footnote{\nAn updated version is available at \\url{http://isabelle.in.tum.de/doc/tutorial.pdf} or in the\ndocumentation of the current Isabelle release, see \\url{http://isabelle.in.tum.de/}.}. For a general\nintroduction to HOL and its automation refer to @{cite B5}.\n\nThe Isabelle theory containing the embedding is included in the appendix and documented in this chapter.\nThroughout the chapter references to the various sections of the appendix can be found.\n\nThis document itself is generated from a separate Isabelle theory that imports the complete\nembedding. The terms and theorems discussed throughout this chapter (starting from~\\ref{representation-layer})\nare well-formed terms or valid theorems in the embedding, unless the contrary is stated explicitly. Furthermore\nthe \\emph{pretty printing} facility of Isabelle's document generation has been utilized to\nmake it easier to distinguish between the embedded logic and the meta-logic: all expressions\nthat belong to the embedded logic are printed in blue color throughout the chapter.\n\nFor technical reasons this color coding could not be used for the raw Isabelle theory in the\nappendix. Still note the use of bold print for the quantifiers and connectives of the embedded\nlogic.\n\n\\<close>"], ["", "section\\<open>A Russell-style Paradox\\<close>"], ["", "text\\<open>\n  \\label{russell-paradox}\n\n  One of the major challenges of an implementation of the Theory of Abstract Objects in functional\n  logic is the fact that a naive representation of the \\<open>\\<lambda>\\<close>-expressions of the theory using the\n  unrestricted, \\<open>\\<beta>\\<close>-convertible \\<open>\\<lambda>\\<close>-expressions of functional logic results in the following\n  paradox (see @{cite \\<open>pp. 24-25\\<close> rtt}):\n\n  Assume \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close> were a valid \\<open>\\<lambda>\\<close>-expression denoting a relation.\n  Now the comprehension axiom of abstract objects requires the following:\n\n  \\begin{center}\n    \\<open>\\<exists>x (A!x & \\<forall>F (xF \\<equiv> F = [\\<lambda>x \\<exists>F (xF & \\<not>Fx)]))\\<close>\n  \\end{center}\n\n  So there is an abstract object that encodes only the property \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close>.\n  Let \\<open>b\\<close> be such an object. Now first assume \\<open>b\\<close> exemplifies\n  \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close>. By \\<open>\\<beta>\\<close>-reduction this implies that there exists a property, that\n  \\<open>b\\<close> encodes, but does not exemplify. Since \\<open>b\\<close> only encodes \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close>,\n  but does also exemplify it by assumption this is a contradiction.\n\n  Now assume \\<open>b\\<close> does not exemplify \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close>. By \\<open>\\<beta>\\<close>-reduction it\n  follows that there does not exist a property that \\<open>b\\<close> encodes, but does not exemplify.\n  Since \\<open>b\\<close> encodes \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close> by construction and does not exemplify\n  it by assumption this is again a contradiction.\n\n  This paradox is prevented in the formulation of object theory by disallowing encoding\n  subformulas in \\<open>\\<lambda>\\<close>-expressions, so in particular \\<open>[\\<lambda>x \\<exists>F (xF & \\<not>Fx)]\\<close> is not\n  part of the language. However during the construction of the embedding it was discovered\n  that this restriction is not sufficient to prevent paradoxes in general. This is discussed\n  in section~\\ref{paradox}. The solution used in the embedding is described in\n  section~\\ref{lambda-expressions}.\n\\<close>"], ["", "section\\<open>Basic Concepts\\<close>"], ["", "text\\<open>\n\nThe introduction mentioned that shallow semantical embeddings were used to successfully represent\ndifferent varieties of modal logic by implementing them using Kripke semantics. The advantage here\nis that Kripke semantics is well understood and there are extensive results about its soundness and\ncompleteness that can be utilized in the analysis of semantical embeddings (see~@{cite ModalLogics}).\n\nFor the Theory of Abstract Objects the situation is different. Section~\\ref{aczel-model} already\nestablished that even a modal version of the traditional Aczel-model is extensional and therefore\ntheorems are true in it, that are not derivable from the axioms of object theory.\nOn the other hand the last section showed that care has to be taken to ensure the consistency of\nan embedding of the theory in functional logic.\n\nFor this reason the embedding first constructs a hyperintensional version of the Aczel-model\nthat serves as a provably consistent basis for the theory. Then several abstraction layers\nare implemented on top of the model structure in order to enable reasoning that is independent\nof the particular representation. These concepts are described in more\ndetail in the following sections.\n\n\\<close>"], ["", "subsection\\<open>Hyperintensional Aczel-model\\<close>"], ["", "text\\<open>\n\n\\label{hyper-aczel-model}\n\nAs mentioned in section~\\ref{aczel-model} it is straightforward to extend\nthe traditional (non-modal) Aczel-model to a modal version by introducing\nprimitive possible worlds following the Kripke semantics for a modal S5 logic.\n\nRelations in the resulting Aczel-model are, however, still \\emph{extensional}.\nTwo relations that are necessarily exemplified by the same objects are equal. \nThe Aczel-model that is used as the basis for the embedding therefore introduces\n\\emph{states} as another primitive besides possible worlds. Truth values are\nrepresented as ternary functions from states and possible worlds to booleans;\nrelations as functions from urelements, states and possible worlds to booleans.\n\nAbstract objects are still defined as sets of one-place relations and the division\nof urelements into ordinary urelements and special urelements, that serve as proxies\nfor abstract objects, is retained as well. Consequently encoding can still be defined\nas set membership of a relation in an abstract object. Exemplification is defined\nas function application of a relation to the urelement corresponding to an individual,\na state and a possible world.\n\nThe semantic truth evaluation of a proposition in a given possible world is defined\nas its evaluation for a designated \\emph{actual state} and the possible world.\n\nLogical connectives are defined to behave classically in the \\emph{actual state}, but\nhave undefined behavior in other states.\n\nThe reason for this construction becomes apparent if one considers the definition of\nthe identity of relations: relations are considered identical if they are \\emph{encoded}\nby the same abstract objects. In the constructed model encoding depends on the behavior of\na relation in all states. Two relations can necessarily be \\emph{exemplified} by the\nsame objects in the actual state, but still not be identical, since they can differ\nin other states. Therefore hyperintensionality of relations is achieved.\n\nThe dependency on states is not limited to relations, but introduced to propositions,\nconnectives and quantifiers as well, although the semantic truth conditions of formulas\nonly depend on the evaluation for the actual state. The reason for this is to be able to define\n\\<open>\\<lambda>\\<close>-expressions (see section~\\ref{lambda-expressions}) and to extend the\nhyperintensionality of relations to them. Since the behavior of logical connectives is undefined\nin states other than the actual state, the behavior of \\<open>\\<lambda>\\<close>-expressions - although classical\nin the actual state - remains undefined for different states.\n\nIn summary, since the semantic truth of a proposition solely depends on its evaluation for the designated\nactual state, in which the logical connectives are defined to behave classically, the reasoning about\npropositions remains classical, as desired. On the other hand the additional dependency on states allows\na representation of the hyperintensionality of relations.\n\nThe technical details of the implementation are described in section~\\ref{representation-layer}.\n\\<close>"], ["", "subsection\\<open>Layered Structure\\<close>"], ["", "text\\<open>\n\nAlthough the constructed variant of the Aczel-model preserves the hyperintensionality of relations\nin the theory, it is still known that there are true theorems in this model\nthat are not derivable from the axioms of object theory (see~\\ref{artificial-theorems}).\n\nGiven this lack of a model with a well-understood degree of soundness and completeness, the embedding uses\na different approach than other semantical embeddings, namely the embedding is divided into\nseveral \\emph{layers} as follows:\n\n\\begin{itemize}\n  \\item The first layer represents the primitives of PLM using the described hyperintensional\n        and modal variant of the Aczel-model.\n  \\item In a second layer the objects of the embedded logic constructed in the first layer are\n        considered as primitives and some of their semantic properties are derived using the\n        background logic as meta-logic.\n  \\item The third layer derives the axiom system of PLM mostly using the semantics of the second\n        layer and partly using the model structure directly.\n  \\item Based on the third layer the deductive system PLM as described in @{cite \\<open>Chap. 9\\<close> PM}\n        is derived solely using the axiom system of the third layer and the fundamental meta-rules\n        stated in PLM. The model structure and the constructed semantics are explicitly\n        not used in any proofs. Thereby the reasoning in this last layer is independent of the\n        first two layers.\n\\end{itemize}\n\nThe rationale behind this approach is the following:\nThe first layer provides a representation of the embedded logic that is provably consistent.\nOnly minimal axiomatization is necessary, whereas the main construction is purely definitional.\nSince the subsequent layers don't contain any additional axiomatization (the axiom system in the third layer\nis \\emph{derived}) their consistency is thereby guaranteed as well.\n\nThe second layer tries to abstract away from the details of the representation by implementing an\napproximation of the formal semantics of PLM\\footnote{Our thanks to Edward Zalta for supplying\nus with a preliminary version of the corresponding unpublished chapter of PLM.}. The long time goal\nwould be to arrive at the representation of a complete semantics in this layer, that would be sufficient\nto derive the axiom system in the next layer and which any specific model structure would have to satisfy.\nUnfortunately this could not be achieved so far, but it was possible to lay some foundations for future work.\n\nAt the moment full abstraction from the representation layer is only achieved after deriving the axiom\nsystem in the third layer. Still it can be reasoned that in any model of object theory the axiom system\nhas to be derivable and therefore by disallowing all further proofs to rely on the representation\nlayer and model structure directly the derivation of the deductive system PLM is universal. The only\nexceptions are the primitive meta-rules of PLM: modus ponens, RN (necessitation) and\nGEN (universal generalization), as well as the deduction rule. These rules do not follow from the axiom system\nitself, but are derived from the semantics in the second layer (see~\\ref{PLM-metarules}).\nStill as the corresponding semantical rules will again have to be derivable for \\emph{any} model,\nthis does not have an impact on the universality of the subsequent reasoning.\n\nThe technical details of the constructed embedding are described in the following sections.\n\\pagebreak\n\\<close>"], ["", "section\\<open>The Representation Layer\\<close>"], ["", "text\\<open>\n\n\\label{representation-layer}\n\nThe first layer of the embedding (see \\ref{TAO_Embedding}) implements the variant\nof the Aczel-model described in section~\\ref{hyper-aczel-model} and builds a representation\nof the language of PLM in the logic of Isabelle/HOL. This process is outlined step by step\nthroughout this section.\n\n\\<close>"], ["", "subsection\\<open>Primitives\\<close>"], ["", "text\\<open>\nThe following primitive types are the basis of the embedding (see \\ref{TAO_Embedding_Primitives}):\n\n\\begin{itemize}\n  \\item Type @{type i} represents possible worlds in the Kripke semantics.\n  \\item Type @{type j} represents \\emph{states} as described in section~\\ref{hyper-aczel-model}.\n  \\item Type @{type bool} represents meta-logical truth values (\\<open>True\\<close> or \\<open>False\\<close>)\n        and is inherited from Isabelle/HOL.\n  \\item Type @{type \\<omega>} represents ordinary urelements.\n  \\item Type @{type \\<sigma>} represents special urelements.\n\\end{itemize}\n\nTwo constants are introduced:\n\n\\begin{itemize}\n  \\item The constant @{term dw} of type @{typeof dw} represents the designated actual world.\n  \\item The constant @{term dj} of type @{typeof dj} represents the designated actual state.\n\\end{itemize}\n\nBased on the primitive types above the following types are defined (see \\ref{TAO_Embedding_Derived_Types}):\n\n\\begin{itemize}\n  \\item Type @{type \\<o>} is defined as the set of all functions of type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"} and\n        represents propositions in the embedded logic.\n  \\item Type @{type \\<upsilon>} is defined as @{datatype \\<upsilon>}. This type represents urelements and an object\n        of this type can be either an ordinary or a special urelement (with the respective type\n        constructors @{term \\<omega>\\<upsilon>} and @{term \\<sigma>\\<upsilon>}).\n  \\item Type @{type \\<Pi>\\<^sub>0} is defined as a synonym for type @{type \\<o>} and represents zero-place\n        relations.\n  \\item Type @{type \\<Pi>\\<^sub>1} is defined as the set of all functions of type \\mbox{@{typ \"\\<upsilon>\\<Rightarrow>j\\<Rightarrow>i\\<Rightarrow>bool\"}}\n        and represents one-place relations (for an urelement a one-place relation evaluates\n        to a truth value in the embedded logic; for an urelement, a state and a possible world\n        it evaluates to a meta-logical truth value).\n  \\item Type @{type \\<Pi>\\<^sub>2} is defined as the set of all functions of type \\mbox{@{typ \"\\<upsilon>\\<Rightarrow>\\<upsilon>\\<Rightarrow>j\\<Rightarrow>i\\<Rightarrow>bool\"}}\n        and represents two-place relations.\n  \\item Type @{type \\<Pi>\\<^sub>3} is defined as the set of all functions of type \\mbox{@{typ \"\\<upsilon>\\<Rightarrow>\\<upsilon>\\<Rightarrow>\\<upsilon>\\<Rightarrow>j\\<Rightarrow>i\\<Rightarrow>bool\"}}\n        and represents three-place relations.\n  \\item Type @{type \\<alpha>} is defined as a synonym of the type of sets of one-place relations \\<open>\\<Pi>\\<^sub>1 set\\<close>,\n        i.e. every set of one-place relations constitutes an object of type @{type \\<alpha>}. This type\n        represents abstract objects.\n  \\item Type @{type \\<nu>} is defined as @{datatype \\<nu>}. This type represents individuals and can\n        be either an ordinary urelement of type @{type \\<omega>} or an abstract object of type @{type \\<alpha>} (with the\n        respective type constructors @{term \\<omega>\\<nu>} and @{term \\<alpha>\\<nu>}).\n  \\item Type @{type \\<kappa>} is defined as the set of all objects of type @{typ \"\\<nu> option\"} and\n        represents individual terms. The type @{typ \"'a option\"} is part of Isabelle/HOL and\n        consists of a type constructor @{term \"Some x\"} for an object @{term \"x\"} of type @{typ 'a}\n        (in this case type @{type \\<nu>}) and an additional special element called @{term \"None\"}.\n        @{term \"None\"} is used to represent individual terms that are definite descriptions\n        that are not logically proper (i.e. they do not denote an individual).\n\\end{itemize}\n\n\\begin{remark}\n  The Isabelle syntax @{theory_text \"typedef \\<o> = UNIV::(j\\<Rightarrow>i\\<Rightarrow>bool) set morphisms eval\\<o> make\\<o> ..\"}\n  found in the theory source in the appendix introduces a new abstract type @{type \\<o>} that is represented\n  by the full set (@{term UNIV})   of objects of type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}. The morphism \\<open>eval\\<o>\\<close> maps\n  an object of abstract type @{type \\<o>} to its representative of type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}, whereas \n  the morphism \\<open>make\\<o>\\<close> maps an object of type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"} to the object\n  of type @{type \\<o>} that is represented by it. Defining these abstract types makes it\n  possible to consider the defined types as primitives in later stages of the embedding,\n  once their meta-logical properties are derived from the underlying representation.\n  For a theoretical analysis of the representation layer the type @{type \\<o>} can be considered\n  a synonym of @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}.\n\n  The Isabelle syntax @{theory_text \"setup_lifting type_definition_\\<o>\"} allows definitions for the\n  abstract type @{type \\<o>} to be stated directly for its representation type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}\n  using the syntax @{theory_text \"lift_definition\"}.\n\n  For the sake of readability in the documentation of the embedding the morphisms are omitted\n  and definitions are stated directly for the representation types\\footnote{The omission of the\n  morphisms is achieved using custom \\emph{pretty printing} rules for the document generation\n  facility of Isabelle. The full technical details without these minor omissions can be found in the\n  raw Isabelle theory in the appendix.}.\n\\end{remark}\n\n\\<close>"], ["", "subsection\\<open>Individual Terms and Definite Descriptions\\<close>"], ["", "text\\<open>\n\\label{individual-terms-and-descriptions}\n\nThere are two basic types of individual terms in PLM: definite descriptions and individual variables\n(and constants). Every logically proper definite description denotes an individual. A definite\ndescription is logically proper if its matrix is (actually) true for a unique individual.\n\nIn the embedding the type @{type \\<kappa>} encompasses all individual terms, i.e. individual variables,\nconstants \\emph{and} definite descriptions. An individual (i.e. a variable or constant\nof type @{type \\<nu>}) can be used in place of an individual term of type @{type \\<kappa>} via the decoration\n@{term \"embedded_style (DUMMY\\<^sup>P)\"} (see~\\ref{TAO_Embedding_IndividualTerms}):\n\n\\begin{center}\n  @{thm \\<nu>\\<kappa>.rep_eq[where x=x, THEN embedded_meta_eq]}\n\\end{center}\n\nThe expression @{term \"embedded_style (x\\<^sup>P)\"} (of type @{typeof \"x\\<^sup>P\"}) is marked to be\nlogically proper (it can only be substituted by objects that are internally of the form @{term \"Some x\"})\nand to denote the individual @{term \"x\"}.\n\nDefinite descriptions are defined as follows:\n\n\\begin{center}\n  @{thm that.rep_eq[where x=\\<phi>, THEN embedded_meta_eq]}\n\\end{center}\n\nIf the propriety condition of a definite description @{prop \"\\<exists>!x. \\<phi> x dj dw\"} holds,\ni.e. \\emph{there exists a unique @{term \"x\"}, such that @{term \"\\<phi> x\"} holds for the actual state and\nthe actual world}, the term \\mbox{@{term \"embedded_style (\\<^bold>\\<iota>x . \\<phi> x)\"}} evaluates to @{term \"Some (THE x . \\<phi> x dj dw)\"}.\nIsabelle's @{theory_text THE} operator evaluates to the unique object, for which the given condition holds,\nif there is such a unique object, and is undefined otherwise. If the propriety condition does not hold,\nthe term evaluates to @{term \"None\"}.\n\nThe following meta-logical functions are defined to aid in handling individual terms:\n\n\\begin{itemize}\n  \\item @{thm[display] proper.rep_eq}\n  \\item @{thm[display] rep.rep_eq}\n\\end{itemize}\n\n@{term \"the\"} maps an object of type @{typ \"'a option\"} that is of the form @{term \"Some x\"} to\n@{term \"x\"} and is undefined for @{term \"None\"}. For an object of type @{type \\<kappa>} the expression\n@{term \"proper x\"} is true, if the term is logically proper, and if this is the case,\nthe expression @{term \"rep x\"} evaluates to the individual of type @{type \\<nu>} that the term denotes.\n\\<close>"], ["", "subsection\\<open>Mapping from Individuals to Urelements\\<close>"], ["", "text\\<open>\n\n\\label{individuals-to-urelements}\n\nTo map abstract objects to urelements (for which relations can be evaluated), a constant\n@{term \\<alpha>\\<sigma>} of type @{typeof \\<alpha>\\<sigma>} is introduced, which maps abstract objects (of type @{type \\<alpha>})\nto special urelements (of type @{type \\<sigma>}), see \\ref{TAO_Embedding_AbstractObjectsToSpecialUrelements}.\n\nTo assure that every object in the full domain of urelements actually is an urelement for (one or more)\nindividual objects, the constant @{term \\<alpha>\\<sigma>} is axiomatized to be surjective.\n\nNow the mapping @{term \"\\<nu>\\<upsilon>\"} of type @{typeof \"\\<nu>\\<upsilon>\"} can be defined as follows:\n\n\\begin{center}\n@{thm \\<nu>\\<upsilon>_def[atomize]}\n\\end{center}\n\nTo clarify the syntax note that this is equivalent to the following:\n\n\\begin{center}\n@{lemma \"(\\<forall> x . \\<nu>\\<upsilon> (\\<omega>\\<nu> x) = \\<omega>\\<upsilon> x) \\<and> (\\<forall> x . \\<nu>\\<upsilon> (\\<alpha>\\<nu> x) = \\<sigma>\\<upsilon> (\\<alpha>\\<sigma> x))\" by (simp add: \\<nu>\\<upsilon>_def)}\n\\end{center}\n\nSo ordinary objects are simply converted to an urelements by the type constructor\n@{term \"\\<omega>\\<upsilon>\"}, whereas for abstract objects the corresponding\nspecial urelement under \\<open>\\<alpha>\\<sigma>\\<close> is converted to an urelement using the type constructor\n@{term \"\\<sigma>\\<upsilon>\"}.\n\n\\begin{remark}\n  Future versions of the embedding may introduce a dependency of the mapping from individuals\n  to urelements on states (see~\\ref{artificial-theorems}).\n\\end{remark}\n\n\\<close>"], ["", "subsection\\<open>Exemplification of n-place relations\\<close>"], ["", "text\\<open>\n  Exemplification of n-place relations can now be defined. Exemplification of zero-place\n  relations is simply defined as the identity, whereas exemplification of n-place relations\n  for \\<open>n \\<ge> 1\\<close> is defined to be true, if all individual terms are logically proper and\n  the function application of the relation to the urelements corresponding to the individuals\n  yields true for a given possible world and state (see \\ref{TAO_Embedding_Exemplification}):\n\\pagebreak\n  \\begin{itemize}\n    \\item @{thm[display] exe0.rep_eq[where x=p, THEN embedded_meta_eq]}\n    \\item @{thm[display] exe1.rep_eq[where x=F and xa=x, THEN embedded_meta_eq]}\n    \\item @{thm[display] exe2.rep_eq[where x=F and xa=x and xb=y, THEN embedded_meta_eq]}\n    \\item @{thm[display] exe3.rep_eq[where x=F and xa=x and xb=y and xc=z, THEN embedded_meta_eq]}\n  \\end{itemize}\n\\<close>"], ["", "subsection\\<open>Encoding\\<close>"], ["", "text\\<open>\n  Encoding is defined as follows (see \\ref{TAO_Embedding_Encoding}):\n\n  \\begin{center}\n  @{thm enc.rep_eq[of x F, THEN embedded_meta_eq]}\n  \\end{center}\n\n  For a given state @{term s} and a given possible world @{term w} it holds that\n  an individual term @{term x} encodes @{term F}, if @{term x} is logically proper,\n  the denoted individual @{term \"rep x\"} is of the form @{term \"\\<alpha>\\<nu> \\<alpha>\"} for\n  some object @{term \\<alpha>} (i.e. it is an abstract object) and @{term F} is contained in @{term \\<alpha>}\n  (recall that abstract objects are defined to be sets of one-place relations).\n\n  Encoding is represented as a function of states and possible worlds to ensure type-correctness,\n  but its evaluation does not depend on either. On the other hand whether @{term F} is contained\n  in @{term \\<alpha>} does depend on the behavior of @{term F} in \\emph{all} states.\n\\<close>"], ["", "subsection\\<open>Connectives and Quantifiers\\<close>"], ["", "text\\<open>\n  \\label{connectives}\n\n  Following the model described in section~\\ref{hyper-aczel-model} the connectives and quantifiers\n  are defined in such a way that they behave classically if evaluated for the designated actual state @{term \"dj\"},\n  whereas their behavior is governed by uninterpreted constants in any other state\\footnote{Early attempts\n  in using an intuitionistic version of connectives and quantifiers based on \\cite{DOttaviano2012} were\n  found to be insufficient to capture the full hyperintensionality of PLM, but served as inspiration\n  for the current construction.}.\n\n  For this purpose the following uninterpreted constants are introduced (see \\ref{TAO_Embedding_Connectives}):\n  \\begin{itemize}\n    \\item @{const I_NOT} of type @{typeof I_NOT}\n    \\item @{const I_IMPL} of type @{typeof I_IMPL}\n  \\end{itemize}\n\n  Modality is represented using the dependency on primitive possible worlds using\n  a standard Kripke semantics for a S5 modal logic.\n\n  The basic connectives and quantifiers are defined as follows\n  (see \\ref{TAO_Embedding_Connectives}):\n  \\begin{itemize}\n    \\item @{thm[display] not.rep_eq[of p, THEN embedded_meta_eq]}\n    \\item @{thm[display] impl.rep_eq[of p q, THEN embedded_meta_eq]}\n    \\item @{thm[display] forall\\<^sub>\\<nu>.rep_eq[of \\<phi>, rename_abs s w x, THEN embedded_meta_eq]}\n    \\item @{thm[display] forall\\<^sub>0.rep_eq[of \\<phi>, rename_abs s w p, THEN embedded_meta_eq]}\n    \\item @{thm[display] forall\\<^sub>1.rep_eq[of \\<phi>, rename_abs s w F, THEN embedded_meta_eq]}\n    \\item @{thm[display] forall\\<^sub>2.rep_eq[of \\<phi>, rename_abs s w F, THEN embedded_meta_eq]}\n    \\item @{thm[display] forall\\<^sub>3.rep_eq[of \\<phi>, rename_abs s w F, THEN embedded_meta_eq]}\n    \\item @{thm[display] box.rep_eq[of p, THEN embedded_meta_eq]}\n    \\item @{thm[display] actual.rep_eq[of p, THEN embedded_meta_eq]}\n  \\end{itemize}\n\n  Note in particular that negation and implication behave\n  classically if evaluated for the actual state @{term \"s = dj\"}, but\n  are governed by the uninterpreted constants @{term I_NOT} and @{term I_IMPL} for\n  @{term \"s \\<noteq> dj\"}:\n\n  \\begin{itemize}\n  \\item @{lemma[display] \"s = dj \\<Longrightarrow> eval\\<o> (embedded_style (\\<^bold>\\<not>p)) s w = (\\<not>eval\\<o> (embedded_style (p)) s w)\"\n          by (unfold embedded_style_def, transfer, auto)}\n  \\item @{lemma \"s \\<noteq> dj \\<Longrightarrow> eval\\<o> (embedded_style (\\<^bold>\\<not>p)) s w = (I_NOT s (eval\\<o> (embedded_style (p)) s) w)\"\n          by (unfold embedded_style_def, transfer, auto)}\n  \\item @{lemma[display] \"s = dj \\<Longrightarrow> eval\\<o> (embedded_style (p \\<^bold>\\<rightarrow> q)) s w = (eval\\<o> (embedded_style p) s w \\<longrightarrow> eval\\<o> (embedded_style q) s w)\"\n          by (unfold embedded_style_def, transfer, auto)}\n  \\item @{lemma \"s \\<noteq> dj \\<Longrightarrow> eval\\<o> (embedded_style (p \\<^bold>\\<rightarrow> q)) s w = (I_IMPL s (eval\\<o> (embedded_style p) s) (eval\\<o> (embedded_style q) s) w)\"\n          by (unfold embedded_style_def, transfer, auto)}\n  \\end{itemize}\n\n  \\begin{remark}\n    Future research may conclude that non-classical behavior in states @{term \"s \\<noteq> dj\"}\n    for negation and implication is not sufficient for achieving the desired level of\n    hyperintensionality for \\<open>\\<lambda>\\<close>-expressions. It would be trivial to introduce additional\n    uninterpreted constants to govern the behavior of the remaining connectives and quantifiers\n    in such states as well, though. The remainder of the embedding would not be affected, i.e.\n    no assumption about the behavior of connectives and quantifiers in states other than @{term \"dj\"}\n    is made in the subsequent reasoning. At the time of writing non-classical behavior for\n    negation and implication is considered sufficient.\n  \\end{remark}\n\n\\<close>"], ["", "subsection\\<open>$\\lambda$-Expressions\\<close>"], ["", "text\\<open>\n\n  \\label{lambda-expressions}\n\n  The bound variables of the \\<open>\\<lambda>\\<close>-expressions of the embedded logic are individual\n  variables, whereas relations are represented as functions acting on urelements.\n  Therefore the definition of the \\<open>\\<lambda>\\<close>-expressions of the embedded logic is non-trivial.\n  The embedding defines them as follows (see \\ref{TAO_Embedding_Lambda}):\n\n  \\begin{itemize}\n    \\item @{thm[display] lambdabinder0.rep_eq[of p, THEN embedded_meta_eq]}\n    \\item @{thm[display] lambdabinder1.rep_eq[of \\<phi>, THEN embedded_meta_eq]}\n    \\item @{thm[display, eta_contract=false] lambdabinder2.rep_eq[of \"\\<lambda> x y . \\<phi> x y\", THEN embedded_meta_eq]}\n    \\item @{thm[display, eta_contract=false] lambdabinder3.rep_eq[of \"\\<lambda> x y z . \\<phi> x y z\", THEN embedded_meta_eq]}\n  \\end{itemize}\n\n\\begin{remark}\n  For technical reasons Isabelle only allows \\<open>\\<lambda>\\<close>-expressions for one-place relations\n  to use a nice binder notation. Although better workarounds may be possible, for now the\n  issue is avoided by the use of the primitive \\<open>\\<lambda>\\<close>-expressions of the background\n  logic in combination with the constants @{term \"\\<^bold>\\<lambda>\\<^sup>2\"} and @{term \"\\<^bold>\\<lambda>\\<^sup>3\"} as shown above.\n\\end{remark}\n\n  The representation of zero-place \\<open>\\<lambda>\\<close>-expressions as the identity is straight-forward;\n  the representation of n-place \\<open>\\<lambda>\\<close>-expressions for \\mbox{\\<open>n \\<ge> 1\\<close>}\n  is illustrated for the case \\mbox{\\<open>n = 1\\<close>}:\n\n  The matrix of the \\<open>\\<lambda>\\<close>-expression @{term \"embedded_style \\<phi>\"} is a function from individuals\n  (of type @{type \\<nu>}) to truth values (of type @{type \\<o>}, resp. @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}).\n  One-place relations are represented as functions of type @{typ \"\\<upsilon>\\<Rightarrow>j\\<Rightarrow>i\\<Rightarrow>bool\"} though,\n  where @{type \\<upsilon>} is the type of urelements.\n\n  The \\<open>\\<lambda>\\<close>-expression @{term \"embedded_style (\\<^bold>\\<lambda>x. \\<phi> x)\"} evaluates to @{term \"True\"} for an urelement @{term u},\n  a state @{term s} and a world @{term w}, if there is an individual @{term \"embedded_style x\"} in the preimage\n  of @{term \"u\"} under @{term \"\\<nu>\\<upsilon>\"} and it holds that \\mbox{@{term \"eval\\<o> (embedded_style (\\<phi> x)) s w\"}}.\n\n  \\begin{center}\n  @{lemma \"eval\\<Pi>\\<^sub>1 (embedded_style (\\<^bold>\\<lambda>x . \\<phi> x)) u s w = (\\<exists> x . \\<nu>\\<upsilon> x = u \\<and> eval\\<o> (embedded_style (\\<phi> x)) s w)\"\n    by (simp add: embedded_style_def meta_defs meta_aux)}\n  \\end{center}\n\n  If restricted to ordinary objects, the definition can be simplified, since @{term \"\\<nu>\\<upsilon>\"} is bijective\n  on the set of ordinary objects:\n\n  \\begin{center}\n  @{lemma \"eval\\<Pi>\\<^sub>1 (embedded_style (\\<^bold>\\<lambda>x . \\<phi> x)) (\\<omega>\\<upsilon> u) s w = eval\\<o> (embedded_style (\\<phi>) (\\<omega>\\<nu> u)) s w\"\n    by (simp add: embedded_style_def meta_defs meta_aux, metis \\<nu>.exhaust \\<nu>\\<upsilon>_\\<omega>\\<nu>_is_\\<omega>\\<upsilon> \\<upsilon>.inject(1) no_\\<alpha>\\<omega>)}\n  \\end{center}\n\n  However in general @{term \"\\<nu>\\<upsilon>\"} can map several abstract objects to the same special urelement,\n  so an analog statement for abstract objects does not hold for arbitrary @{term \"\\<phi>\"}. As described\n  in section~\\ref{russell-paradox} such a statement would in fact not be desirable, since it would\n  lead to inconsistencies.\n\n  Instead the embedding introduces the concept of \\emph{proper maps}.\n  A map from individuals to propositions is defined to be proper if its truth evaluation for the actual state only\n  depends on the urelements corresponding to the individuals (see \\ref{TAO_Embedding_Proper}):\n\n  \\begin{itemize}\n    \\item @{thm[display] IsProperInX.rep_eq[of \\<phi>]}\n    \\item @{thm[display] IsProperInXY.rep_eq[of \\<phi>]}\n    \\item @{thm[display] IsProperInXYZ.rep_eq[of \\<phi>]}\n  \\end{itemize}\n\n  Now by the definition of proper maps the evaluation of \\<open>\\<lambda>\\<close>-expressions behaves as expected\n  for proper @{term \"embedded_style \\<phi>\"}:\n\n  \\begin{center}\n  @{lemma \"IsProperInX (embedded_style \\<phi>) \\<longleftrightarrow> (\\<forall> w x . eval\\<Pi>\\<^sub>1 (embedded_style (\\<^bold>\\<lambda>x . \\<phi> (x\\<^sup>P))) (\\<nu>\\<upsilon> x) dj w = eval\\<o> (embedded_style (\\<phi> (x\\<^sup>P))) dj w)\"\n    by (auto simp: embedded_style_def meta_defs meta_aux IsProperInX_def)}\n  \\end{center}\n\n  \\begin{remark}\n    The right-hand side of the equation above does not quantify over all states,\n    but is restricted to the actual state @{term \"dj\"}.\n    This is sufficient given that truth evaluation only depends on the actual state\n    and goes along with the desired semantics of \\<open>\\<lambda>\\<close>-expressions (see~\\ref{semantics-lambda}).\n  \\end{remark}\n\n  Maps that contain encoding formulas in their arguments are in general\n  not proper and thereby the paradox mentioned in section~\\ref{russell-paradox} is prevented.\n\n  In fact proper maps are the most general kind of functions that may appear in a lambda-expression,\n  such that \\<open>\\<beta>\\<close>-conversion holds. In what way proper maps correspond to the formulas that PLM\n  allows as the matrix of a \\<open>\\<lambda>\\<close>-expression is a complex question and discussed separately in\n  section~\\ref{differences-lambda}.\n\\<close>"], ["", "subsection\\<open>Validity\\<close>"], ["", "text\\<open>\n  Semantic validity is defined as follows (see \\ref{TAO_Embedding_Validity}):\n  \n  \\begin{center}\n    @{thm valid_in.rep_eq[of v \"embedded_style \\<phi>\"]}\n  \\end{center}\n\n  A formula is considered semantically valid for a possible world @{term v} if it evaluates\n  to @{term True} for the actual state @{term dj} and the given possible world @{term v}.\n\n  \\begin{remark}\n    The Isabelle Theory in the appendix defines the syntax \\mbox{\\<open>v \\<Turnstile> p\\<close>} in the representation\n    layer, following the syntax used in the formal semantics of PLM.\n    The syntax \\mbox{@{term \"[p in v]\"}} that is easier to use in Isabelle due to bracketing the expression\n    is only introduced after the semantics is derived in \\ref{TAO_Semantics_Validity}.\n    For simplicity only the latter syntax is used in this documentation.\n  \\end{remark}\n\\<close>"], ["", "subsection\\<open>Concreteness\\<close>"], ["", "text\\<open>\n  \\label{concreteness}\n\n  PLM defines concreteness as a one-place relation constant. For the embedding care has to\n  be taken that concreteness actually matches the primitive distinction between ordinary and\n  abstract objects. The following requirements have to be satisfied by the introduced notion of\n  concreteness:\n  \\begin{itemize}\n    \\item Ordinary objects are possibly concrete. In the meta-logic this means that for every\n          ordinary object there exists at least one possible world, in which the object is concrete.\n    \\item Abstract objects are not possibly concrete.\n  \\end{itemize}\n\n  An additional requirement is enforced by axiom (\\ref{PM-qml}.4)\\cite{PM}, see~\\ref{axioms-necessity}.\n  To satisfy this axiom the following has to be assured:\n  \\begin{itemize}\n    \\item Possibly contingent objects exist. In the meta-logic this means that there exists\n          an ordinary object and two possible worlds, such that the ordinary object is\n          concrete in one of the worlds, but not concrete in the other.\n    \\item Possibly no contingent objects exist. In the meta-logic this means that there exists\n          a possible world, such that all objects that are concrete in this world, are concrete\n          in all possible worlds.\n  \\end{itemize}\n\n  In order to satisfy these requirements a constant @{const ConcreteInWorld} is introduced,\n  that maps ordinary objects (of type @{type \\<omega>}) and possible worlds (of type @{type i})\n  to meta-logical truth values (of type @{type bool}). This constant is axiomatized in the\n  following way (see~\\ref{TAO_Embedding_Concreteness}):\n  \\begin{itemize}\n    \\item @{thm OrdinaryObjectsPossiblyConcreteAxiom}\n    \\item @{thm PossiblyContingentObjectExistsAxiom}\n    \\item @{thm PossiblyNoContingentObjectExistsAxiom}\n  \\end{itemize}\n\n  Concreteness can now be defined as a one-place relation:\n  \\begin{center}\n    @{thm Concrete.rep_eq[THEN embedded_meta_eq]}\n  \\end{center}\n\n  Whether an ordinary object is concrete is governed by the introduced constant, whereas\n  abstract objects are never concrete.\n\n\\<close>"], ["", "subsection\\<open>The Syntax of the Embedded Logic\\<close>"], ["", "text\\<open>\n\nThe embedding aims to provide a readable syntax for the embedded logic that is as close as possible\nto the syntax of PLM and clearly distinguishes between the embedded\nlogic and the meta-logic. Some concessions have to be made due to the limitations of definable syntax\nin Isabelle, though. Moreover exemplification and encoding have to use a dedicated syntax in order\nto be distinguishable from function application.\n\nThe syntax for the basic formulas of PLM used in the embedding is summarized in the\nfollowing table:\n\n\\begin{center}\n\\begin{tabular}{l|l|l|c}\nPLM & syntax in words & embedded logic & type \\\\\n\\hline\n\\<open>\\<phi>\\<close> & it holds that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<phi>)\"} & @{type \\<o>} \\\\\n\\<open>\\<not>\\<phi>\\<close> & not \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<not>\\<phi>)\"} & @{type \\<o>}  \\\\\n\\<open>\\<phi> \\<rightarrow> \\<psi>\\<close> & \\<open>\\<phi>\\<close> implies \\<open>\\<psi>\\<close> & @{term \"embedded_style (\\<phi> \\<^bold>\\<rightarrow> \\<psi>)\"} & @{type \\<o>}  \\\\\n\\<open>\\<box>\\<phi>\\<close> & necessarily \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<box>\\<phi>)\"} & @{type \\<o>}  \\\\\n\\<open>\\<A>\\<phi>\\<close> & actually \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<A>\\<phi>)\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>\\<upsilon>\\<close> & \\<open>\\<upsilon>\\<close> (an individual term) exemplifies \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,\\<upsilon>\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>x\\<close> & \\<open>x\\<close> (an individual variable) exemplifies \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,x\\<^sup>P\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>\\<upsilon>\\<^sub>1\\<upsilon>\\<^sub>2\\<close> & \\<open>\\<upsilon>\\<^sub>1\\<close> and \\<open>\\<upsilon>\\<^sub>2\\<close> exemplify \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,\\<upsilon>\\<^sub>1,\\<upsilon>\\<^sub>2\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>xy\\<close> & \\<open>x\\<close> and \\<open>y\\<close> exemplify \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,x\\<^sup>P,y\\<^sup>P\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>\\<upsilon>\\<^sub>1\\<upsilon>\\<^sub>2\\<upsilon>\\<^sub>3\\<close> & \\<open>\\<upsilon>\\<^sub>1\\<close>, \\<open>\\<upsilon>\\<^sub>2\\<close> and \\<open>\\<upsilon>\\<^sub>3\\<close> exemplify \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,\\<upsilon>\\<^sub>1,\\<upsilon>\\<^sub>2,\\<upsilon>\\<^sub>3\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<Pi>xyz\\<close> & \\<open>x\\<close>, \\<open>y\\<close> and \\<open>z\\<close> exemplify \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lparr>\\<Pi>,x\\<^sup>P,y\\<^sup>P,z\\<^sup>P\\<rparr>\"} & @{type \\<o>}  \\\\\n\\<open>\\<upsilon>\\<Pi>\\<close> & \\<open>\\<upsilon>\\<close> encodes \\<open>\\<Pi>\\<close> & @{term \"embedded_style \\<lbrace>\\<upsilon>,\\<Pi>\\<rbrace>\"} & @{type \\<o>}  \\\\\n\\<open>\\<iota>x\\<phi>\\<close> & \\emph{the} \\<open>x\\<close>, such that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<iota>x . \\<phi> x)\"} & @{type \\<kappa>}  \\\\\n\\<open>\\<forall>x(\\<phi>)\\<close> & for all individuals \\<open>x\\<close> it holds that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<forall>\\<^sub>\\<nu> x . \\<phi> x)\"} & @{type \\<o>} \\\\\n\\<open>\\<forall>p(\\<phi>)\\<close> & for all propositions \\<open>p\\<close> it holds that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<forall>\\<^sub>0 p . \\<phi> p)\"} & @{type \\<o>} \\\\\n\\<open>\\<forall>F(\\<phi>)\\<close> & for all relations \\<open>F\\<close> it holds that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<forall>\\<^sub>1 F . \\<phi> F)\"} & @{type \\<o>} \\\\\n& & @{term \"embedded_style (\\<^bold>\\<forall>\\<^sub>2 F . \\<phi> F)\"} & \\\\\n& & @{term \"embedded_style (\\<^bold>\\<forall>\\<^sub>3 F . \\<phi> F)\"} & \\\\\n\\<open>[\\<lambda> p]\\<close> & being such that \\<open>p\\<close> & @{term \"embedded_style (\\<^bold>\\<lambda>\\<^sup>0 p)\"}  & @{typ \\<Pi>\\<^sub>0} \\\\\n\\<open>[\\<lambda>x \\<phi>]\\<close> & being \\<open>x\\<close> such that \\<open>\\<phi>\\<close> & @{term \"embedded_style (\\<^bold>\\<lambda> x . \\<phi> x)\"} & @{type \\<Pi>\\<^sub>1} \\\\\n\\<open>[\\<lambda>xy \\<phi>]\\<close> & being \\<open>x\\<close> and \\<open>y\\<close> such that \\<open>\\<phi>\\<close> & @{term[eta_contract=false] \"embedded_style (\\<^bold>\\<lambda>\\<^sup>2 (\\<lambda> x y . \\<phi> x y))\"} & @{type \\<Pi>\\<^sub>2} \\\\\n\\<open>[\\<lambda>xyz \\<phi>]\\<close> & being \\<open>x\\<close>, \\<open>y\\<close> and \\<open>z\\<close> such that \\<open>\\<phi>\\<close> & @{term[eta_contract=false] \"embedded_style (\\<^bold>\\<lambda>\\<^sup>3 (\\<lambda> x y z . \\<phi> x y z))\"} & @{type \\<Pi>\\<^sub>3}\n\\end{tabular}\n\\end{center}\n\n\\pagebreak\n\nSeveral subtleties have to be considered:\n\\begin{itemize}\n  \\item @{term \"n\"}-place relations are only represented for \\mbox{\\<open>n \\<le> 3\\<close>}.\n        As the resulting language is already expressive enough to represent the most interesting\n        parts of the theory and it would be trivial to add analog implementations for\n        \\mbox{\\<open>n > 3\\<close>}, this is considered to be sufficient. Future work may attempt to construct a general\n        representation for \\<open>n\\<close>-place relations for arbitrary \\<open>n\\<close>.\n  \\item Individual terms (that can be descriptions) and individual variables, resp. constants have\n        different types. Exemplification and encoding is defined for individual terms of type @{type \\<kappa>}.\n        Individual variables (i.e. variables of type @{type \\<nu>}) or individual constants\n        (i.e. constants of type @{type \\<nu>}) can be converted to type @{type \\<kappa>} using the\n        decoration~@{term \"embedded_style (DUMMY\\<^sup>P)\"}.\n  \\item In PLM a general term @{term \"\\<phi>\"}, as it occurs in definite descriptions,\n        quantification formulas and \\<open>\\<lambda>\\<close>-expressions above, can contain \\emph{free} variables. If\n        such a term occurs within the scope of a variable binding operator, free occurrences of\n        the variable are considered to be \\emph{bound} by the operator. In the embedding this concept\n        is replaced by representing @{term \"embedded_style \\<phi>\"} as a \\emph{function} acting on the bound variables\n        and using the native concept of binding operators in Isabelle.\n  \\item The representation layer of the embedding defines a separate quantifier for every type of\n        variable in PLM. This is done to assure that only quantification ranging over these types\n        is part of the embedded language. The definition of a general quantifier in the representation layer\n        could for example be used to quantify over individual \\emph{terms} (of type @{type \\<kappa>}), whereas\n        only quantification ranging over individuals (of type @{type \\<nu>}) is part of the language of PLM.\n        After the semantics is introduced in section~\\ref{semantics}, a \\emph{type class} is constructed\n        that is characterized by the semantics of quantification and instantiated for all variable types.\n        This way a general binder that can be used for all variable types can be defined. The details\n        of this approach are explained in section~\\ref{general-quantifier}.\n\\end{itemize}\n\nThe syntax used for stating that a proposition is semantically valid is the following:\n\\begin{center}\n    @{term \"[\\<phi> in v]\"}\n\\end{center}\n\nHere @{term \"embedded_style \\<phi>\"} and @{term \"v\"} are free variables (in the meta-logic).\nTherefore, stating the expression above as a lemma will implicitly be a quantified statement over all\npropositions @{term \"embedded_style \\<phi>\"} and all possible worlds @{term \"v\"} (unless\n@{term \"embedded_style \\<phi>\"} or @{term \"v\"} are explicitly restricted in the current scope\nor globally declared as constants).\n\n\\vfill\n\\pagebreak\n\\<close>"], ["", "(*<*)"], ["", "context Semantics\nbegin"], ["", "(*>*)"], ["", "section\\<open>Semantic Abstraction\\<close>"], ["", "text\\<open>\n\\label{semantics}\n\nThe second layer of the embedding (see~\\ref{TAO_Semantics}) abstracts away from the technicalities\nof the representation layer and states the truth conditions for formulas of the embedded logic\nin a similar way as the (at the time of writing unpublished) semantics of object theory.\n\n\\<close>"], ["", "subsection\\<open>Domains and Denotation Functions\\<close>"], ["", "text\\<open>\nIn order to do so the abstract types introduced in the representation layer\n@{typ \\<kappa>}, @{typ \\<o>} resp. @{typ \\<Pi>\\<^sub>0}, @{typ \\<Pi>\\<^sub>1}, @{typ \\<Pi>\\<^sub>2} and @{typ \\<Pi>\\<^sub>3} are considered\nas primitive types and assigned semantic domains: @{type R\\<^sub>\\<kappa>}, @{typ R\\<^sub>0}, @{typ R\\<^sub>1},\n@{typ R\\<^sub>2} and @{typ R\\<^sub>3} (see~\\ref{TAO_Semantics_Semantics_Domains}).\n\nFor the embedding the definition of these semantic domains is trivial, since the abstract types of\nthe representation layer are already modeled using representation sets. Therefore the semantic domain\nfor each type can simply be defined as the type of its representatives.\n\nAs a next step denotation functions are defined that assign semantic denotations to the objects of each\nabstract type (see~\\ref{TAO_Semantics_Semantics_Denotations}).\nThe formal semantics of PLM does not a priori assume that every term has a denotation. Therefore,\nthe denotation functions are represented as functions that map to the \\<open>option\\<close> type of the\nrespective domain. This way they can either map a term to @{term \"Some x\"}, if the term denotes\n@{term \"x\"}, or to @{term \"None\"}, if the term does not denote.\n\nIn the embedding all relation terms always denote, therefore the denotation functions @{term \"d\\<^sub>0\"},\n\\<open>\\<dots>\\<close>, @{term \"d\\<^sub>3\"} for relations can simply be defined as the type constructor @{term \"Some\"}.\nIndividual terms on the other hand are already represented by an \\<open>option\\<close> type,\nso the denotation function @{term \"d\\<^sub>\\<kappa>\"} can be defined as the identity.\n\nMoreover the primitive type of possible worlds @{type i} is used as the semantic domain of possible\nworlds @{typ W} and the primitive actual world @{term \"dw\"} as the semantic actual world\n@{term \"w\\<^sub>0\"} (see~\\ref{TAO_Semantics_Semantics_Actual_World}).\n\n\\begin{remark}\nAlthough the definitions for semantic domains and denotations may seem redundant, conceptually\nthe abstract types of the representation layer now have the role of primitive types. Although for\nsimplicity the last section regarded the type @{type \\<o>} as synonym of \\mbox{@{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}}, it was\nintroduced as a distinct type for which the set of all functions of type \\mbox{@{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}} merely\nserves as the underlying set of representatives. An object of type @{type \\<o>} cannot directly be\nsubstituted for a variable of type \\mbox{@{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}}. To do so it first has to be mapped to its\nrepresentative of type \\mbox{@{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}} by the use of the morphism @{term \"eval\\<o>\"} that was introduced\nin the type definition and omitted in the last section for the sake of readability. Therefore although\nthe definitions of the semantic domains and denotation functions may seem superfluous, the domains are\ndifferent types than the corresponding abstract type and the denotation functions are functions between\ndistinct types (note the use of @{theory_text \"lift_definition\"} rather than @{theory_text \"definition\"} \nfor the denotation functions in~\\ref{TAO_Semantics_Semantics_Denotations} that allows to define\nfunctions on abstract types in the terms of the underlying representation types).\n\\end{remark}\n\n\\<close>"], ["", "subsection\\<open>Exemplification and Encoding Extensions\\<close>"], ["", "text\\<open>\nSemantic truth conditions for exemplification formulas are defined using \\emph{exemplification extensions}.\nExemplification extensions are functions relative to\nsemantic possible worlds that map objects in the domain of \\<open>n\\<close>-place relations to meta-logical truth\nvalues in the case \\mbox{\\<open>n = 0\\<close>} and sets of \\<open>n\\<close>-tuples of objects in the domain\nof individuals in the case \\mbox{\\<open>n \\<ge> 1\\<close>}. Formally they are defined as follows\n(see~\\ref{TAO_Semantics_Semantics_Exemplification_Extensions}):\n\n\\begin{itemize}\n  \\item @{thm[display] ex0_def[expand2, of p w]}\n  \\item @{thm[display] ex1_def[expand2, of F w]}\n  \\item @{thm[display] ex2_def[expand2, of R w]}\n  \\item @{thm[display] ex3_def[expand2, of R w]}\n\\end{itemize}\n\nThe exemplification extension of a \\<open>0\\<close>-place relation is its evaluation for the actual state and the\ngiven possible world. The exemplification extension of \\<open>n\\<close>-place relations \\mbox{(\\<open>n \\<ge> 1\\<close>)}\nin a possible world is the set of all (tuples of) \\emph{individuals} that are mapped to\n\\emph{urelements} for which the relation evaluates to true for the given possible world and the\nactual state. This is in accordance with the constructed Aczel-model (see~\\ref{hyper-aczel-model}).\n\nConceptually, exemplification extensions as maps to sets of \\emph{individuals} are independent of the underlying\nmodel and in particular do not require the concept of \\emph{urelements} as they are present in an\nAczel-model. Their use in the definition of truth conditions for exemplification formulas below\nis therefore an abstraction away from the technicalities of the representation layer.\n\nSimilarly to the exemplification extension for one-place relations an \\emph{encoding extension}\nis defined as follows (see~\\ref{TAO_Semantics_Semantics_Encoding_Extension}):\n\n\\begin{center}\n  @{thm en_def[expand1, of F]}\n\\end{center}\n\nThe encoding extension of a relation is defined as the set of all abstract objects that contain\nthe relation. Since encoding is modally rigid the encoding extension does not need to be relativized\nfor possible worlds.\n\\<close>"], ["", "subsection\\<open>Truth Conditions of Formulas\\<close>"], ["", "text\\<open>\n\nBased on the definitions above it is now possible to define truth conditions\nfor the atomic formulas of the language.\n\nFor exemplification formulas of \\<open>n\\<close>-place relations\nit suffices to consider the case of one-place relations, for which the truth condition is defined\nas follows (see~\\ref{TAO_Semantics_Semantics_Exemplification}):\n\n\\begin{center}\n  @{thm T1_1[of w \"embedded_style \\<Pi>\" \"embedded_style \\<kappa>\"]}\n\\end{center}\n\nThe relation term @{term \"embedded_style \\<Pi>\"} is exemplified by an individual term @{term \"embedded_style \\<kappa>\"} in a possible world\n@{term \"w\"} if both terms have a denotation and the denoted individual is contained in the exemplification\nextension of the denoted relation in @{term \"w\"}. The definitions for \\<open>n\\<close>-place relations\n\\mbox{(\\<open>n > 1\\<close>)} and \\<open>0\\<close>-place relations are analog.\n\nThe truth condition for encoding formulas is defined in a similar manner\n(see~\\ref{TAO_Semantics_Semantics_Encoding}):\n\n\\begin{center}\n  @{thm T2[of w \"embedded_style \\<kappa>\" \"embedded_style \\<Pi>\"]}\n\\end{center}\n\nThe only difference to exemplification formulas is that the encoding extension does not depend\non the possible world @{term \"w\"}.\n\nThe truth conditions for complex formulas are straightforward\n(see~\\ref{TAO_Semantics_Semantics_Complex_Formulas}):\n\n\\begin{itemize}\n  \\item @{thm[display] T4[of w \\<psi>]}\n  \\item @{thm[display] T5[of w \\<psi> \\<chi>]}\n  \\item @{thm[display] T6[of w \\<psi>]}\n  \\item @{thm[display] T7[of w \\<psi>]}\n  \\item @{thm[display] T8_\\<nu>[of w \\<psi>]}\n  \\item @{thm[display] T8_0[of w \\<psi>]}\n  \\item @{thm[display] T8_1[of w \\<psi>]}\n  \\item @{thm[display] T8_2[of w \\<psi>]}\n  \\item @{thm[display] T8_3[of w \\<psi>]}\n\\end{itemize}\n\nA negation formula @{term \"embedded_style (\\<^bold>\\<not>\\<psi>)\"} is semantically true in a possible world, if and only if\n@{term \"embedded_style \\<psi>\"} is not semantically true in the given possible world. Similarly truth conditions for\nimplication formulas and quantification formulas are defined canonically.\n\nThe truth condition of the modal box operator @{term \"embedded_style (\\<^bold>\\<box>\\<psi>)\"} as @{term \"embedded_style \\<psi>\"} being true in all\npossible worlds, shows that modality follows a S5 logic. A formula involving the actuality operator @{term \"embedded_style (\\<^bold>\\<A>\\<psi>)\"}\nis defined to be semantically true, if and only if @{term \"embedded_style \\<psi>\"} is true in the designated actual world.\n\n\\<close>"], ["", "subsection\\<open>Denotation of Definite Descriptions\\<close>"], ["", "text\\<open>\n\nThe definition of the denotation of description terms (see~\\ref{TAO_Semantics_Semantics_Descriptions})\ncan be presented in a more readable form by splitting it into its two cases and by using the meta-logical\nquantifier for unique existence:\n\\begin{itemize}\n  \\item @{lemma[display] \"(\\<exists>!x. [\\<psi> x in w\\<^sub>0])\n            \\<Longrightarrow> d\\<^sub>\\<kappa> (embedded_style (\\<^bold>\\<iota>x. \\<psi> x)) = Some (THE x. [\\<psi> x in w\\<^sub>0])\"\n    by (auto simp: embedded_style_def D3)}\n  \\item @{lemma[display] \"\\<not>(\\<exists>!x. [\\<psi> x in w\\<^sub>0])\n            \\<Longrightarrow> d\\<^sub>\\<kappa> (embedded_style (\\<^bold>\\<iota>x. \\<psi> x)) = None\"\n    by (auto simp: embedded_style_def D3)}\n\\end{itemize}\n\nIf there exists a unique @{term \"x\"}, such that @{term \"embedded_style (\\<psi> x)\"} is true in the actual world,\nthe definite description denotes and its denotation is this unique @{term \"x\"}. Otherwise\nthe definite description fails to denote.\n\nIt is important to consider what happens if a non-denoting definite description occurs in a formula:\nThe only positions in which such a term could occur in a complex formula is in an exemplification expression\nor in an encoding expression. Given the above truth conditions it becomes clear, that\nthe presence of non-denoting terms does \\emph{not} mean that there are formulas without\ntruth conditions: Since exemplification and encoding formulas are defined to be true \\emph{only if}\nthe contained individual terms have denotations, such formulas are @{term \"False\"} for non-denoting\nindividual terms.\n\n\\<close>"], ["", "subsection\\<open>Denotation of $\\lambda$-Expressions\\<close>"], ["", "text\\<open>\n\n\\label{semantics-lambda}\n\nThe most complex part of the semantic abstraction is the definition of denotations for \\<open>\\<lambda>\\<close>-expressions.\nThe formal semantics of PLM is split into several cases and uses a special class of\n\\emph{Hilbert-Ackermann \\<open>\\<epsilon>\\<close>-terms} that are challenging to represent. Therefore a simplified\nformulation of the denotation criteria is used. Moreover the denotations of \\<open>\\<lambda>\\<close>-expressions are\ncoupled to syntactical conditions. This fact is represented using the notion of \\emph{proper maps}\nas a restriction for the matrix of a \\<open>\\<lambda>\\<close>-expression that was introduced in section~\\ref{lambda-expressions}.\nThe definitions are implemented as follows (see~\\ref{TAO_Semantics_Semantics_Lambda_Expressions}):\n\n\\begin{itemize}\n  \\item @{lemma[display] \"d\\<^sub>1 (embedded_style (\\<^bold>\\<lambda>x. \\<lparr>\\<Pi>, x\\<^sup>P\\<rparr>)) = d\\<^sub>1 (embedded_style \\<Pi>)\"\n          by (simp add: embedded_style_def D4_1)}\n  \\item @{lemma[display] \"IsProperInX (embedded_style \\<phi>) \\<Longrightarrow> Some r = d\\<^sub>1 (embedded_style (\\<^bold>\\<lambda>x. \\<phi> (x\\<^sup>P)))\n          \\<and> Some o\\<^sub>1 = d\\<^sub>\\<kappa> (embedded_style x) \\<longrightarrow> (o\\<^sub>1 \\<in> ex1 r w) = [\\<phi> x in w]\"\n          by (simp add: embedded_style_def D5_1)}\n  \\item @{lemma[display] \"Some r = d\\<^sub>0 (embedded_style (\\<^bold>\\<lambda>\\<^sup>0 \\<phi>)) \\<longrightarrow> ex0 r w = [\\<phi> in w]\"\n    by (simp add: embedded_style_def D6)}\n\\end{itemize}\n\nThe first condition for \\emph{elementary} \\<open>\\<lambda>\\<close>-expressions is straightforward.\nThe general case in the second condition is more complex: Given that the matrix @{term \"embedded_style \\<phi>\"}\nis a proper map, the relation denoted by the \\<open>\\<lambda>\\<close>-expression has the property, that for a\ndenoting individual term @{term \"embedded_style x\"}, the denoted individual is contained in\nits exemplification extension for a possible world @{term \"w\"}, if and only if @{term \"embedded_style (\\<phi> x)\"}\nholds in @{term \"w\"}.\nAt a closer look this is the statement of \\<open>\\<beta>\\<close>-conversion restricted to denoting individuals:\nthe truth condition of the \\<open>\\<lambda>\\<close>-expression being exemplified by some denoting individual term,\nis the same as the truth condition of the matrix of the term for the denoted individual.\nTherefore it is clear that the precondition that @{term \"embedded_style \\<phi>\"} is a proper map\nis necessary and sufficient.\nGiven this consideration the case for \\<open>0\\<close>-place relations is straightforward and\nthe cases for \\mbox{\\<open>n \\<ge> 2\\<close>} are analog to the case \\mbox{\\<open>n = 1\\<close>}.\n\n\\<close>"], ["", "subsection\\<open>Properties of the Semantics\\<close>"], ["", "text\\<open>\n\n  The formal semantics of PLM imposes several further restrictions some of which are derived as\n  auxiliary lemmas. Furthermore some auxiliary statements that are specific to the underlying\n  representation layer are proven.\n\n  The following auxiliary statements are derived (see~\\ref{TAO_Semantics_Semantics_Auxiliary_Lemmata}):\n  \\begin{enumerate}\n    \\item All relations denote, e.g. @{thm[display] propex\\<^sub>1[of \"embedded_style F\"]}\n    \\item An individual term of the form @{term \"embedded_style (x\\<^sup>P)\"} denotes @{term \"x\"}:\n          @{lemma[display] \"d\\<^sub>\\<kappa> (embedded_style (x\\<^sup>P)) = Some x\"\n            by (simp add: embedded_style_def d\\<^sub>\\<kappa>_proper)}\n    \\item Every ordinary object is contained in the extension of the concreteness property for some\n          possible world:\n          @{lemma[display] \"Some r = d\\<^sub>1 (embedded_style (E!)) \\<Longrightarrow> (\\<forall> x . \\<exists> w . \\<omega>\\<nu> x \\<in> ex1 r w)\"\n            by (simp add: embedded_style_def ConcretenessSemantics1)}\n    \\item An object that is contained in the extension of the concreteness property in any world is\n          an ordinary object:\n          @{lemma[display] \"Some r = d\\<^sub>1 (embedded_style (E!)) \\<Longrightarrow> (\\<forall> x . x \\<in> ex1 r w \\<longrightarrow> (\\<exists> y . x = \\<omega>\\<nu> y))\"\n            by (simp add: embedded_style_def ConcretenessSemantics2)}\n    \\item The denotation functions for relation terms are injective, e.g.\n          @{thm[display] d\\<^sub>1_inject[of \"embedded_style F\" \"embedded_style G\"]}\n    \\item The denotation function for individual terms is injective for denoting terms:\n          @{thm[display] d\\<^sub>\\<kappa>_inject[of \"o\\<^sub>1\" \"embedded_style x\" \"embedded_style y\"]}\n  \\end{enumerate}\n\n  Especially statements 5 and 6 are only derivable due to the specific construction of\n  the representation layer: since the semantic domains were defined as the representation sets\n  of the respective abstract types and denotations were defined canonically, objects that have the\n  same denotation are identical as objects of the abstract type. 3 and 4 are necessary to connect\n  concreteness with the underlying distinction between ordinary and abstract objects in the model.\n\\<close>"], ["", "subsection\\<open>Proper Maps\\<close>"], ["", "text\\<open>\n  The definition of \\emph{proper maps} as described in section~\\ref{lambda-expressions} is\n  formulated in terms of the meta-logic. Since denotation conditions in the semantics and\n  later some of the axioms have to be restricted to proper maps, a method has to be devised\n  by which the propriety of a map can easily be shown without using meta-logical concepts.\n\n  Therefore introduction rules for @{term \"IsProperInX\"}, @{term \"IsProperInXY\"} and\n  @{term \"IsProperInXYZ\"} are derived and a proving method @{method[names_short = true] \"show_proper\"}\n  is defined that can be used to proof the propriety of a map using these introduction rules\n  (see~\\ref{TAO_Semantics_Proper}).\n\n  The rules themselves rely on the power of the \\emph{unifier} of Isabelle/HOL: Any map acting\n  on individuals that can be expressed by another map that solely acts on exemplification expressions\n  involving the individuals, is shown to be proper. This effectively means that all maps whose arguments\n  only appear in exemplification expressions are proper. Using the provided introduction rules\n  Isabelle's unifier can derive the propriety of such maps automatically.\n\n  For a discussion about the relation between\n  this concept and admissible \\<open>\\<lambda>\\<close>-expressions in PLM see section~\\ref{differences-lambda}.\n\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context Semantics *)\n(*>*)"], ["", "section\\<open>General All-Quantifier\\<close>"], ["", "text\\<open>\n  \\label{general-quantifier}\n\n  Since the last section established the semantic truth conditions of the specific versions of the\n  all-quantifier for all variable types of PLM, it is now possible to define a binding symbol for general\n  all-quantification.\n\n  This is done using the concept of \\emph{type classes} in Isabelle/HOL. Type classes define\n  constants that depend on a \\emph{type variable} and state assumptions about this constant.\n  In subsequent reasoning the type of an object can be restricted to a type of the introduced\n  type class. Thereby the reasoning can make use of all assumptions that have been stated about\n  the constants of the type class. A priori it is not assumed that any type actually satisfies\n  the requirements of the type class, so initially statements involving types restricted\n  to a type class can not be applied to any specific type.\n\n  To allow that the type class has to be \\emph{instantiated} for the desired type. This is done\n  by first providing definitions for the constants of the type class specific to the\n  respective type. Then each assumption made by the type class has to be proven given the\n  particular type and the provided definitions. After that any statement that was proven for\n  the type class can be applied to the instantiated type.\n\n  In the case of general all-quantification for the embedding this concept can be utilized by\n  introducing the type class @{class quantifiable} that is equipped with a constant that is used\n  as the general all-quantification binder (see~\\ref{TAO_Quantifiable_Class}).\n  For this constant it can now be assumed that it satisfies the semantic property of all\n  quantification: \\mbox{@{thm quantifiable_T8[of w \\<psi>]}}.\n\n  Since it was already shown in the last section that the specific all-quantifier for each\n  variable type satisfies this property, the type class can immediately be instantiated for the\n  types @{type \\<nu>}, @{type \\<Pi>\\<^sub>0}, @{type \\<Pi>\\<^sub>1}, @{type \\<Pi>\\<^sub>2} and @{type \\<Pi>\\<^sub>3} (see~\\ref{TAO_Quantifiable_Instantiations}).\n  The instantiation proofs only need to refer to the statements derived in the semantics section for the respective version\n  of the quantifier and are thereby independent of the representation layer.\n\n  From this point onward the general all-quantifier can completely replace the type specific\n  quantifiers. This is true even if a quantification is meant to only range over objects of a\n  particular type: In this case the desired type (if it can not implicitly be deduced from the\n  context) can be stated explicitly while still using the general quantifier.\n\n  \\begin{remark}\n    Technically it would be possible to instantiate the type class @{class quantifiable} for\n    any other type that satisfies the semantic criterion, thereby compromising the restriction\n    of the all-quantifier to the primitive types of PLM. However, this is not done in the\n    embedding and therefore the introduction of a general quantifier using a type class is\n    considered a reasonable compromise.\n  \\end{remark}\n\n\\<close>"], ["", "section\\<open>Derived Language Elements\\<close>"], ["", "text\\<open>\n  The language of the embedded logic constructed so far is limited to a minimal set of\n  primitive elements. This section introduces further derived language elements that are\n  defined directly in the embedded logic.\n\n  Notably identity is not part of the primitive language, but introduced as a \\emph{defined}\n  concept.\n\\<close>"], ["", "subsection\\<open>Connectives\\<close>"], ["", "text\\<open>\n  The remaining classical connectives and the modal diamond operator are defined in the traditional manner\n  (see~\\ref{TAO_BasicDefinitions_DerivedConnectives}):\n  \\begin{itemize}\n    \\item @{thm[display] conj_def[expand2, THEN embedded_eq, of \\<phi> \\<psi>]}\n    \\item @{thm[display] disj_def[expand2, THEN embedded_eq, of \\<phi> \\<psi>]}\n    \\item @{thm[display] equiv_def[expand2, THEN embedded_eq, of \\<phi> \\<psi>]}\n    \\item @{thm[display] diamond_def[expand1, THEN embedded_eq, of \\<phi>]}\n  \\end{itemize}\n\n  Furthermore, the general all-quantifier is supplemented by an existential quantifier as follows:\n  \\begin{itemize}\n    \\item @{thm[display] exists_def[expand1, of \\<phi>, THEN embedded_eq, rename_abs \\<alpha>]}\n  \\end{itemize}\n\\<close>"], ["", "subsection\\<open>Identity\\<close>"], ["", "text\\<open>\n  The definitions for identity are stated separately for each type of term\n  (see~\\ref{TAO_BasicDefinitions_Identity}):\n\n  \\begin{itemize}\n    \\item @{thm[display] basic_identity\\<^sub>E_infix_def[unfolded basic_identity\\<^sub>E_def, THEN embedded_def, of x y]}\n    \\item @{thm[display] basic_identity\\<^sub>1_def[expand2, of F G, rename_abs x, THEN embedded_eq]}\n    \\item @{thm[display] basic_identity\\<^sub>2_def[expand2, of F G, rename_abs x, THEN embedded_eq]}\n    \\item @{thm basic_identity\\<^sub>3_def[expand2, of F G, rename_abs x y, THEN embedded_eq]}\n    \\item @{thm basic_identity\\<^sub>0_def[expand2, of p q, rename_abs x x, THEN embedded_eq]}\n  \\end{itemize}\n\n  Similarly to the general all-quantifier it makes sense to introduce a general identity\n  relation for all types of terms (@{type \\<kappa>}, @{type \\<o>} resp. @{typ \\<Pi>\\<^sub>0}, @{typ \\<Pi>\\<^sub>1}, @{typ \\<Pi>\\<^sub>2}, @{typ \\<Pi>\\<^sub>3}).\n  However, whereas all-quantification is characterized by a semantic criterion that can\n  be generalized in a type class, identity is defined independently for each type. Therefore a general\n  identity symbol will only be introduced in section~\\ref{general-identity},\n  since it will then be possible to formulate and prove a reasonable property shared\n  by the identity of all types of terms.\n\\<close>"], ["", "(*<*)"], ["", "context MetaSolver\nbegin"], ["", "(*>*)"], ["", "section\\<open>The Proving Method meta\\_solver\\<close>"], ["", "text\\<open>\\label{meta_solver}\\<close>"], ["", "subsection\\<open>General Concept\\<close>"], ["", "text\\<open>\n\n  Since the semantics in section~\\ref{semantics} constructed a first abstraction on top of the\n  representation layer, it makes sense to revisit the general concept of the layered structure\n  of the embedding.\n\n  The idea behind this structure is that reasoning in subsequent layers should - as far as possible - only\n  rely on the previous layer. However, the restriction of proofs to a specific subset of the facts\n  that are valid in the global context can be cumbersome for automated reasoning. While it is possible\n  to restrict automated reasoning tools to only consider specific sets of facts, it is still an\n  interesting question whether the process of automated reasoning in the layered approach can be made easier.\n\n  To that end the embedding utilizes the Isabelle package \\emph{Eisbach}. This package allows to conveniently\n  define new proving methods that are based on the systematic application of existing methods.\n  \n  \\begin{remark}\n    The Eisbach package even allows the construction of more complex proving methods that involve\n    pattern matching. This functionality is utilized in the construction of a substitution method as\n    described in section~\\ref{substitution-method}.\n  \\end{remark}\n\n  The idea is to construct a simple resolution prover that can deconstruct complex\n  formulas of the embedded logic to simpler formulas that are connected by a relation in the meta-logic\n  as required by the semantics.\n\n  For example an implication formula can be deconstructed as follows:\n  \\begin{center}\n    @{thm ImplS[of v \\<phi> \\<psi>]}\n  \\end{center}\n\n  Whereas the basic proving methods available in Isabelle cannot immediately prove\n  \\mbox{@{lemma \"[\\<phi> \\<^bold>\\<rightarrow> \\<phi> in v]\" by (simp add: ImplS)}} without any facts about the definitions of\n  validity and implication, they \\emph{can} prove \\mbox{@{lemma \"[\\<phi> in v] \\<longrightarrow> [\\<phi> in v]\" by simp}}\n  directly as an instance of \\mbox{@{lemma \"p \\<longrightarrow> p\" by simp}}.\n\\<close>"], ["", "subsection\\<open>Implementation\\<close>"], ["", "text\\<open>\n  Following this idea the method @{method meta_solver} is introduced (see~\\ref{TAO_MetaSolver})\n  that repeatedly applies rules like the above in order to translate complex formulas of the embedded logic\n  to meta-logical statements involving simpler formulas.\n\n  The formulation of appropriate introduction, elimination and substitution rules for the logical\n  connectives and quantifiers is straightforward. Beyond that the concept can be used to\n  resolve exemplification and encoding formulas to their semantic truth conditions as well,\n  e.g. (see~\\ref{TAO_MetaSolver_Encoding}):\n  \\begin{center}\n    @{thm Exe1S[of v F x]}\n  \\end{center}\n\n  This way a large set of formulas can be decomposed to semantic expressions that can be automatically\n  proven without having to rely on the meta-logical definitions directly.\n\n  Additionally the @{method meta_solver} is equipped with rules for\n  being abstract and ordinary and for the defined identity.\n\n  Notably the representation layer has the property that the defined identities are equivalent to\n  the identity in the meta-logic. Formally the following statements are true and derived as rules\n  for the @{method meta_solver}:\n\n  \\begin{itemize}\n    \\item @{thm[display] Eq\\<^sub>ES[of v \"embedded_style x\" \"embedded_style y\"]}\n    \\item @{thm[display] Eq\\<kappa>S[of v \"embedded_style x\" \"embedded_style y\"]}\n    \\item @{thm[display] Eq\\<^sub>1S[of v \"embedded_style F\" \"embedded_style G\"]}\n    \\item @{thm[display] Eq\\<^sub>2S[of v \"embedded_style F\" \"embedded_style G\"]}\n    \\item @{thm[display] Eq\\<^sub>3S[of v \"embedded_style F\" \"embedded_style G\"]}\n    \\item @{thm[display] Eq\\<^sub>0S[of v \"embedded_style F\" \"embedded_style G\"]}\n  \\end{itemize}\n\n  The proofs for these facts (see~\\ref{TAO_MetaSolver_Identity}) are complex and do not\n  solely rely on the properties of the formal semantics of PLM.\n\n  The fact that they are derivable has a distinct advantage: since identical terms\n  in the sense of PLM are identical in the meta-logic, proving the axiom of\n  substitution (see~\\ref{axioms-identity}) is trivial.\n  A derivation that is solely based on the semantics on the other hand, would require a complex\n  induction proof. For this reason it is considered a reasonable compromise to include these statements\n  as admissible rules for the @{method meta_solver}. However, future work may attempt to enforce\n  the separation of layers more strictly and consequently abstain from these rules.\n\n  \\begin{remark}\n    Instead of introducing a custom proving method using the Eisbach package, a similar\n    effect could be achieved by instead supplying the derived introduction, elimination and substitution\n    rules directly to one of the existing proving methods like @{method auto} or @{method clarsimp}.\n    In practice, however, we found that the custom @{method meta_solver} produces more reliable\n    results, especially in the case that a proving objective cannot be solved completely by the supplied rules.\n    Moreover the constructed custom proving method serves as a proof of concept\n    and may inspire the development of further more complex proving methods that go beyond a simple\n    resolution prover in the future.\n  \\end{remark}\n\\<close>"], ["", "subsection\\<open>Applicability\\<close>"], ["", "(*<*)"], ["", "context\nbegin"], ["", "interpretation PLM"], ["proof (prove)\ngoal:\nNo subgoals!", "."], ["", "(*>*)"], ["", "text\\<open>\n  Given the discussion above and keeping the layered structure of the embedding in mind, it is\n  important to precisely determine for which purposes it is valid to use the constructed\n  @{method meta_solver}.\n\n  The main application of the method in the embedding is to support the derivation of the axiom\n  system as described in section~\\ref{axioms}. Furthermore the @{method meta_solver} can aid in examining the\n  meta-logical properties of the embedding. The @{method meta_solver} is only supplied with rules that\n  are \\emph{reversible}. Thereby it is justified to use it to simplify a statement\n  before employing a tool like @{theory_text \"nitpick\"} in order to look for models or\n  counter-models for a statement.\n\n  However it is \\emph{not} justified to assume that a theorem that can be proven with the aid of the\n  @{method meta_solver} method is derivable in the formal system of PLM, since\n  the result still depends on the specific structure of the representation layer. However,\n  based on the concept of the @{method meta_solver} another proving method is\n  introduced in section~\\ref{PLM-solver}, namely the @{method PLM_solver}. This proving method\n  only employs rules that are derivable from the formal system of PLM itself. Thereby this method\n  \\emph{can} be used in proofs without sacrificing the universality of the result.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* anonymous context interpreting the PLM locale *)"], ["", "end"], ["", "(* context MetaSolver *)\n(*>*)"], ["", "section\\<open>General Identity Relation\\<close>"], ["", "text\\<open>\n  \\label{general-identity}\n\n  As already mentioned in section~\\ref{general-quantifier} similarly to the general quantification\n  binder it is desirable to introduce a general identity relation.\n\n  Since the identity of PLM is not directly characterized by semantic truth conditions, but instead\n  \\emph{defined} using specific complex formulas in the embedded logic for each type of term,\n  some other property has to be found that is shared by the respective definitions and can reasonably\n  be used as the condition of a type class.\n\n  A natural choice for such a condition is the axiom of the substitution of identicals\n  (see~\\ref{axioms-identity}). The axiom states that if two objects are identical (in the sense of the defined\n  identity of PLM), then a formula involving the first object implies the formula resulting from\n  substituting the second object for the first object. This inspires the following condition for\n  the type class @{class identifiable} (see~\\ref{TAO_Identifiable_Class}):\n\n  \\begin{center}\n    @{thm identifiable_class.l_identity[of v \\<alpha> \\<beta> \\<phi>]}\n  \\end{center}\n\n  Using the fact that in the last section it was already derived, that the defined identity\n  in the embedded-logic for each term implies the primitive identity of the meta-logical objects,\n  this type class can be instantiated for all types of terms: @{type \\<kappa>}, @{typ \\<Pi>\\<^sub>0} resp. @{type \\<o>},\n  @{type \\<Pi>\\<^sub>1}, @{type \\<Pi>\\<^sub>2}, @{type \\<Pi>\\<^sub>3} (see~\\ref{TAO_Identifiable_Instantiation}).\n\n  Since now general quantification and general identity are available, an additional quantifier\n  for unique existence can be introduced (such a quantifier involves both quantification and identity).\n  To that end a derived type class is introduced that is the combination of the @{class quantifiable}\n  and the @{class identifiable} classes. Although this is straightforward for the relation types,\n  this reveals a subtlety involving the distinction between individuals of type @{type \\<nu>} and\n  individual terms of type @{type \\<kappa>}: The type @{type \\<nu>} belongs to the class @{class quantifiable},\n  the type @{type \\<kappa>} on the other hand does not: no quantification over individual \\emph{terms}\n  (that may not denote) was defined. On the other hand the class @{class identifiable} was only\n  instantiated for the type @{type \\<kappa>}, but not for the type @{type \\<nu>}.\n  This issue can be solved by noticing that it is straightforward and\n  justified to define an identity for @{type \\<nu>} as follows:\n\n  \\begin{center}\n    @{thm identity_\\<nu>_def[expand2, of x y, THEN embedded_eq]}\n  \\end{center}\n\n  This way type @{type \\<nu>} is equipped with both the general all-quantifier and the general identity\n  relation and unique existence can be defined for all variable types as expected:\n\n  \\begin{center}\n    @{thm exists_unique_def[expand1, of \\<phi>, THEN embedded_eq]}\n  \\end{center}\n\n  Another subtlety has to be considered: at times it is necessary to expand the definitions\n  of identity for a specific type to derive statements in PLM. Since the defined identities were\n  introduced prior to the general identity symbol, such an expansion is therefore so far not possible\n  for a statement that uses the general identity, even if the types are fixed in the context.\n\n  To allow such an expansion the definitions of identity are equivalently restated for the general\n  identity symbol and each specific type (see~\\ref{TAO_Identifiable_Definitions}). This way\n  the general identity can from this point onward completely replace the type-specific identity\n  symbols.\n\n\\pagebreak\n\n\\<close>"], ["", "(*<*)"], ["", "context Axioms\nbegin"], ["", "(*>*)"], ["", "section\\<open>The Axiom System of PLM\\<close>"], ["", "text\\<open>\n  \\label{axioms}\n\n  The last step in abstracting away from the representation layer is the derivation of the\n  axiom system of PLM. Conceptionally the\n  derivation of the axioms is the last moment in which it is deemed admissible to rely\n  on the meta-logical properties of the underlying model structure. Future work may even\n  restrict this further to only allow the use of the properties of the semantics in the\n  proofs (if this is found to be possible).\n\n  To be able to distinguish between the axioms and other statements and theorems in the\n  embedded logic they are stated using a dedicated syntax (see~\\ref{TAO_Axioms}):\n  \\begin{center}\n    @{thm axiom_def[expand1, of \\<phi>]}\n  \\end{center}\n\n  Axioms are unconditionally true in all possible worlds. The only exceptions are\n  \\emph{necessitation-averse}, resp. \\emph{modally-fragile} axioms\\footnote{Currently PLM uses\n  only one such axiom, see~\\ref{axioms-actuality}.}. Such axioms are stated using the following syntax:\n  \\begin{center}\n    @{thm actual_validity_def[expand1, of \\<phi>]}\n  \\end{center}\n\n\\<close>"], ["", "subsection\\<open>Axioms as Schemata\\<close>"], ["", "text\\<open>\n  \\label{axiom-schemata}\n\n  Most of the axioms in PLM are stated as \\emph{axiom schemata}. They use variables that range over\n  and can therefore be instantiated for any formula and term.\n  Furthermore PLM introduces the notion of \\emph{closures} (see~@{cite \\<open>(\\ref{PM-closures})\\<close> PM}). Effectively this means\n  that the statement of an axiom schema implies that the universal generalization of the schema,\n  the actualization of the schema and (except for modally-fragile axioms) the necessitation of the\n  schema is also an axiom.\n\n  Since in Isabelle/HOL free variables in a theorem already range over all terms of the same type\n  no special measures have to be taken to allow instantiations for arbitrary terms. The concept of\n  closures is introduced using the following rules (see~\\ref{TAO_Axioms_Closures}):\n\n  \\begin{itemize}\n    \\item @{thm[display] axiom_instance[of \\<phi> v]}\n    \\item @{thm[display] closures_universal[of \\<phi>]}\n    \\item @{thm[display] closures_actualization[of \\<phi>]}\n    \\item @{thm[display] closures_necessitation[of \\<phi>]}\n  \\end{itemize}\n\n  For modally-fragile axioms only the following rules are introduced:\n\n  \\begin{itemize}\n    \\item @{thm[display] necessitation_averse_axiom_instance[of \\<phi>]}\n    \\item @{thm[display] necessitation_averse_closures_universal[of \\<phi>]}\n  \\end{itemize}\n\n  \\begin{remark}\n    To simplify the instantiation of the axioms in subsequent proofs,\n    a set of \\emph{attributes} is defined that can be used to transform\n    the statement of the axioms using the rules defined above.\n\n    This way for example the axiom \\mbox{@{thm qml_2}} can be directly transformed\n    to \\mbox{@{thm qml_2[axiom_universal, axiom_instance, of v \\<phi>]}} by not referencing\n    it directly as @{theory_text qml_2}, but by applying the defined attributes\n    to it: @{theory_text \"qml_2[axiom_universal, axiom_instance]\"}\n  \\end{remark}\n\\<close>"], ["", "subsection\\<open>Derivation of the Axioms\\<close>"], ["", "text\\<open>\n  To simplify the derivation of the axioms a proving method @{method axiom_meta_solver} is introduced, that\n  unfolds the dedicated syntax, then applies the meta-solver and if possible resolves\n  the proof objective automatically.\n\n  Most of the axioms can be derived by the @{method axiom_meta_solver} directly.\n  Some axioms, however, require more verbose proofs or their representation in the functional\n  setting of Isabelle/HOL requires special attention.\n  Therefore in the following the complete axiom system is listed and discussed in\n  detail where necessary. Additionally each axiom is associated with the numbering in\n  the current draft of PLM@{cite PM}.\n\\<close>"], ["", "subsection\\<open>Axioms for Negations and Conditionals\\<close>"], ["", "text\\<open>\n  The axioms for negations and conditionals can be derived automatically and\n  present no further issues (see~\\ref{TAO_Axioms_NegationsAndConditionals}):\n\n  \\begin{itemize}\n    \\item @{thm pl_1} \\hfill{(\\ref{PM-pl}.1)}\n    \\item @{thm pl_2} \\hfill{(\\ref{PM-pl}.2)}\n    \\item @{thm pl_3} \\hfill{(\\ref{PM-pl}.3)}\n  \\end{itemize}\n\n\\<close>"], ["", "subsection\\<open>Axioms of Identity\\<close>"], ["", "text\\<open>\n  \\label{axioms-identity}\n\n  The axiom of the substitution of identicals can be proven automatically,\n  if additionally supplied with the defining assumption of the type class\n  @{class identifiable}. The statement is the following (see~\\ref{TAO_Axioms_Identity}):\n\n  \\begin{itemize}\n    \\item @{thm l_identity} \\hfill{(\\ref{PM-l-identity})}\n  \\end{itemize}\n\\<close>"], ["", "subsection\\<open>Axioms of Quantification\\<close>"], ["", "text\\<open>\n  \\label{quantification-axioms}\n\n  The axioms of quantification are formulated in a way that differs from the statements in\n  PLM, as follows (see~\\ref{TAO_Axioms_Quantification}):\n\n  \\begin{itemize}\n    \\item @{thm cqt_1[of \\<phi> \\<tau>]} \\hfill{(\\ref{PM-cqt}.1a)}\n    \\item @{thm cqt_1_\\<kappa>[of \\<phi> \\<tau>]} \\hfill{(\\ref{PM-cqt}.1b)}\n    \\item @{thm cqt_3} \\hfill{(\\ref{PM-cqt}.3)}\n    \\item @{thm cqt_4} \\hfill{(\\ref{PM-cqt}.4)}\n    \\item @{thm cqt_5[of \\<psi> \\<phi>, rename_abs x \\<nu> x]} \\hfill{(\\ref{PM-cqt}.5a)}\n    \\item @{thm cqt_5_mod[of \\<psi> \\<tau>, rename_abs \\<nu>]} \\hfill{(\\ref{PM-cqt}.5b)}\n  \\end{itemize}\n\n  The original axioms in PLM\\footnote{Note that the axioms\n  will in all likelihood be adjusted in future versions of PLM in order to prevent the paradox\n  described in section~\\ref{paradox}.} are the following:\n\n  \\begin{itemize}\n    \\item \\<open>\\<forall>\\<alpha>\\<phi> \\<rightarrow> (\\<exists>\\<beta>(\\<beta> = \\<tau>) \\<rightarrow> \\<phi>\\<^sup>\\<tau>\\<^sub>\\<alpha>)\\<close> \\hfill{(\\ref{PM-cqt}.1)}\n    \\item \\<open>\\<exists>\\<beta>(\\<beta> = \\<tau>)\\<close>, provided \\<open>\\<tau>\\<close> is not a description and \\<open>\\<beta>\\<close> doesn't occur free in \\<open>\\<tau>\\<close>.\\hfill{(\\ref{PM-cqt}.2)}\n    \\item \\<open>\\<forall>\\<alpha>(\\<phi> \\<rightarrow> \\<psi>) \\<rightarrow> (\\<forall>\\<alpha> \\<phi> \\<rightarrow> \\<forall>\\<alpha> \\<psi>)\\<close> \\hfill{(\\ref{PM-cqt}.3)}\n    \\item \\<open>\\<phi> \\<rightarrow> (\\<forall>\\<alpha> \\<phi>)\\<close>, provided \\<open>\\<alpha>\\<close> doesn't occur free in \\<open>\\<phi>\\<close> \\hfill{(\\ref{PM-cqt}.4)}\n    \\item \\<open>\\<psi>\\<^sup>\\<iota>\\<^sup>x\\<^sup>\\<phi>\\<^sub>\\<mu> \\<rightarrow> \\<exists>\\<nu> (\\<nu> = \\<iota>x\\<phi>)\\<close>, provided (a) \\<open>\\<psi>\\<close> is either an exemplification formula \\<open>\\<Pi>\\<^sup>n\\<kappa>\\<^sub>1\\<dots>\\<kappa>\\<^sub>n\\<close> (\\<open>n \\<ge> 1\\<close>)\n          or an encoding formula \\<open>\\<kappa>\\<^sub>1\\<Pi>\\<^sup>1\\<close>, (b) \\<open>\\<mu>\\<close> is an individual variable that occurs in \\<open>\\<psi>\\<close>\n          and only as one or more of the \\<open>\\<kappa>\\<^sub>i\\<close> (\\<open>1 \\<le> i \\<le> n\\<close>), and (c) \\<open>\\<nu>\\<close> is any individual variable\n          that doesn't occur free in \\<open>\\<phi>\\<close>.\\hfill{(\\ref{PM-cqt}.5)}\n  \\end{itemize}\n\n  In the embedding definite descriptions have the type @{type \\<kappa>} that is different from the\n  type for individuals @{type \\<nu>}. Quantification is only defined for @{type \\<nu>}, not for @{type \\<kappa>}.\n\n  Therefore, the restriction of (\\ref{PM-cqt}.2) does not apply, since the type restriction of\n  quantification ensures that @{term \"\\<tau>\"} cannot be a definite description.\n  Consequently the inner precondition of (\\ref{PM-cqt}.1)\n  can be dropped in (\\ref{PM-cqt}.1a) - since a quantifier is used in the\n  formulation, the problematic case of definite descriptions is excluded and the dropped\n  precondition would always hold.\n\n  The second formulation (\\ref{PM-cqt}.1b) for definite descriptions involves the type\n  conversion @{term \"embedded_style (DUMMY\\<^sup>P)\"} and keeps the inner precondition (since descriptions\n  may not denote).\n\n  (\\ref{PM-cqt}.5b) can be stated as a generalization of (\\ref{PM-cqt}.5a) to general individual\n  terms, since (\\ref{PM-cqt}.2) already implies its right hand side for every term except descriptions.\n\n  Consequently (\\ref{PM-cqt}.1b) and (\\ref{PM-cqt}.5b) can replace the original axioms\n  (\\ref{PM-cqt}.1) and (\\ref{PM-cqt}.5) for individual terms.\n  For individual variables and constants as well as relations the simplified formulation\n  (\\ref{PM-cqt}.1a) can be used instead.\n\n  Future work may want to reconsider the reformulation of the axioms, especially considering the most\n  recent developments described in section~\\ref{paradox}. At the time of writing the reformulation is\n  considered a reasonable compromise, since due to the type restrictions of the embedding the reformulated\n  version of the axioms is an equivalent representation of the original axioms.\n\n  The predicate @{term \"SimpleExOrEnc\"} used as the precondition for (\\ref{PM-cqt}.5)\n  is defined as an inductive predicate with the following introduction rules:\n\n  \\begin{itemize}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,x\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,x,DUMMY\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,DUMMY,x\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,x,DUMMY,DUMMY\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,DUMMY,x,DUMMY\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lparr>F,DUMMY,DUMMY,x\\<rparr>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}\n    \\item @{lemma[eta_contract=false] \"SimpleExOrEnc (\\<lambda>x. embedded_style \\<lbrace>x,F\\<rbrace>)\"\n            by (simp add: SimpleExOrEnc.intros embedded_style_def)}              \n  \\end{itemize}\n\n  This corresponds exactly to the restriction of @{term \"embedded_style \\<psi>\"} to an exemplification\n  or encoding formula in PLM.\n\n\\<close>"], ["", "subsection\\<open>Axioms of Actuality\\<close>"], ["", "text\\<open>\n  \\label{axioms-actuality}\n\n  As mentioned in the beginning of the section the modally-fragile axiom of actuality\n  is stated using a different syntax (see~\\ref{TAO_Axioms_Actuality}):\n\n  \\begin{itemize}\n    \\item @{thm logic_actual} \\hfill{(\\ref{PM-logic-actual})}\n  \\end{itemize}\n\n  Note that the model finding tool @{theory_text nitpick} can find a counter-model for the\n  formulation as a regular axiom, as expected.\n\n  The remaining axioms of actuality are not modally-fragile and therefore stated as regular\n  axioms:\n  \n  \\begin{itemize}\n    \\item @{thm logic_actual_nec_1} \\hfill{(\\ref{PM-logic-actual-nec}.1)}\n    \\item @{thm logic_actual_nec_2} \\hfill{(\\ref{PM-logic-actual-nec}.2)}\n    \\item @{thm logic_actual_nec_3} \\hfill{(\\ref{PM-logic-actual-nec}.3)}\n    \\item @{thm logic_actual_nec_4} \\hfill{(\\ref{PM-logic-actual-nec}.4)}\n  \\end{itemize}\n\n  All of the above can be proven automatically by the @{method axiom_meta_solver} method.\n\\<close>"], ["", "subsection\\<open>Axioms of Necessity\\<close>"], ["", "text\\<open>\n  \\label{axioms-necessity}\n\n  The axioms of necessity are the following (see~\\ref{TAO_Axioms_Necessity}):\n\n  \\begin{itemize}\n    \\item @{thm qml_1} \\hfill{(\\ref{PM-qml}.1)}\n    \\item @{thm qml_2} \\hfill{(\\ref{PM-qml}.2)}\n    \\item @{thm qml_3} \\hfill{(\\ref{PM-qml}.3)}\n    \\item @{thm qml_4} \\hfill{(\\ref{PM-qml}.4)}\n  \\end{itemize}\n\n  While the first three axioms can be derived automatically, the last axiom requires\n  special attention. On a closer look the formulation may be familiar. The axiom\n  was already mentioned in section~\\ref{concreteness} while constructing the representation\n  of the constant @{term \"embedded_style E!\"}. To be able to derive this axiom here the\n  constant was specifically axiomatized. Consequently the derivation requires\n  the use of these meta-logical axioms stated in the representation layer.\n\n\\<close>"], ["", "subsection\\<open>Axioms of Necessity and Actuality\\<close>"], ["", "text\\<open>\n  The axioms of necessity and actuality can be derived automatically\n  and require no further attention (see~\\ref{TAO_Axioms_NecessityAndActuality}):\n\n  \\begin{itemize}\n    \\item @{thm qml_act_1} \\hfill{(\\ref{PM-qml-act}.1)}\n    \\item @{thm qml_act_2} \\hfill{(\\ref{PM-qml-act}.2)}\n  \\end{itemize}\n\\<close>"], ["", "subsection\\<open>Axioms of Descriptions\\<close>"], ["", "text\\<open>\n  There is only one axiom dedicated to descriptions (note, however, that descriptions play\n  a role in the axioms of quantification). The statement is the following (see~\\ref{TAO_Axioms_Descriptions}):\n\n  \\begin{itemize}\n    \\item @{thm descriptions} \\hfill{(\\ref{PM-descriptions})}\n  \\end{itemize}\n\n  Given the technicalities of descriptions already discussed in section~\\ref{quantification-axioms}\n  it comes at no surprise that this statement requires a verbose proof.\n\n\\<close>"], ["", "subsection\\<open>Axioms of Complex Relation Terms\\<close>"], ["", "(*<*)"], ["", "context\nbegin"], ["", "interpretation MetaSolver"], ["proof (prove)\ngoal:\nNo subgoals!", "."], ["", "(*>*)"], ["", "text\\<open>\n  The axioms of complex relation terms deal with the properties of \\<open>\\<lambda>\\<close>-expressions.\n  \n  Since the @{method meta_solver} was not equipped with explicit rules for \\<open>\\<lambda>\\<close>-expressions,\n  the statements rely on their semantic properties as described in section~\\ref{semantics} directly.\n\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* unnamed subcontext with MetaSolver interpretation *)\n(*>*)"], ["", "text\\<open>\n\n  The statements are the following (see~\\ref{TAO_Axioms_ComplexRelationTerms}):\n  \\begin{itemize}\n    \\item @{thm lambda_predicates_1[THEN embedded_eq, of \\<phi>]} \\hfill{(\\ref{PM-lambda-predicates}.1)}\n    \\item @{thm lambda_predicates_2_1} \\hfill{(\\ref{PM-lambda-predicates}.2)}\n    \\item @{thm lambda_predicates_2_2} \\hfill{(\\ref{PM-lambda-predicates}.2)}\n    \\item @{thm[break=true] lambda_predicates_2_3} \\hfill{(\\ref{PM-lambda-predicates}.2)}\n    \\item @{thm lambda_predicates_3_0} \\hfill{(\\ref{PM-lambda-predicates}.3)}\n    \\item @{thm lambda_predicates_3_1} \\hfill{(\\ref{PM-lambda-predicates}.3)}\n    \\item @{thm lambda_predicates_3_2} \\hfill{(\\ref{PM-lambda-predicates}.3)}\n    \\item @{thm lambda_predicates_3_3} \\hfill{(\\ref{PM-lambda-predicates}.3)}\n    \\item @{thm lambda_predicates_4_0} \\hfill{(\\ref{PM-lambda-predicates}.4)}\n    \\item @{thm lambda_predicates_4_1} \\hfill{(\\ref{PM-lambda-predicates}.4)}\n    \\item @{thm lambda_predicates_4_2} \\hfill{(\\ref{PM-lambda-predicates}.4)}\n    \\item @{thm lambda_predicates_4_3} \\hfill{(\\ref{PM-lambda-predicates}.4)}\n  \\end{itemize}\n\n  The first axiom, \\<open>\\<alpha>\\<close>-conversion, could be omitted entirely. Since\n  lambda-expressions are modeled using functions with bound variables and \\<open>\\<alpha>\\<close>-conversion\n  is part of the logic of Isabelle/HOL, it already holds implicitly.\n\n  As explained in section~\\ref{lambda-expressions} \\<open>\\<beta>\\<close>-conversion has to be restricted\n  to \\emph{proper maps}. In PLM this restriction is implicit due to the fact that\n  \\<open>\\<lambda>\\<close>-expressions are only well-formed if their matrix is a propositional formula.\n\n  The formulation of the last class of axioms\n  ((\\ref{PM-lambda-predicates}.4), @{term \"\\<iota>\"}-conversion)\n  has to be adjusted to be representable in the functional setting. The original axiom is stated as follows in PLM:\n  \\begin{center}\n    \\<open>\\<A>(\\<phi> \\<equiv> \\<psi>) \\<rightarrow> ([\\<lambda>x\\<^sub>1\\<cdots>x\\<^sub>n \\<chi>\\<^sup>*] = [\\<lambda>x\\<^sub>1\\<cdots>x\\<^sub>n \\<chi>\\<^sup>*']\\<close>\n  \\end{center}\n  \\<open>\\<chi>\\<^sup>*'\\<close> is required to be the result of substituting  \\<open>\\<iota>x\\<psi>\\<close> for zero or more occurrences of \\<open>\\<iota>x\\<phi>\\<close>\n  in \\<open>\\<chi>\\<^sup>*\\<close>. In the functional setting @{term \"embedded_style \\<chi>\"} can be represented\n  as function from individual terms of type @{type \\<kappa>} to propositions of type @{type \\<o>}.\n  Thereby substituting \\<open>\\<iota>x\\<psi>\\<close> for occurrences of \\<open>\\<iota>x\\<phi>\\<close> can be expressed by\n  comparing the function application of @{term \"embedded_style \\<chi>\"} to @{term \"embedded_style (\\<^bold>\\<iota>x. \\<phi> x)\"}\n  with the function application of @{term \"embedded_style \\<chi>\"} to @{term \"embedded_style (\\<^bold>\\<iota>x. \\<psi> x)\"}.\n\n  Since in this representation @{term \"embedded_style \\<phi>\"} and @{term \"embedded_style \\<psi>\"} are functions as well\n  (from type @{type \\<nu>} to type @{type \\<o>}) the precondition has to be reformulated\n  to hold for the application of @{term \"embedded_style \\<phi>\"} and @{term \"embedded_style \\<psi>\"} to\n  an arbitrary individual @{term \"embedded_style x\"} to capture the concept of \\<open>\\<A>(\\<phi> \\<equiv> \\<psi>)\\<close> in PLM, where \\<open>\\<phi>\\<close>\n  and \\<open>\\<psi>\\<close> may contain \\<open>x\\<close> as a free variable.\n\\<close>"], ["", "subsection\\<open>Axioms of Encoding\\<close>"], ["", "text\\<open>\n  The last class of axioms deals with encoding (see~\\ref{TAO_Axioms_Encoding}):\n\n  \\begin{itemize}\n    \\item @{thm encoding} \\hfill{(\\ref{PM-encoding})}\n    \\item @{thm nocoder} \\hfill{(\\ref{PM-nocoder})}\n    \\item @{thm A_objects} \\hfill{(\\ref{PM-A-objects})}\n  \\end{itemize}\n\n  Whereas the first statement, \\emph{encoding is modally rigid}, is a direct consequence of the semantics\n  (recall that the encoding extension of a property was not relativized to possible worlds; see\n   section~\\ref{semantics}), the second axiom, \\emph{ordinary objects do not encode}, is only derivable\n  by expanding the definition of the encoding extension and the meta-logical distinction\n  between ordinary and abstract objects.\n\n  Similarly the comprehension axiom for abstract objects\n  depends on the model structure and follows from the representation of abstract objects as sets\n  of one-place relations and the definition of encoding as set membership.\n\n  Furthermore in the functional setting @{term \"embedded_style \\<phi>\"} has to be represented as a function\n  and the condition it imposes on @{term \"embedded_style F\"} is expressed as its application to @{term \"embedded_style F\"}.\n  The formulation in PLM on the other hand has to explicitly exclude a free occurrence of \\<open>x\\<close>\n  in \\<open>\\<phi>\\<close>. In the functional setting this is not necessary. Since @{term \"embedded_style x\"}\n  is bound by the existential quantifier and not explicitly given to @{term \"embedded_style \\<phi>\"} \n  as an argument, the condition @{term \"embedded_style \\<phi>\"} imposes on @{term \"embedded_style F\"}\n  cannot depend on @{term \"embedded_style x\"} by construction.\n\n\\<close>"], ["", "subsection\\<open>Summary\\<close>"], ["", "text\\<open>\n  Although some of the axioms have to be adjusted to be representable in the functional environment,\n  the resulting formulation faithfully represents the original axiom system of PLM.\n\n  Furthermore a large part of the axioms can be derived independently of the technicalities of\n  the representation layer with proofs that only depend on the representation of the semantics described in\n  section~\\ref{semantics}. Future work may explore available options to further minimize the dependency\n  on the underlying model structure.\n\n  To verify that the axiom system faithfully represents the reference system, the\n  deductive system PLM as described in @{cite \\<open>Chap. 9\\<close> PM} is derived solely based on the\n  formulation of the axioms without falling back to the model structure or the semantics (see~\\ref{TAO_PLM}).\n\n\\pagebreak\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context Axioms *)\n(*>*)\n\n\n(*<*)"], ["", "context PLM\nbegin"], ["", "(*>*)"], ["", "section\\<open>The Deductive System PLM\\<close>"], ["", "text\\<open>\n  The derivation of the deductive system PLM (@{cite \\<open>Chap. 9\\<close> PM}) from the axiom system constitutes\n  a major part of the Isabelle theory in the appendix (see~\\ref{TAO_PLM}). Its extent of\n  over one hundred pages makes it infeasible to discuss every aspect in full detail.\n\n  Nevertheless it is worthwhile to have a look at the mechanics of the derivation and to\n  highlight some interesting concepts.\n\\<close>"], ["", "subsection\\<open>Modally Strict Proofs\\<close>"], ["", "text\\<open>\n  \\label{PLM-modally-strict}\n\n  PLM distinguishes between two sets of theorems: the theorems, that are derivable from\n  the complete axiom system including the modally-fragile axiom,\n  and the set of theorems, that have \\emph{modally-strict} proofs (see~@{cite \\<open>(\\ref{PM-theoremhood})\\<close> PM}).\n\n  A proof is modally-strict, if it does not depend on any modally-fragile axioms.\n\n  In the embedding modally-strict theorems are stated to be true for an arbitrary semantic\n  possible world: \\mbox{@{term \"[\\<phi> in v]\"}}\n\n  Here the variable @{term \"v\"} implicitly ranges over all semantic possible worlds of\n  type @{type i}, including the designated actual world @{term \"dw\"}. Since modally-fragile axioms\n  only hold in @{term \"dw\"}, they therefore cannot be used to prove a statement formulated\n  this way, as desired.\n\n  Modally-fragile theorems on the other hand are stated to be true only for the designated\n  actual world: \\mbox{@{term \"[\\<phi> in dw]\"}}\n\n  This way necessary axioms, as well as modally-fragile axioms can be used in their proofs. However\n  it is not possible to infer from a modally-fragile theorem that the same statement holds as a\n  modally-strict theorem.\n\n  This representation of modally-strict and modally-fragile theorems is discussed in more detail\n  in section~\\ref{differences-modally-strict}.\n\\<close>"], ["", "subsection\\<open>Fundamental Metarules of PLM\\<close>"], ["", "text\\<open>\n  \\label{PLM-metarules}\n\n  The primitive rule of PLM is the modus ponens rule (see~\\ref{TAO_PLM_ModusPonens}):\n  \n  \\begin{itemize}\n    \\item @{thm modus_ponens[of v \\<phi> \\<psi>]} \\hfill{(\\ref{PM-modus-ponens})}\n  \\end{itemize}\n\n  This rule is a direct consequence of the semantics of the implication.\n\n  Additionally two fundamental Metarules are derived in PLM, \\emph{GEN} and \\emph{RN} (see~\\ref{TAO_PLM_GEN_RN}):\n\n  \\begin{itemize}\n    \\item @{thm rule_gen[of v \\<phi>]} \\hfill{(\\ref{PM-rule-gen})}\n    \\item @{thm RN_2[rename_abs w, of \\<phi> \\<psi> v]} \\hfill{(\\ref{PM-RN})}\n  \\end{itemize}\n\n  Although in PLM these rules can be derived by structural induction on the length of\n  a derivation, this proving mechanism cannot be reproduced in Isabelle. However,\n  the rules are direct consequences of the semantics described in section~\\ref{semantics}.\n  The same is true for the deduction rule (see~\\ref{TAO_PLM_NegationsAndConditionals}):\n\n  \\begin{itemize}\n    \\item @{thm deduction_theorem[of v \\<phi> \\<psi>]} \\hfill{(\\ref{PM-deduction-theorem})}\n  \\end{itemize}\n\n  Consequently this rule is derived from the semantics as well.\n  \n  These rules are the \\emph{only} exceptions to the concept that the deductive system of\n  PLM is derived solely from the axiom system without relying on the previous layers of the\n  embedding.\n\n\\<close>"], ["", "subsection\\<open>PLM Solver\\<close>"], ["", "(*<*)"], ["", "context\nbegin"], ["", "interpretation MetaSolver"], ["proof (prove)\ngoal:\nNo subgoals!", "."], ["", "(*>*)"], ["", "text\\<open>\n  \\label{PLM-solver}\n\n  Similarly to the @{method meta_solver} described in section~\\ref{meta_solver} another proving\n  method is introduced, namely the @{method PLM_solver} (see~\\ref{TAO_PLM_Solver}).\n\n  This proving method is initially not equipped with any rules. Throughout the derivation of the\n  deductive system, whenever an appropriate rule is derived as part of PLM directly or becomes\n  trivially derivable from the proven theorems, it is added to the @{method PLM_solver}.\n\n  Additionally the @{method PLM_solver} can instantiate any theorem of the deductive system PLM \n  as well as any axiom, if doing so resolves the current proving goal.\n\n  By its construction the @{method PLM_solver} has the property, that it can \\emph{only} prove\n  statements that are derivable from the deductive system PLM. Thereby it is safe to use to aid\n  in any proof throughout the section. In practice it can automatically prove a variety of simple\n  statements and aid in more complex proofs throughout the derivation of the deductive system.\n\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* unnamed subcontext with MetaSolver interpretation *)\n(*>*)"], ["", "subsection\\<open>Additional Type Classes\\<close>"], ["", "text\\<open>\n  \\label{PLM-type-classes}\n\n  In PLM it is possible to derive statements involving the general identity symbol by case\n  distinction: if such a statement is derivable for all types of terms in the language separately,\n  it can be concluded that it is derivable for the identity symbol in general. Such a case distinction\n  cannot be directly reproduced in the embedding, since it cannot be assumed that every instantiation of the\n  type class @{class identifiable} is in fact one of the types of terms of PLM.\n\n  However, there is a simple way to still formulate such general statements. This is done by\n  the introduction of additional type classes. A simple example is the type class @{class id_eq}\n  (see~\\ref{TAO_PLM_Identity}). This new type class assumes the following statements to be true:\n\n  \\begin{itemize}\n    \\item @{thm id_eq_1[of v \\<alpha>]} \\hfill{(\\ref{PM-id-eq}.1)}\n    \\item @{thm id_eq_2[of v \\<alpha> \\<beta>]} \\hfill{(\\ref{PM-id-eq}.2)}\n    \\item @{thm id_eq_3[of v \\<alpha> \\<beta> \\<gamma>]} \\hfill{(\\ref{PM-id-eq}.3)}\n  \\end{itemize}\n\n  Since these statements can be derived \\emph{separately} for the types @{type \\<nu>}, @{type \\<Pi>\\<^sub>0},\n  @{type \\<Pi>\\<^sub>1}, @{type \\<Pi>\\<^sub>2} and @{type \\<Pi>\\<^sub>3}, the type class @{class id_eq} can be instantiated\n  for each of these types.\n\\<close>"], ["", "subsection\\<open>The Rule of Substitution\\<close>"], ["", "text\\<open>\n  A challenge in the derivation of the deductive system that is worth to examine in\n  detail is the \\emph{rule of substitution}.  The rule is stated in PLM as follows\n  (see~(\\ref{PM-rule-sub-nec})@{cite PM}):\n\n  \\begin{addmargin}{1cm}\n    If \\<open>\\<turnstile>\\<^sub>\\<box> \\<psi> \\<equiv> \\<chi>\\<close> and \\<open>\\<phi>'\\<close> is the result of substituting the formula \\<open>\\<chi>\\<close>\n    for zero or more occurrences of \\<open>\\<psi>\\<close> where the latter is a subformula of \\<open>\\<phi>\\<close>,\n    then if \\<open>\\<Gamma> \\<turnstile> \\<phi>\\<close>, then \\<open>\\<Gamma> \\<turnstile> \\<phi>'\\<close>. [Variant: If \\<open>\\<turnstile>\\<^sub>\\<box> \\<psi> \\<equiv> \\<chi>\\<close>, then \\<open>\\<phi> \\<turnstile> \\<phi>'\\<close>]\n  \\end{addmargin}\n\n  A naive representation of the rule would be the following:\n\n  \\begin{center}\n    @{term \"(\\<And>v. [\\<psi> \\<^bold>\\<equiv> \\<chi> in v]) \\<Longrightarrow> [\\<phi> \\<psi> in v] \\<longleftrightarrow> [\\<phi> \\<chi> in v]\"}\n  \\end{center}\n\n  However this statement is \\emph{not} derivable. The issue is connected to the restriction\n  of @{term \"\\<psi>\"} to be a \\emph{subformula} of \\<open>\\<phi>\\<close> in PLM. The formulation above would allow\n  the rule to be instantiated for \\emph{any function} @{term \"embedded_style \\<phi>\"} from formulas to formulas.\n\n  Formulas in the embedding have type @{type \\<o>} which is internally represented by functions of the\n  type @{typ \"j\\<Rightarrow>i\\<Rightarrow>bool\"}. Therefore the formulation above could be instantiated with a function\n  @{term \"embedded_style \\<phi>\"} that has the following internal representation:\n  \\mbox{@{term \"\\<lambda> \\<psi> . make\\<o>(\\<lambda> s w .  \\<forall> s . eval\\<o> (embedded_style \\<psi>) s w)\"}}\n\n  So nothing prevents @{term \"embedded_style \\<phi>\"} from evaluating its argument for a state\n  different from the designated actual state @{term \"dj\"}. The condition @{term \"(\\<And>v. [\\<psi> \\<^bold>\\<equiv> \\<chi> in v])\"}\n  on the other hand only requires @{term \"embedded_style \\<psi>\"} and @{term \"embedded_style \\<chi>\"} to be\n  (necessarily) equivalent in the \\emph{actual state} - no statement about other states is implied.\n\n  Another issue arises if one considers one of the example cases of legitimate uses of the rule\n  of substitution in PLM (see~@{cite \\<open>(\\ref{PM-rule-sub-nec})\\<close> PM}):\n\n  \\begin{addmargin}{1cm}\n    If \\<open>\\<turnstile> \\<exists>x A!x\\<close> and \\<open>\\<turnstile>\\<^sub>\\<box> A!x \\<equiv> \\<not>\\<diamond>E!x\\<close>, then \\<open>\\<turnstile> \\<exists>x \\<not>\\<diamond>E!x\\<close>.\n  \\end{addmargin}\n\n  This would not follow from the naive formulation above, even if it were derivable.\n  Since \\<open>x\\<close> is \\emph{bound} by\n  the existential quantifier, in the functional representation @{term \"embedded_style \\<phi>\"}\n  has to have a different type. In the example @{term \"embedded_style \\<phi>\"}\n  has to be \\mbox{@{term[eta_contract=false] \"(\\<lambda> \\<psi> . embedded_style (\\<^bold>\\<exists> x :: \\<nu> . \\<psi> x))\"}} which is of\n  type @{typeof \"(\\<lambda> \\<psi> . embedded_style (\\<^bold>\\<exists> x :: \\<nu> . \\<psi> x))\"}. @{term \"embedded_style \\<psi>\"} and\n  @{term \"embedded_style \\<chi>\"} have to be functions as well:\n  \\mbox{@{term[eta_contract=false] \"(embedded_style \\<psi>) = (\\<lambda> x . embedded_style \\<lparr>A!,x\\<rparr>)\"}} and\n  \\mbox{@{term[eta_contract=false] \"(embedded_style \\<chi>) = (\\<lambda> x . embedded_style (\\<^bold>\\<not>\\<^bold>\\<diamond>\\<lparr>E!,x\\<rparr>))\"}}.\n  Consequently the equivalence condition for this case has to be reformulated to\n  \\mbox{@{term \"\\<And> x v. [\\<psi> x \\<^bold>\\<equiv> \\<chi> x in v]\"}}\\footnote{This is analog to the fact that \\<open>x\\<close>\n  is a free variable in the condition \\<open>\\<turnstile>\\<^sub>\\<box> A!x \\<equiv> \\<not>\\<diamond>E!x\\<close> in PLM.}.\n\n  \n\\<close>"], ["", "subsubsection\\<open>Solution\\<close>"], ["", "text\\<open>\n\n  The embedding employs a solution that is complex, but can successfully address the described\n  issues.\n\n  The following definition is introduced (see~\\ref{TAO_PLM_Necessity}):\n\n  \\begin{center}\n    @{thm Substable_def[expand2, of cond \\<phi>]}\n  \\end{center}\n\n  Given a condition @{term \"cond\"} a function @{term \"embedded_style \\<phi>\"}\n  is considered @{term \"Substable\"}, if and only if for all @{term \"embedded_style \\<psi>\"}\n  and  @{term \"embedded_style \\<chi>\"} that satisfy @{term \"cond\"} it follows in each\n  possible world @{term \"v\"} that \\mbox{@{term \"[\\<phi> \\<psi> \\<^bold>\\<equiv> \\<phi> \\<chi> in v]\"}}\\footnote{@{term \"embedded_style \\<psi>\"}\n  and  @{term \"embedded_style \\<chi>\"} can have an arbitrary type. @{term \"embedded_style \\<phi>\"} is a function\n  from this type to formulas.}.\n\n  Now several introduction rules for this property are derived. The idea is to capture the\n  notion of \\emph{subformula} in PLM. A few examples are:\n\n  \\begin{itemize}\n    \\item @{lemma \"Substable cond (\\<lambda>\\<phi>. embedded_style \\<Theta>)\"\n            by (simp add: embedded_style_def Substable_intro_const)}\n    \\item @{lemma \"Substable cond \\<psi> \\<Longrightarrow> Substable cond (\\<lambda>\\<phi>. embedded_style ( \\<^bold>\\<not>\\<psi> \\<phi>))\"\n            by (simp add: embedded_style_def Substable_intro_not)}\n    \\item @{lemma \"Substable cond \\<psi> \\<and> Substable cond \\<chi> \\<Longrightarrow> Substable cond (\\<lambda>\\<phi>. embedded_style (\\<psi> \\<phi> \\<^bold>\\<rightarrow> \\<chi> \\<phi>))\"\n            by (simp add: embedded_style_def Substable_intro_impl)}\n  \\end{itemize}\n\n  These rules can be derived using theorems of PLM.\n\n  As illustrated above in the functional setting substitution has to be allowed not only for formulas,\n  but also for \\emph{functions} to formulas. To that end the type class @{class Substable} is introduced\n  that fixes a condition @{term \"Substable_Cond\"} to be used as @{term \"cond\"} in the definition above\n  and assumes the following:\n\n  \\begin{center}\n    @{thm Substable_class.rule_sub_nec[of \\<phi> \\<psi> \\<chi> \\<Theta> v]}\n  \\end{center}\n\n  If @{term \"embedded_style \\<phi>\"} is @{term \"Substable\"} (as per the definition above) under the\n  condition @{term \"Substable_Cond\"} that was fixed in the type class, and @{term \"embedded_style \\<psi>\"}\n  and @{term \"embedded_style \\<chi>\"} satisfy the fixed condition @{term \"Substable_Cond\"}, then everything\n  that is true for @{term \"[\\<phi> \\<psi> in v]\"} is also true for @{term \"[\\<phi> \\<chi> in v]\"}.\n\n  As a base case this type class is \\emph{instantiated} for the type of formulas @{type \\<o>} with\n  the following definition of @{term \"Substable_Cond\"}:\n\n  \\begin{center}\n    @{thm Substable_Cond_\\<o>_def[expand2, of \\<psi> \\<chi>]}\n  \\end{center}\n\n  Furthermore the type class is instantiated for \\emph{functions} from an arbitrary type to\n  a type of the class @{class Substable} with the following definition of @{term \"Substable_Cond\"}:\n\n  \\begin{center}\n    @{thm Substable_Cond_fun_def[expand2, of \\<psi> \\<chi>]}\n  \\end{center}\n\\<close>"], ["", "subsubsection\\<open>Proving Methods\\<close>"], ["", "text\\<open>\n\n  \\label{substitution-method}\n\n  Although the construction above covers exactly the cases in which PLM allows substitutions, it does\n  not yet have a form that allows to conveniently \\emph{apply} the rule of substitution. In order\n  to apply the rule, it first has to be established that a formula can be decomposed into a\n  function with the substituents as arguments and it further has to be shown that this function\n  satisfies the appropriate @{term \"Substable\"} condition. This complexity prevents any reasonable\n  use cases. This problem is mitigated by the introduction of proving methods.\n  The main method is called @{method PLM_subst_method}.\n\n  This method uses a combination of pattern matching and automatic rule application to provide\n  a convenient way to apply the rule of substitution in practice.\n\n  For example assume the current proof objective is @{term \"[\\<^bold>\\<not>\\<^bold>\\<not>\\<^bold>\\<diamond>\\<lparr>E!,x\\<rparr> in v]\"}. Now it is possible to\n  apply @{method PLM_subst_method} as follows:\n  \\begin{center}\n    @{theory_text \"apply (PLM_subst_method \\\"\\<lparr>A!,x\\<rparr>\\\" \\\"(\\<^bold>\\<not>(\\<^bold>\\<diamond>\\<lparr>E!,x\\<rparr>))\\\"\"}\n  \\end{center}\n  The method automatically analyzes the current proving goal, uses pattern matching to find an\n  appropriate choice for a function @{term \"embedded_style \\<phi>\"}, applies the substitution rule and\n  resolves the substitutability claim about @{term \"embedded_style \\<phi>\"}.\n\n  Consequently it can resolve the current proof objective\n  by producing two new proving goals: @{term \"\\<forall>v. [\\<lparr>A!,x\\<rparr> \\<^bold>\\<equiv> \\<^bold>\\<not>\\<^bold>\\<diamond>\\<lparr>E!,x\\<rparr> in v]\"} and @{term \"[\\<^bold>\\<not>\\<lparr>A!,x\\<rparr> in v]\"},\n  as expected. The complexity of the construction above is hidden away entirely.\n\n  Similarly assume the proof objective is @{term \"[\\<^bold>\\<exists> x . (\\<^bold>\\<not>(\\<^bold>\\<diamond>\\<lparr>E!,x\\<^sup>P\\<rparr>))  in v]\"}. Now the method\n  @{method PLM_subst_method} can be invoked as follows:\n  \\begin{center}\n    @{theory_text \"apply (PLM_subst_method \\\"\\<lambda>x . \\<lparr>A!,x\\<^sup>P\\<rparr>\\\" \\\"\\<lambda>x . (\\<^bold>\\<not>(\\<^bold>\\<diamond>\\<lparr>E!,x\\<^sup>P\\<rparr>))\\\"\"}\n  \\end{center}\n  This will result in the new proving goals:\n  \\mbox{@{term \"\\<forall>x v. [\\<lparr>A!,x\\<^sup>P\\<rparr> \\<^bold>\\<equiv> \\<^bold>\\<not>\\<^bold>\\<diamond>\\<lparr>E!,x\\<^sup>P\\<rparr> in v]\"}} and \\mbox{@{term \"[\\<^bold>\\<exists>x. \\<lparr>A!,x\\<^sup>P\\<rparr> in v]\"}}, as\n  desired.\n\n\\<close>"], ["", "subsubsection\\<open>Conclusion\\<close>"], ["", "text\\<open>\n  Although an adequate representation of the rule of substitution in the functional setting\n  is challenging, the above construction allows a convenient use of the rule. Moreover it is\n  important to note that despite the complexity of the representation no assumptions about\n  the underlying model structure were made. The construction is completely\n  derivable from the rules of PLM itself, so the devised rule is safe to use without\n  compromising the provability claim of the layered structure of the embedding.\n\n  All statements that are proven using the constructed substitution methods, remain derivable\n  from the deductive system of PLM.\n\\<close>"], ["", "subsection\\<open>An Example Proof\\<close>"], ["", "text\\<open>\n  To illustrate how the derivation of theorems in the embedding works in practice,\n  consider the following example\\footnote{Since the whole proof is stated as raw Isabelle code,\n  unfortunately no color-coding can be applied.}:\n\\<close>"], ["", "lemma \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow> ((\\<^bold>\\<not>\\<^bold>\\<box>\\<phi>) \\<^bold>\\<equiv> (\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>))) in v]\""], ["proof (prove)\ngoal (1 subgoal):\n 1. [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow>\n                    \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow>\n     (\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n      \\<^bold>\\<box>\\<^bold>\\<not>\\<phi>) in v]", "proof (rule CP)"], ["proof (state)\ngoal (1 subgoal):\n 1. [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow>\n                    \\<^bold>\\<box>\\<phi>) in v] \\<Longrightarrow>\n    [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n     \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]", "assume \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v]\""], ["proof (state)\nthis:\n  [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v]\n\ngoal (1 subgoal):\n 1. [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow>\n                    \\<^bold>\\<box>\\<phi>) in v] \\<Longrightarrow>\n    [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n     \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]", "hence \"[(\\<^bold>\\<not>\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>)) \\<^bold>\\<equiv> \\<^bold>\\<box>\\<phi> in v]\""], ["proof (prove)\nusing this:\n  [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v]\n\ngoal (1 subgoal):\n 1. [\\<^bold>\\<not>\\<^bold>\\<box>\\<^bold>\\<not>\\<phi> \\<^bold>\\<equiv>\n     \\<^bold>\\<box>\\<phi> in v]", "by (metis sc_eq_box_box_1 diamond_def vdash_properties_10)"], ["proof (state)\nthis:\n  [\\<^bold>\\<not>\\<^bold>\\<box>\\<^bold>\\<not>\\<phi> \\<^bold>\\<equiv>\n   \\<^bold>\\<box>\\<phi> in v]\n\ngoal (1 subgoal):\n 1. [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow>\n                    \\<^bold>\\<box>\\<phi>) in v] \\<Longrightarrow>\n    [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n     \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]", "thus \"[((\\<^bold>\\<not>\\<^bold>\\<box>\\<phi>) \\<^bold>\\<equiv> (\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>))) in v]\""], ["proof (prove)\nusing this:\n  [\\<^bold>\\<not>\\<^bold>\\<box>\\<^bold>\\<not>\\<phi> \\<^bold>\\<equiv>\n   \\<^bold>\\<box>\\<phi> in v]\n\ngoal (1 subgoal):\n 1. [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n     \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]", "by (meson CP \"\\<^bold>\\<equiv>I\" \"\\<^bold>\\<equiv>E\" \"\\<^bold>\\<not>\\<^bold>\\<not>I\" \"\\<^bold>\\<not>\\<^bold>\\<not>E\")"], ["proof (state)\nthis:\n  [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n   \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]\n\ngoal:\nNo subgoals!", "qed"], ["", "text\\<open>\n  Since the statement is an implication it is derived using a \\emph{conditional proof}.\n  To that end the proof statement already applies the initial rule @{theory_text CP}.\n\n  The proof objective inside the proof body is now \\mbox{@{term \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v] \\<Longrightarrow> [\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv> \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]\"}},\n  so \\mbox{@{term \"[\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv> \\<^bold>\\<box>\\<^bold>\\<not>\\<phi> in v]\"}} has to be shown under the assumption \\mbox{@{term \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v]\"}}.\n  Therefore the first step is to assume \\mbox{@{term \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) in v]\"}}.\n\n  The second statement can now be automatically derived using the previously proven theorem\n  @{theory_text sc_eq_box_box_1}, the definition of the diamond operator and a deduction\n  rule. The final proof objective follows from a combination of introduction and elimination\n  rules.\n\n  The automated reasoning tool @{theory_text sledgehammer} can find proofs for\n  the second and final statement automatically. It can even automatically find a proof\n  for the entire theorem resulting in the following one-line proof:\n\\<close>"], ["", "lemma \"[\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow> \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow> ((\\<^bold>\\<not>\\<^bold>\\<box>\\<phi>) \\<^bold>\\<equiv> (\\<^bold>\\<box>(\\<^bold>\\<not>\\<phi>))) in v]\""], ["proof (prove)\ngoal (1 subgoal):\n 1. [\\<^bold>\\<box>(\\<phi> \\<^bold>\\<rightarrow>\n                    \\<^bold>\\<box>\\<phi>) \\<^bold>\\<rightarrow>\n     (\\<^bold>\\<not>\\<^bold>\\<box>\\<phi> \\<^bold>\\<equiv>\n      \\<^bold>\\<box>\\<^bold>\\<not>\\<phi>) in v]", "by (metis \"\\<^bold>\\<equiv>I\" CP \"\\<^bold>\\<equiv>E\"(1) \"\\<^bold>\\<equiv>E\"(2) raa_cor_1 sc_eq_box_box_1 diamond_def)"], ["", "text\\<open>\n  So it can be seen that the embedding can be used to interactively prove statements\n  with the support of automated reasoning tools and often even complete proofs\n  for complex statements can be found automatically.\n\\<close>"], ["", "subsection\\<open>Summary\\<close>"], ["", "text\\<open>\n  A full representation of the deductive system PLM, as described in @{cite \\<open>Chap. 9\\<close> PM}, could\n  be derived without violating the layered structure of the embedding.\n\n  Although compromises affecting the degree of automation had to be made, the resulting\n  representation can conveniently be used for the interactive construction of complex proofs\n  while retaining the support of the automation facilities of Isabelle/HOL.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context PLM*)\n(*>*)"], ["", "section\\<open>Artificial Theorems\\<close>"], ["", "(*<*)"], ["", "context ArtificialTheorems\nbegin"], ["", "(*>*)"], ["", "text\\<open>\n\n  \\label{artificial-theorems}\n\n  The layered approach of the embedding provides the means to derive theorems\n  independently of the representation layer and model structure. It is still interesting to consider\n  some examples of theorems that are \\emph{not} part of PLM, but can be derived in the\n  embedding using its meta-logical properties.\n\\<close>"], ["", "subsection\\<open>Non-Standard $\\lambda$-Expressions\\<close>"], ["", "text\\<open>\n  \\label{artificial-theorems-lambda}\n\n  The following statement involves a \\<open>\\<lambda>\\<close>-expressions that contains encoding subformulas\n  and is consequently not part of PLM (see~\\ref{TAO_ArtificialTheorems}):\n\n  \\begin{center}\n    @{thm lambda_enc_2[of v F y x]}\n  \\end{center}\n\n  In this case traditional \\<open>\\<beta>\\<close>-conversion still holds, since the \\<open>\\<lambda>\\<close>-expression\n  does not contain encoding expressions involving its bound variable\\footnote{Consequently the\n  matrix is a \\emph{proper map}.}. On the other hand the following is \\emph{not} a theorem in\n  the embedding (the tool @{theory_text nitpick} can find a counter-model):\n\n  \\begin{center}\n    @{term \"[(\\<lparr>\\<^bold>\\<lambda> x . \\<lbrace>x\\<^sup>P, F\\<rbrace>, x\\<^sup>P\\<rparr> \\<^bold>\\<rightarrow> \\<lbrace>x\\<^sup>P, F\\<rbrace>) in v]\"}\n  \\end{center}\n\n  Instead the following generalized versions of \\<open>\\<beta>\\<close>-conversion are theorems:\n\n  \\begin{itemize}\n    \\item @{thm lambda_enc_4[of v F z]}\n    \\item @{thm lambda_ex[of v \\<phi> z]}\n  \\end{itemize}\n\n  These theorems can be equivalently stated purely in the embedded logic:\n  \n  \\begin{itemize}\n    \\item @{thm lambda_enc_emb[of v F z]}\n    \\item @{thm lambda_ex_emb[of v \\<phi> z]}\n  \\end{itemize}\n\n  The second statement shows that in general \\<open>\\<lambda>\\<close>-expressions\n  in the embedding have a \\emph{non-standard} semantics. As a special case, however,\n  the behavior of \\<open>\\<lambda>\\<close>-expressions is classical if restricted to\n  proper maps, which is due to the following theorem\\footnote{Note that for propositional formulas\n  an equivalent statement is derivable in PLM as well.}:\n\n  \\begin{center}\n    @{thm proper_beta[of \\<phi> v x]}\n  \\end{center}\n\n  As a consequence of the generalized \\<open>\\<beta>\\<close>-conversion\n  there are theorems in the embedding involving \\<open>\\<lambda>\\<close>-expressions\n  that \\emph{do} contain encoding subformulas in the bound variable, e.g.:\n  \n  \\begin{center}\n    @{thm lambda_enc_1[of v F y]}\n  \\end{center}\n  \n  This topic is discussed in more detail in section~\\ref{differences-lambda}.\n\\<close>"], ["", "subsection\\<open>Consequences of the Aczel-model\\<close>"], ["", "text\\<open>\n  Independently the following theorem is a consequence of the constructed Aczel-model:\n\n  \\begin{center}\n    @{thm lambda_rel_extensional[of v a b R, THEN embedded_eq]}\n  \\end{center}\n\n  The reason for this theorem to hold is that the condition on @{term \"a\"} and @{term \"b\"}\n  forces the embedding to map both objects to the same urelement. By the definition of\n  exemplification the presented \\<open>\\<lambda>\\<close>-expressions only depend on this urelement,\n  therefore they are forced to be equal. Neither the deductive system of PLM nor its formal\n  semantics require this equality.\n\n  Initial research suggests that this artificial theorem can be avoided by extending the\n  embedding in the following way: the mapping from abstract objects to special urelements\n  constructed in section~\\ref{individuals-to-urelements} can be modified to depend on states.\n  This way the condition used in the theorem only implies that @{term \"a\"}\n  and @{term \"b\"} are mapped to the same urelement in the \\emph{actual state}. Since\n  they can still be mapped to different urelements in different states, the derived equality\n  no longer follows.\n\n  This extension of the embedding increases the complexity of the representation\n  layer slightly, but its preliminary analysis suggests that it presents no further issues, so\n  future versions of the embedding will in all likelihood include such a modification.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context ArtificialTheorems *)\n(*>*)"], ["", "section\\<open>Sanity Tests\\<close>"], ["", "text\\<open>\n  The consistency of the constructed embedding can be verified by\n  the model-finding tool @{theory_text nitpick} (see~\\ref{TAO_SanityTests_Consistency}).\n  Since the main construction of the embedding is definitional and only a minimal set of meta-logical\n  axioms is used, this is expected.\n\n  The hyperintensionality of the constructed model can be verified for some simple\n  example cases. The following statements have counter-models (see~\\ref{TAO_SanityTests_Intensionality}):\n\n  \\begin{itemize}\n    \\item @{term \"[(\\<^bold>\\<lambda>y. (q \\<^bold>\\<or> \\<^bold>\\<not>q)) \\<^bold>= (\\<^bold>\\<lambda>y. (p \\<^bold>\\<or> \\<^bold>\\<not>p)) in v]\"}\n    \\item @{term \"[(\\<^bold>\\<lambda>y. (p \\<^bold>\\<or> q)) \\<^bold>= (\\<^bold>\\<lambda>y. (q \\<^bold>\\<or> p)) in v]\"}\n  \\end{itemize}\n\n  Furthermore the meta-logical axioms stated in section~\\ref{concreteness} can be justified\n  (see~\\ref{TAO_SanityTests_MetaAxioms}):\n  \\begin{itemize}\n    \\item @{thm[display] SanityTests.OrdAxiomCheck[rename_abs x v y u z z]}\n    \\item @{thm[display] SanityTests.AbsAxiomCheck[rename_abs x v y u z z]}\n    \\item @{thm[display] SanityTests.PossiblyContingentObjectExistsCheck}\n    \\item @{thm[display] SanityTests.PossiblyNoContingentObjectExistsCheck}\n  \\end{itemize}\n\n  The first axiom is equivalent to the fact that concreteness matches the domains of ordinary, resp.\n  abstract objects, whereas the second and third axiom correspond to the conjuncts of\n  axiom~(\\ref{PM-qml}.4)@{cite PM}.\n\n\\begin{remark}\n  Additionally some further desirable meta-logical properties of the embedding are verified\n  in~\\ref{TAO_SanityTests_MetaRelations} and~\\ref{TAO_SanityTests_MetaLambda}.\n\\end{remark}\n\\<close>"], ["", "chapter\\<open>Technical Limitations of Isabelle/HOL\\<close>"], ["", "text\\<open>\n  Although the presented embedding shows that the generic proof assistant Isabelle/HOL\n  offers a lot of flexibility in expressing even a very complex and challenging theory\n  as the Theory of Abstract Objects, it has some limitations that required compromises\n  in the formulation of the theory.\n\n  In this chapter some of these limitations and their consequences for the embedding\n  are discussed. Future versions of Isabelle may allow a clearer implementation especially\n  of the layered approach of the embedding.\n  \n\\<close>"], ["", "section\\<open>Limitations of Type Classes and Locales\\<close>"], ["", "text\\<open>\n  Isabelle provides a powerful tool for abstract reasoning called @{theory_text locale}.\n  Locales are used for \\emph{parametric} reasoning. Type classes, as already described \n  briefly in section~\\ref{general-quantifier} and further mentioned in sections~\\ref{general-identity}\n  and~\\ref{PLM-type-classes}, are in fact special cases of locales that are additionally\n  connected to Isabelle's internal type system.\n\n  The definition of a locale defines a set of constants that can use arbitrary type variables\\footnote{Type\n  classes on the other hand are restricted to only one type variable.}. Assumptions about\n  these constants can be postulated that can be used in the reasoning within the context of\n  the locale. Similarly to the instantiation of a type class, a locale can be \\emph{interpreted}\n  for specific definitions of the introduced constants, if it can be proven that the postulated assumptions\n  are satisfied for the interpretation.\n\n  Thereby it is possible to reason about abstract structures that are solely characterized by a specific\n  set of assumptions. Given that it can be shown that these assumptions are satisfied for a concrete\n  case, an interpretation of the locale allows the use of all theorems shown\n  for the abstract case in the concrete application.\n\n  Therefore in principle locales would be a perfect fit for the layered structure of the embedding:\n  If the representation of the formal semantics and the axiom system could both be formulated\n  as locales, it could first be shown that the axiom system is a \\emph{sublocale} of the formal\n  semantics, i.e. every set of constants that satisfies the requirements of the formal semantics\n  also satisfies the requirements of the axiom system, and further the formal semantics could\n  be interpreted for a concrete model structure.\n\n  Since the reasoning within a locale cannot use further assumptions that are only satisfied\n  by a specific interpretation, this way the universality of the reasoning based on the axiom\n  system could be formally guaranteed - no proof that is solely based on the axiom locale\n  could use any meta-logical statement tied to the underlying representation layer and\n  model structure\\footnote{Although the construction of chapter~\\ref{embedding} provides the means\n  for universal reasoning that is independent of a model as well, it depends on \\emph{fair use} of\n  the provided layer structure.}.\n\n  However, a major issue arises when trying to formulate the axiom system as a locale.\n  Constants in a locale have to be introduced with a fixed type.\n  Although this type can use type variables, e.g. @{typ \"'a\\<Rightarrow>'a\\<Rightarrow>'\\<o>\"},\n  the type variable @{typ \"'a\"} is fixed throughout the locale. This makes it impossible\n  to introduce a general binder for all-quantification or a general identity symbol in a single axiom\n  locale that could be used for the statement of the axioms of quantification and the substitution\n  of identicals.\n\n  Several solutions to this problem could be considered: the identity relation could be\n  introduced as a polymorphic constant \\emph{outside the locale} and the locale could assume some\n  properties for this constant for specific type variables. Before interpreting the\n  locale the polymorphic constant could then be \\emph{overloaded} for concrete types\n  in order to be able to satisfy the assumptions. However, it would still be\n  impossible to prove a general statement about identity: every statement would have\n  to be restricted to a specific type, because in general no assumptions about the\n  properties of identity could be made.\n\n  Another solution would be to refrain from using general quantifiers and identity relations\n  altogether, but to introduce separate binders and identity symbols for the type of individuals and\n  each relation type. However, this would add a significant amount of notational complexity\n  and would require to duplicate all statements that hold for quantification\n  and identity in general for every specific type. Statements ranging over multiple types\n  would even have to be stated for every possible combination of types separately.\n\n  It could also be considered to introduce the axioms of quantification and identity separately\n  from the axiom locale in a type class. An interpretation of the complete axiom system would\n  then have to interpret the axiom locale, as well as instantiate the respective type classes.\n  Since type classes can only use one type variable, this would make it impossible to use a type\n  variable for truth values in the definition of the respective type classes, though. Consequently\n  it is unclear how appropriate assumptions for such type classes could be formulated.\n  Using separate locales instead of type classes would be connected with different issues.\n\n  Several other concepts were considered during the construction of the embedding,\n  but no solution was found that would both accurately represent the axiom system and\n  still be notationally convenient.\n\n  The most natural extension of Isabelle's locale system that would solve the described\n  issues, would be the ability to introduce polymorphic constants in a locale that\n  can be restricted to a type class (resp. a \\emph{sort}). The type class could potentially even\n  be introduced simultaneously with the locale. However, such a construction is currently not possible\n  in Isabelle and as of yet it is unknown whether the internal type system of Isabelle\n  would allow such an extension in general.\n\\<close>"], ["", "section\\<open>Case Distinctions by Type\\<close>"], ["", "text\\<open>\n  Although a general identity relation can be represented using type classes\n  as described in sections~\\ref{general-quantifier} and~\\ref{general-identity}, this\n  construction differs from the concept used in PLM. The identity relation of PLM is\n  not determined by some set of properties, but by its definition for the specific concrete types.\n\n  Isabelle does not allow the restriction of a type variable in a statement\n  to a specific set of types. Type variables can only be restricted to specific \\emph{sorts},\n  so effectively to type classes. As mentioned in section~\\ref{PLM-type-classes}, this means\n  that statements about the general identity relation, that depend on the specific\n  definitions for the concrete types, cannot be proven as in PLM by case distinction\n  on types. Instead additional type classes have to be introduced that \\emph{assume} the statements\n  and then have to be instantiated for the concrete types.\n\n  Although this construction involves some technical overhead, the solution is elegant and provides\n  a flexible representation for such general statements.\n\\<close>"], ["", "section\\<open>Structural Induction and Proof-Theoretic Reasoning\\<close>"], ["", "text\\<open>\n  As mentioned in section~\\ref{PLM-metarules}, some of the meta-rules that PLM can derive\n  by induction on the length of a derivation, have to be proven using the semantics instead\n  in the embedding, e.g. the deduction theorem\n  \\mbox{@{thm PLM.deduction_theorem[of v \\<phi> \\<psi>]}}.\n\n  While the derivation of these fundamental rules using the semantics is justified,\n  it would be interesting to investigate whether the proof-theoretic reasoning\n  PLM uses in these cases can be reproduced in Isabelle/HOL. A related topic is\n  the representation of the concept of \\emph{modally-strict proofs} as described\n  in sections~\\ref{PLM-modally-strict} and~\\ref{differences-modally-strict}.\n\\<close>"], ["", "chapter\\<open>Discussion and Results\\<close>"], ["", "section\\<open>Differences between the Embedding and PLM\\<close>"], ["", "text\\<open>\n  Although the embedding attempts to represent the language and logic of PLM as precisely\n  as possible, there remain some differences between PLM and its representation in Isabelle/HOL.\n  Some of the known differences are discussed in the following sections.\n  A complete analysis of the precise relation between PLM and the embedding unfortunately\n  goes beyond the scope of this thesis and will only be possible after PLM has recovered\n  from the discovered paradox (see~\\ref{paradox}). Such an analysis will be a highly\n  interesting and relevant topic for future research.\n\\<close>"], ["", "subsection\\<open>Propositional Formulas and $\\lambda$-Expressions\\<close>"], ["", "text\\<open>\n  \\label{differences-lambda}\n\n  The main difference between the embedding and PLM is the fact that the embedding does\n  not distinguish between propositional and non-propositional formulas.\n\n  This purely syntactic distinction is challenging to reproduce in a shallow embedding that\n  does not introduce the complete term structure of the embedded language directly.\n  Instead the embedding attempts to analyze the semantic reason for the\n  syntactic distinction and to devise a semantic criterion that can be used as a replacement\n  for the syntactic restriction.\n\n  The identified issue, that is addressed by the distinction in PLM, is described\n  in section~\\ref{russell-paradox}: Allowing non-propositional formulas in \\<open>\\<beta>\\<close>-convertible\n  \\<open>\\<lambda>\\<close>-expressions without restriction leads to paradoxes.\n\n  Since the embedding is known to be consistent, the issue presents itself in a slightly\n  different fashion: the paradox is constructed under the assumption that \\<open>\\<beta>\\<close>-conversion\n  holds unconditionally for all \\<open>\\<lambda>\\<close>-expressions. In the embedding on the other hand in\n  general \\<open>\\<lambda>\\<close>-expressions have a \\emph{non-standard} semantics and \\<open>\\<beta>\\<close>-conversion\n  only follows as a special case (see~\\ref{artificial-theorems-lambda}).\n  Thereby the consistency of the system is preserved.\n\n  With the definition of \\emph{proper maps} (see~\\ref{lambda-expressions}), the embedding\n  constructs a necessary and sufficient condition on functions that may serve as matrix of\n  a \\<open>\\<lambda>\\<close>-expression while allowing \\<open>\\<beta>\\<close>-conversion.\n\n  The idea is that every \\<open>\\<lambda>\\<close>-expression that is syntactically well-formed\n  in PLM should have a proper map as its matrix. Two subtleties have to be considered, though:\n\n  It was discovered that there are \\<open>\\<lambda>\\<close>-expressions which are part of PLM, whose matrix\n  does not correspond to a proper map in the embedding. The analysis of this issue led to the\n  discovery of a paradox in the formulation of PLM and is discussed in more detail in\n  section~\\ref{paradox}. As a consequence these cases will not constitute proper\n  \\<open>\\<lambda>\\<close>-expressions in future versions of PLM.\n\n  The remaining subtlety is the fact that there are proper maps, that do not correspond to\n  propositional formulas. Some examples have already been mentioned in section~\\ref{artificial-theorems-lambda}.\n  Therefore the embedding suggests that the theory of PLM can be consistently extended to include\n  a larger set of proper, \\<open>\\<beta>\\<close>-convertible \\<open>\\<lambda>\\<close>-expressions. Since the set of\n  relations of PLM already has to be adjusted to prevent the discovered paradox, such an extension presents\n  a viable option.\n\n  Once PLM has recovered from the paradox, future research can consider available\n  options to align the set of relations present in the embedding with the resulting set of\n  relations of the new version of PLM.\n\\<close>"], ["", "subsection\\<open>Terms and Variables\\<close>"], ["", "text\\<open>\n\n  In PLM an individual term can be an individual variable, an individual constant or a definite\n  description. A large number of statements is formulated using specific object-language variables instead\n  of metavariables ranging over arbitrary terms. From such a statement its universal generalization\n  can be derived using the rule GEN,  which then can be instantiated for any individual term,\n  given that it denotes (\\mbox{\\<open>\\<exists>\\<beta> \\<beta> = \\<tau>\\<close>}).\n\n  As already mentioned in sections~\\ref{individual-terms-and-descriptions} and~\\ref{quantification-axioms}\n  the embedding uses a slightly different approach: In the embedding individuals and\n  individual terms have different \\emph{types}.\n\n  The technicalities of this approach and a discussion about the accuracy of this representation\n  were already given in the referenced sections, so at this point it suffices to summarize the\n  resulting differences between the embedding and PLM:\n\n  \\begin{itemize}\n    \\item The individual variables of PLM are represented as variables of type @{type \\<nu>} in the embedding.\n    \\item Individual constants can be represented by declaring constants of type @{type \\<nu>}.\n    \\item Meta-level variables (like \\<open>\\<tau>\\<close>) ranging over all individual terms\n          in PLM can be represented as variables of type @{type \\<kappa>}.\n    \\item Objects of type @{type \\<nu>} have to be explicitly converted to objects of type @{type \\<kappa>}\n          using the decoration @{term \"embedded_style (DUMMY\\<^sup>P)\"}, if they are to be used in a context\n          that allows general individual terms.\n    \\item The axioms of quantification are adjusted to go along with this representation\n          (see~\\ref{quantification-axioms}).\n  \\end{itemize}\n\n  In PLM the situation for relation variables, constants and terms is analog. However, the\n  embedding uses the following simplification in order to avoid the additional complexity\n  introduced for individuals:\n\n  Since at the time of writing PLM unconditionally asserts \\mbox{\\<open>\\<exists>\\<beta> \\<beta> = \\<tau>\\<close>}\n  for any relation term by an axiom, the embedding uses only one type \\<open>\\<Pi>\\<^sub>n\\<close> for each\n  arity of relations. Therefore no special type conversion between variables and terms is necessary\n  and every relation term can immediately be instantiated for a variable of type \\<open>\\<Pi>\\<^sub>n\\<close>.\n  This hides the additional steps PLM employs for such instantiations (the generalization by GEN\n  followed by an instantiation using quantification theory). Since \\mbox{\\<open>\\<exists>\\<beta> \\<beta> = \\<tau>\\<close>} holds\n  unconditionally for relation terms, this simplification is justified.\n\n  However, the recent developments described in section~\\ref{paradox} suggest that \\mbox{\\<open>\\<exists>\\<beta> \\<beta> = \\<tau>\\<close>}\n  will in all likelihood no longer hold unconditionally for every relation term in future versions of PLM.\n  Therefore, future versions of the embedding will have to include a distinction between relation\n  terms and relation variables in a similar way as is already done for individuals. An alternative\n  approach that could result in a more elegant representation would be to implement concepts of free\n  logic based on the research in @{cite FreeLogic} for both individuals and relations.\n\\<close>"], ["", "subsection\\<open>Modally-strict Proofs and the Converse of RN\\<close>"], ["", "(*<*)"], ["", "context PLM\nbegin"], ["", "(*>*)"], ["", "text\\<open>\n\n\\label{differences-modally-strict}\n\nAs described in section~\\ref{PLM-modally-strict} modally-strict theorems\nin the embedding are stated in the form \\mbox{@{term \"[\\<phi> in v]\"}}, so they are stated\nto be semantically true for an arbitrary possible world @{term \"v\"}.\n\nModally-strict theorems in PLM are defined using a proof-theoretic concept:\nmodally-strict proofs are not allowed to use modally-fragile axioms. They are solely derived\nfrom axioms whose necessitations are axioms as well (see~\\ref{axiom-schemata}).\n\nThe metarule RN states in essence that if there is a modally-strict proof for \\<open>\\<phi>\\<close>,\nthen \\<open>\\<box>\\<phi>\\<close> is derivable as a theorem. PLM proves this fact by induction on the length\nof the derivation. Remark (\\ref{PM-abstraction-contingent})@{cite PM}\ngives an example of a case in which the converse is false: if \\<open>\\<box>\\<phi>\\<close> is derivable as a\ntheorem, this does not imply that there is a modally-strict proof for \\<open>\\<phi>\\<close>.\n\nHowever, in the embedding the following is derivable from the semantics of\nthe box operator:\n\n\\begin{center}\n  @{lemma \"[\\<^bold>\\<box>\\<phi> in dw] \\<Longrightarrow> (\\<forall> v . [\\<phi> in v])\" by (simp add: Semantics.T6) }\n\\end{center}\n\nSo although the converse of RN is not true in PLM, an equivalent statement for theorems of\nthe form \\mbox{@{term \"[\\<phi> in v]\"}} in the embedding can be derived from the semantics.\n\nThe modally-strict theorems of PLM are a subset of a larger class of theorems, namely the theorems\nthat are \\emph{necessarily true}. Semantically a statement of the form \\mbox{@{term \"[\\<phi> in v]\"}}\nin the embedding is derivable, whenever @{term \"embedded_style \\<phi>\"} is a \\emph{necessary theorem}.\n\nUnfortunately there is no semantic criterion that allows to decide whether a statement is a necessary\ntheorem or a modally-strict theorem. Therefore, the embedding has to express modally-strict theorems\nas necessary theorems, for which the converse of RN is in fact true.\n\nThis still does not compromise the claim that any statement that is derived in \\ref{TAO_PLM}\nis also derivable in PLM: the basis for this claim is that no proofs in this layer may rely on the\nmeta-logical properties of the embedding, but only the fundamental meta-rules of PLM are allowed\nto derive theorems from the axioms.\nSince the converse of RN is neither a fundamental meta-rule of PLM, nor derivable without using\nthe semantics, it is not stated as an admissible rule for these proofs. Thereby it is guaranteed\nthat no statement of the form \\mbox{@{term \"[\\<phi> in v]\"}} is derived that is not a modally-strict\ntheorem of PLM.\n\nUnfortunately this has the consequence that the proving method @{method PLM_solver} cannot be\nequipped with a reversible elimination rule for the box operator, which reduces its power\nas a proving method. However, preserving the claim that theorems derived in the embedding\nare also theorems of PLM even when restricting to modally-strict theorems was given preference\nover an increased level of automation.\n\\<close>"], ["", "section\\<open>A Paradox in PLM\\<close>"], ["", "text\\<open>\n  \\label{paradox}\n\n  During the analysis of the constructed embedding it was discovered\n  that the formulation of the theory in PLM at the time of writing\n  allowed paradoxical constructions.\n\n  This section first describes the process that led to the discovery of the paradox and\n  the role the embedding played in it, after which the construction of the paradox is\n  outlined in the language of PLM.\n\n  The paradox has since been confirmed by Edward Zalta and a vivid discussion\n  about its repercussions and possible solutions has developed. At the time of writing\n  it has become clear that there are several options to recover from the paradox while\n  in essence retaining the full set of theorems of PLM. So far no final decision has been\n  reached about which option will be implemented in future versions of PLM.\n\\<close>"], ["", "subsection\\<open>Discovery of the Paradox\\<close>"], ["", "text\\<open>\n  The discovery of the paradox originates in the analysis of the concept of \\emph{proper maps}\n  in the embedding and its relation to propositional formulas in PLM, which are the only formulas\n  PLM allows as the matrix of \\<open>\\<lambda>\\<close>-expressions (see~\\ref{differences-lambda}).\n\n  While trying to verify the conjecture, that the matrix of every \\<open>\\<lambda>\\<close>-expression allowed in PLM\n  corresponds to a proper map in the embedding, it was discovered, that \\<open>\\<lambda>\\<close>-expressions of\n  the form \\mbox{\\<open>[\\<lambda>y F\\<iota>x(y[\\<lambda>z Rxz])]\\<close>} in which the bound variable \\<open>y\\<close> occurs in\n  an encoding formula inside the matrix of a definite description, were part of PLM, but their\n  matrix was \\emph{not} a proper map in the embedding and therefore \\<open>\\<beta>\\<close>-conversion\n  was not derivable for these terms.\n\n  Further analysis showed that a modification of the embedding which would allow \\<open>\\<beta>\\<close>-conversion\n  for such expressions, would have to involve a restriction of the Aczel-model (in particular of the map\n  from abstract objects to urelements).\n\n  In order to understand how the Aczel-model could be adequately restricted, the\n  consequences of allowing \\<open>\\<beta>\\<close>-conversion in the mentioned cases \\emph{by assumption}\n  were studied in the embedding. This led to the first proof of inconsistency\n  (see~\\ref{TAO_Paradox_original-paradox}):\n\n  \\begin{center}\n    @{lemma \"(\\<And>G \\<phi>. IsProperInX (\\<lambda>x. embedded_style \\<lparr>G,\\<^bold>\\<iota>y. \\<phi> y x\\<rparr>)) \\<Longrightarrow> False\"\n      by (unfold embedded_style_def, simp, insert Paradox.original_paradox, simp)}\n  \\end{center}\n\n  Under the assumption that @{term \"(\\<lambda>x. embedded_style \\<lparr>G,\\<^bold>\\<iota>y. \\<phi> y x\\<rparr>)\"} is a proper map for\n  arbitrary @{term \"embedded_style G\"} and @{term \"embedded_style \\<phi>\"},\n  @{term \"False\"} is derivable in the embedding. However \\<open>\\<lambda>\\<close>-expressions with the\n  equivalent of such maps as matrix were in fact part of PLM.\n\n  Since the inconsistency can be derived without relying on the meta-logical properties of\n  the embedding, it was immediately possible to translate the proof back to the language of PLM.\n  The resulting formulation then served as the basis for further\n  discussions with Edward Zalta.\n\n  Since then the issue leading to the paradox was identified as the \\emph{description backdoor}\n  (see~\\ref{TAO_Paradox_description_backdoor}) that can be used to construct a variety of\n  paradoxical cases, e.g. the paradox described in section~\\ref{russell-paradox} can be reconstructed.\n  This refined version of the paradox is used in the inconsistency proof in \\ref{TAO_Paradox_russell-paradox}\n  and is outlined in the language of PLM in the next section. The general situation\n  leading to the paradox is repeated without referring to the particularities of the embedding.\n\\<close>"], ["", "subsection\\<open>Construction using the Language of PLM\\<close>"], ["", "text\\<open>\n\n  Object theory distinguishes between propositional and\n  non-propositional formulas. Propositional formulas are not allowed to\n  contain encoding subformulas, so for example \\mbox{\\<open>\\<exists>F xF\\<close>} is not\n  propositional. Only propositional formulas can be the matrix of a\n  \\<open>\\<lambda>\\<close>-expression, so \\mbox{\\<open>[\\<lambda>x \\<exists>F xF]\\<close>} is not a valid term of\n  the theory - it is excluded syntactically.\n\n  The reason for this is that considering \\mbox{\\<open>[\\<lambda>x \\<exists>F xF & \\<not>Fx]\\<close>} a valid, denoting\n  \\<open>\\<lambda>\\<close>-expression for which \\<open>\\<beta>\\<close>-conversion holds would result in a\n  paradox as described in section~\\ref{russell-paradox}.\n\n  Excluding non-propositional formulas in\n  \\<open>\\<lambda>\\<close>-expressions was believed to be sufficient to prevent such\n  inconsistencies. This was shown to be incorrect, though.\n\n  The problem is the \\emph{description backdoor}. The term \\mbox{\\<open>[\\<lambda>y F\\<iota>x\\<psi>]\\<close>}\n  is well-formed, even if \\<open>\\<psi>\\<close> is \\emph{not} propositional. This is due to the definition\n  of \\emph{subformula}: \\<open>\\<psi>\\<close> is \\emph{not} a subformula of \\<open>F\\<iota>x\\<psi>\\<close>, so \\<open>\\<psi>\\<close> \\emph{may} contain\n  encoding subformulas itself and \\<open>F\\<iota>x\\<psi>\\<close> is still a propositional formula.\n\n  This was deemed to be no problem and for cases like \\mbox{\\<open>[\\<lambda>y F\\<iota>x(xG)]\\<close>} as\n  they are mentioned and used in PLM this is indeed true.\n\n  It had not been considered that \\<open>y\\<close> may appear within the matrix of\n  such a description and more so, it may appear in an encoding expression, for example \n  \\mbox{\\<open>[\\<lambda>y F\\<iota>x(xG & yG)]\\<close>} is still a propositional formula.\n\n  Therefore, the following construction is possible:\n\n  \\begin{equation}\\tag{1}\n    \\<open>[\\<lambda>y [\\<lambda>z \\<forall>p(p\\<rightarrow>p)]\\<iota>x(x = y & \\<psi>)]\\<close>\n  \\end{equation}\n\n  Here \\<open>\\<psi>\\<close> can be an arbitrary non-propositional formula in which \\<open>x\\<close> and \\<open>y\\<close>\n  may be free and (1) is still a valid, denoting \\<open>\\<lambda>\\<close>-expression for which\n  \\<open>\\<beta>\\<close>-conversion holds.\n\n  By \\<open>\\<beta>\\<close>-conversion and description theory the following is derivable:\n\n  \\begin{equation}\\tag{2}\n    \\<open>[\\<lambda>y [\\<lambda>z \\<forall>p(p\\<rightarrow>p)]\\<iota>x(x = y & \\<psi>)]x \\<equiv> \\<psi>\\<^sup>x\\<^sub>y\\<close>\n  \\end{equation}\n\n  \\begin{remark}\n    Using a modally-strict proof only the following is derivable:\\\\\n    \\mbox{\\<open>[\\<lambda>y [\\<lambda>z \\<forall>p(p\\<rightarrow>p)]\\<iota>x(x = y & \\<psi>)]x \\<equiv> \\<A>\\<psi>\\<^sup>x\\<^sub>y\\<close>}\\\\\n    For the construction of the paradox, the modally-fragile statement\n    is sufficient. However, it is possible to construct similar paradoxical cases\n    without appealing to any modally-fragile axioms or theorems as well.\n  \\end{remark}\n\n  This effectively undermines the intention of restricting \\<open>\\<lambda>\\<close>-expressions\n  to only propositional formulas:\n\n  Although \\mbox{\\<open>[\\<lambda>x \\<exists>F xF & \\<not>Fx]\\<close>} is not part of the language, it is possible to\n  formulate the following instead:\n\n  \\begin{equation}\\tag{3}\n    \\<open>[\\<lambda>y [\\<lambda>z \\<forall>p(p\\<rightarrow>p)]\\<iota>x(x = y & (\\<exists>F yF & \\<not>Fy))]\\<close>\n  \\end{equation}\n\n  If one considers (2) now, one can see that this \\<open>\\<lambda>\\<close>-expressions behaves\n  exactly the way that \\mbox{\\<open>[\\<lambda>x \\<exists>F xF & \\<not>Fx]\\<close>} would, if it were part of the\n  language, i.e. the result of \\<open>\\<beta>\\<close>-reduction for \\mbox{\\<open>[\\<lambda>x \\<exists>F xF & \\<not>Fx]\\<close>} would be\n  the same as the right hand side of (2) when applied to (3). Therefore, the \\<open>\\<lambda>\\<close>-expression\n  in (3) can be used to reproduce the paradox described in section~\\ref{russell-paradox}.\n\\<close>"], ["", "subsection\\<open>Possible Solutions\\<close>"], ["", "text\\<open>\n  Fortunately no theorems were derived in PLM, that actually use problematic\n  \\<open>\\<lambda>\\<close>-expressions as described above. Therefore, it is possible to recover from the\n  paradox without losing any theorems. At the time of writing, it seems likely that\n  a concept of \\emph{proper} \\<open>\\<lambda>\\<close>-expressions will be introduced to the theory and only\n  \\emph{proper} \\<open>\\<lambda>\\<close>-expressions will be forced to have denotations and allow \\<open>\\<beta>\\<close>-conversion.\n  Problematic \\<open>\\<lambda>\\<close>-expressions that would lead to paradoxes, will not be considered \\emph{proper}.\n  Several options are available to define the propriety of \\emph{\\<open>\\<lambda>\\<close>-expressions}\n  and to adjust PLM in detail.\n\n  As a consequence the purely syntactical distinction between propositional\n  and non-propositional formulas is no longer sufficient to guarantee\n  that every relation term has a denotation. The embedding of the theory shows\n  that an adequate definition of \\emph{proper \\<open>\\<lambda>\\<close>-expressions}\n  can consistently replace this distinction entirely yielding a broader set of relations.\n  The philosophical implications of such a radical modification of the theory\n  have not yet been analyzed entirely though, and at the time of writing\n  it is an open question whether such a modification may be implemented in\n  future versions of PLM.\n\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context PLM *)\n(*>*)"], ["", "section\\<open>A Meta-Conjecture about Possible Worlds\\<close>"], ["", "(*<*)"], ["", "context PossibleWorlds\nbegin"], ["", "(*>*)"], ["", "text\\<open>\n  A conversation between Bruno Woltzenlogel Paleo and Edward Zalta about the Theory\n  of Abstract Objects led to the following meta-conjecture:\n\n  \\textquote{\n      For every syntactic possible world \\emph{w}, there exists a semantic\n      point \\emph{p} which is the denotation of \\emph{w}.\n  }\\footnote{This formulation originates in the resulting e-mail correspondence between\n  Bruno Woltzenlogel Paleo and Christoph Benzm\\\"uller.}\n\n  Since the embedding constructs a representation of the semantics of PLM, it was\n  possible to formally analyze the relationship between syntactic and semantic possible worlds\n  and arrive at the following theorems (see~\\ref{TAO_PossibleWorlds}):\n\n  \\begin{itemize}\n    \\item @{thm SemanticPossibleWorldForSyntacticPossibleWorlds[of w]}\n    \\item @{thm SyntacticPossibleWorldForSemanticPossibleWorlds[of w]}\n  \\end{itemize}\n\n  The first statement shows that for every \\emph{syntactic} possible world @{term \"embedded_style x\"}\n  there is a \\emph{semantic} possible world @{term \"v\"}, such that a proposition is syntactically\n  true in @{term \"embedded_style x\"}, if and only if it is semantically true in @{term \"v\"}.\n\n  The second statement shows that for every \\emph{semantic} possible world @{term \"v\"} there\n  is a \\emph{syntactic} possible world @{term \"embedded_style x\"}, such that a proposition is semantically\n  true in @{term \"v\"}, if and only if it is \\emph{syntactically} true in @{term \"embedded_style x\"}.\n\n  This result extends the following theorems already derived syntactically in PLM (\\<open>w\\<close> is restricted\n  to only range over syntactic possible worlds):\n  \\begin{itemize}\n    \\item \\<open>\\<diamond>p \\<equiv> \\<exists>w(w \\<Turnstile> p)\\<close> \\hfill{(\\ref{PM-fund}.1)}\n    \\item \\<open>\\<box>p \\<equiv> \\<forall>w(w \\<Turnstile> p)\\<close> \\hfill{(\\ref{PM-fund}.2)}\n  \\end{itemize}\n\n  Whereas the syntactic statements of PLM already show the relation between the modal operators\n  and syntactic possible worlds, the semantic statements derived in the embedding show that\n  there is in fact a natural bijection between syntactic and semantic possible worlds.\n\n  This example shows that a semantical embedding allows a detailed analysis of the semantical\n  properties of a theory and to arrive at interesting meta-logical results.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(* context PossibleWorlds *)\n(*>*)"], ["", "section\\<open>Functional Object Theory\\<close>"], ["", "text\\<open>\n  The first and foremost goal of the presented work was to show that the second-order fragment of\n  the Theory of Abstract Objects as described in PLM can be represented in functional\n  higher-order logic using a shallow semantical embedding.\n\n  As a result a theory was constructed in Isabelle/HOL that - although its faithfulness\n  is yet to be formally verified - is most likely able to represent and verify all reasoning\n  in the target theory. A formal analysis of the faithfulness of the embedding\n  is unfortunately not possible at this time, since the theory of PLM first has to be adjusted\n  to prevent the discovered paradox. Depending on the precise modifications of PLM the embedding\n  will have to be adjusted accordingly, after which the question can be revisited.\n\n  The embedding goes to great lengths to construct a restricted environment, in which it is possible\n  to derive new theorems that can easily be translated back to the reference system of PLM.\n  The fact that the construction of the paradox described in section~\\ref{paradox} could be reproduced\n  in the target logic, strongly indicates the merits and success of this approach.\n\n  Independently of the relation between the embedding and the target system, a byproduct\n  of the embedding is a working functional variant of object theory that deserves to be studied in\n  its own right. To that end future research may want to drop the layered structure of the embedding and\n  dismiss all constructions that solely serve to restrict reasoning in the embedding in order to\n  more closely reproduce the language of PLM. Automated reasoning in the resulting theory will be\n  significantly more powerful and the interesting properties of the original theory, that result\n  from the introduction of abstract objects and encoding, can still be preserved.\n\\<close>"], ["", "section\\<open>Relations vs. Functions\\<close>"], ["", "text\\<open>\n  As mentioned in the introduction, Oppenheimer and Zalta argue that relational type theory is more\n  fundamental than functional type theory (see @{cite rtt}). One of their main arguments is that the\n  Theory of Abstract Objects is not representable in functional type theory.\n  The success of the presented embedding, however, suggests that the topic has to be\n  examined more closely.\n\n  Their result is supported by the presented work in the following sense: it is impossible to\n  represent the Theory of Abstract Objects by representing its \\<open>\\<lambda>\\<close>-expressions directly as\n  primitive \\<open>\\<lambda>\\<close>-expressions in functional logic. Furthermore, exemplification cannot\n  be represented classically as function application, while at the same time introducing encoding\n  as a second mode of predication.\n\n  This already establishes that the traditional approach of translating relational type theory\n  to functional type theory in fact fails for the Theory of Abstract Objects. A simple version of\n  functional type theory, that only involves two primitive types (for individuals and propositions),\n  is insufficient for a representation of the theory.\n\n  The embedding does not share several of the properties of\n  the representative functional type theory constructed in @{cite \\<open>pp. 9-12\\<close> rtt}:\n\n  \\begin{itemize}\n    \\item Relations are \\emph{not} represented as functions from individuals to propositions.\n    \\item Exemplification is \\emph{not} represented as simple function application.\n    \\item The \\<open>\\<lambda>\\<close>-expressions of object theory are \\emph{not} represented as\n          primitive \\<open>\\<lambda>\\<close>-expressions.\n  \\end{itemize}\n\n  To illustrate the general schema that the embedding uses instead assume\n  that there is a primitive type for each arity of relations \\<open>R\\<^sub>n\\<close>.\n  Let further \\<open>\\<iota>\\<close> be the type of individuals and \\<open>\\<o>\\<close> be the type of propositions.\n  The general construct is now the following:\n\n  \\begin{itemize}\n    \\item Exemplification (of an \\<open>n\\<close>-place relation) is a function of type \\mbox{\\<open>R\\<^sub>n\\<Rightarrow>\\<iota>\\<Rightarrow>\\<dots>\\<Rightarrow>\\<iota>\\<Rightarrow>\\<o>\\<close>}.\n    \\item Encoding is a function of type \\mbox{\\<open>\\<iota>\\<Rightarrow>R\\<^sub>1\\<Rightarrow>\\<o>\\<close>}.\n    \\item To represent \\<open>\\<lambda>\\<close>-expressions functions \\<open>\\<Lambda>\\<^sub>n\\<close> of type \\mbox{\\<open>(\\<iota>\\<Rightarrow>\\<dots>\\<Rightarrow>\\<iota>\\<Rightarrow>\\<o>)\\<Rightarrow>R\\<^sub>n\\<close>} are introduced.\n          The \\<open>\\<lambda>\\<close>-expression \\mbox{\\<open>[\\<lambda>x\\<^sub>1\\<dots>x\\<^sub>n \\<phi>]\\<close>} of object theory is represented as\n          \\mbox{\\<open>\\<Lambda>\\<^sub>n[\\<lambda>x\\<^sub>1\\<dots>x\\<^sub>n \\<phi>]\\<close>}.\n  \\end{itemize}\n\n  The Theory of Abstract Objects restricts the matrix of \\<open>\\<lambda>\\<close>-expressions to propositional\n  formulas, so not all functions of type \\mbox{\\<open>\\<iota>\\<Rightarrow>\\<dots>\\<Rightarrow>\\<iota>\\<Rightarrow>\\<o>\\<close>} are supposed to denote relations.\n  However, since in classical functional type theory functions are total, \\<open>\\<Lambda>\\<^sub>n\\<close> has to map\n  all these functions to some object of type \\<open>R\\<^sub>n\\<close>. To solve this problem concepts used in\n  the embedding of free logic can help\\footnote{See the embedding of free logic constructed in @{cite FreeLogic}.}.\n  The function \\<open>\\<Lambda>\\<^sub>n\\<close> can map functions of type \\mbox{\\<open>\\<iota>\\<Rightarrow>\\<dots>\\<Rightarrow>\\<iota>\\<Rightarrow>\\<o>\\<close>} that do not\n  correspond to propositional formulas to objects of type \\<open>R\\<^sub>n\\<close> that\n  represent invalid (resp. non-existing) relations. For invalid relations the functions used\n  to represent encoding and exemplification can be defined to map to an object of type \\<open>\\<o>\\<close>\n  that represents invalid propositions.\n\n  Oppenheimer and Zalta argue that using a free logic and letting non-propositional\n  formulas fail to denote is not an option, since it prevents classical reasoning for non-propositional\n  formulas\\footnote{See @{cite \\<open>pp. 30-31\\<close> rtt}.}. Although this is true for the case of a simple\n  functional type theory, it does not apply to the constructed theory: since only objects of\n  type \\<open>R\\<^sub>n\\<close> may fail to denote, non-propositional reasoning is unaffected.\n\n\\begin{remark}\n  Although the constructed functional type theory is based on the general structure of the\n  presented embedding, instead of introducing concepts of free logic, \\<open>\\<lambda>\\<close>-expressions\n  involving non-propositional formulas are assigned \\emph{non-standard} denotations,\n  i.e. they do denote, but \\<open>\\<beta>\\<close>-conversion only holds under certain conditions\n  (see~\\ref{differences-lambda}). Although this concept has merits as well, future versions of the embedding\n  may instead utilize the concepts described in @{cite FreeLogic} to replace this construction\n  by a free logic implementation that will more closely reflect the concepts of propositional formulas\n  and \\<open>\\<lambda>\\<close>-expressions in object theory.\n\\end{remark}\n\n\n  The constructed theory can represent the relations and \\<open>\\<lambda>\\<close>-expressions of object theory,\n  as well as exemplification and encoding. Furthermore, the embedding shows that it has a model and\n  that an adequate intensional interpretation of propositions can be used to\n  preserve the desired hyperintensionality of relations in \\<open>\\<lambda>\\<close>-expressions.\n\n  In summary it can be concluded that a representation of object theory in functional type theory\n  is feasible, although it is connected with a fair amount of complexity (i.e. the introduction of\n  additional primitive types and the usage of concepts of intensional and free logic).\n  On the other hand, whether this result contradicts the philosophical claim that relations are\n  more fundamental than functions, is still debatable considering the fact that the proposed\n  construction has to introduce new primitive types for relations\\footnote{Note, however,\n  that the embedding can represent relations as functions acting on urelements following the\n  Aczel-model.} and the construction is complex in general. Further it has to be noted that so\n  far only the second-order fragment of object theory has been considered and the full\n  type-theoretic version of the theory may present further challenges.\n\n\\pagebreak\n\\<close>"], ["", "section\\<open>Conclusion\\<close>"], ["", "text\\<open>\n  The presented work shows that shallow semantical embeddings in HOL have the potential to represent\n  even highly complex theories that originate in a fundamentally different tradition of logical\n  reasoning (e.g. relational instead of functional type theory). The presented embedding represents\n  the most ambitious project in this area so far and its success clearly shows the merits of the approach.\n\n  Not only could the embedding uncover a previously unknown paradox in the formulation of its target\n  theory, but it could contribute to the understanding of the relation between functional and\n  relational type theory and provide further insights into the general structure of the target theory,\n  its semantics and possible models. It can even show that a consistent extension of the theory\n  is possible that can increase its expressibility.\n\n  For the field of mathematics an analysis of chapters 14 and 15 of PLM, that construct\n  natural numbers and theoretical mathematical objects and relations in object theory,\n  is of particular interest. The embedding can be a significant aid in the study of these chapters, since the\n  properties of the derived objects and relations can immediately be analyzed and verified using the extensive library for abstract\n  mathematical reasoning already present in Isabelle/HOL as a reference.\n\n  The presented work introduces novel concepts that can benefit future endeavors of semantical\n  embeddings in general: a layered structure allows the representation of a target theory without\n  extensive prior results about its model structure and provides the means to comprehensively\n  study potential models. Custom proving methods can benefit automated reasoning in an embedded\n  logic and provide the means to reproduce even complex deductive rules of a target system\n  in a user-friendly manner.\n\n  The fact that the embedding can construct a verified environment which allows to conveniently\n  prove and verify theorems in the complex target system while retaining the support of automated\n  reasoning tools, shows the great potential of semantical embeddings in providing the means\n  for a productive interaction between humans and computer systems.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"]]}