{"file_name": "/home/qj213/afp-2021-10-22/thys/Collections/Userguides/ICF_Userguide.thy", "working_directory": "/home/qj213/afp-2021-10-22/thys/Collections", "problem_names": ["lemma rbt_restrict_list_correct: \n  assumes [simp]: \"rs.invar s\"\n  shows \"rbt_restrict_list s l = [x\\<leftarrow>l. x\\<in>rs.\\<alpha> s]\"", "lemma hs_to_list'_correct: \n  assumes INV: \"hs.invar s\"\n  shows \"set (hs_to_list' s) = hs.\\<alpha> s\"", "lemma hs_bex_correct: \n  \"hs.invar s \\<Longrightarrow> hs_bex s P \\<longleftrightarrow> (\\<exists>x\\<in>hs.\\<alpha> s. P x)\""], "translations": [["", "lemma rbt_restrict_list_correct: \n  assumes [simp]: \"rs.invar s\"\n  shows \"rbt_restrict_list s l = [x\\<leftarrow>l. x\\<in>rs.\\<alpha> s]\""], ["proof (prove)\ngoal (1 subgoal):\n 1. rbt_restrict_list s l = filter (\\<lambda>x. x \\<in> rs.\\<alpha> s) l", "by (simp add: rbt_restrict_list_def rs.memb_correct)"], ["", "text \\<open>\n  The lemma @{thm [source] rs.memb_correct}: @{thm [display] rs.memb_correct[no_vars]} \n\n  states correctness of the @{const rs.memb}-function. \n  The function @{const rs.\\<alpha>} maps a red-black-tree to the set that it represents.\n  Moreover, we have to explicitely keep track of the invariants of the used data structure,\n  in this case red-black trees. \n  The premise @{thm (prem 1) rs.memb_correct} represents the invariant assumption for the collection data structure.\n  Red-black-trees are invariant-free, so this defaults to @{term \"True\"}.\n  For uniformity reasons, these (unnecessary) invariant assumptions are present in all correctness lemmata.\n\n  Many of the correctness lemmas for standard RBT-set-operations are summarized by the lemma @{thm [source] rs.correct}:\n    @{thm [display] rs.correct[no_vars]}\n\\<close>"], ["", "text \\<open>\n  All implementations provided by this library are compatible with the Isabelle/HOL code-generator.\n  Now follow some examples of using the code-generator.\n  Note that the code generator can only generate code for plain constants \n  without arguments, while the operations like @{const rs.memb} have arguments,\n  that are only hidden by an abbreviation.\n\\<close>"], ["", "text \\<open>\n  There are conversion functions from lists to sets and, vice-versa, from sets to lists:\n\\<close>"], ["", "definition \"conv_tests \\<equiv> (\n  rs.from_list [1::int .. 10],\n  rs.to_list (rs.from_list [1::int .. 10]),\n  rs.to_sorted_list (rs.from_list [1::int,5,6,7,3,4,9,8,2,7,6]),\n  rs.to_rev_list (rs.from_list [1::int,5,6,7,3,4,9,8,2,7,6])\n)\""], ["", "ML_val \\<open>@{code conv_tests}\\<close>"], ["", "text \\<open>\n  Note that sets make no guarantee about ordering, hence the only thing we can \n  prove about conversion from sets to lists is:\n    @{thm [source] rs.to_list_correct}: @{thm [display] rs.to_list_correct[no_vars]}\n\n  Some sets, like red-black-trees, also support conversion to sorted lists,\n  and we have:\n    @{thm [source] rs.to_sorted_list_correct}: @{thm [display] rs.to_sorted_list_correct[no_vars]} and\n    @{thm [source] rs.to_rev_list_correct}: @{thm [display] rs.to_rev_list_correct[no_vars]} \n\\<close>"], ["", "definition \"restrict_list_test \\<equiv> rbt_restrict_list (rs.from_list [1::nat,2,3,4,5]) [1::nat,9,2,3,4,5,6,5,4,3,6,7,8,9]\""], ["", "ML_val \\<open>@{code restrict_list_test}\\<close>"], ["", "definition \"big_test n = (rs.from_list [(1::int)..n])\""], ["", "ML_val \\<open>@{code big_test} (@{code int_of_integer} 9000)\\<close>"], ["", "subsection \"Theories\""], ["", "text \\<open>\n  To make available the whole collections framework to your formalization, \n  import the theory @{theory Collections.Collections} which includes everything. Here is a\n  small selection:\n  \\begin{description}\n    \\item[@{theory Collections.SetSpec}] Specification of sets and set functions\n    \\item[@{theory Collections.SetGA}] Generic algorithms for sets\n    \\item[@{theory Collections.SetStdImpl}] Standard set implementations (list, rb-tree, hashing, tries)\n    \\item[@{theory Collections.MapSpec}] Specification of maps\n    \\item[@{theory Collections.MapGA}] Generic algorithms for maps\n    \\item[@{theory Collections.MapStdImpl}] Standard map implementations (list,rb-tree, hashing, tries)\n    \\item[@{theory Collections.ListSpec}] Specification of lists\n    \\item[@{theory Collections.Fifo}] Amortized fifo queue\n    \\item[@{theory Collections.DatRef}] Data refinement for the while combinator\n  \\end{description}\n\n\\<close>"], ["", "subsection \"Iterators\""], ["", "text \\<open>An important concept when using collections are iterators. An iterator is a kind of generalized fold-functional.\n  Like the fold-functional, it applies a function to all elements of a set and modifies a state. There are\n  no guarantees about the iteration order. But, unlike the fold functional, you can prove useful properties of iterations\n  even if the function is not left-commutative. Proofs about iterations are done in invariant style, establishing an\n  invariant over the iteration.\n\n  The iterator combinator for red-black tree sets is @{const rs.iterate}, and the proof-rule that is usually used is:\n    @{thm [source] rs.iteratei_rule_P}: @{thm [display] rs.iteratei_rule_P[no_vars]}\n\n  The invariant @{term I} is parameterized with the set of remaining elements that have not yet been iterated over and the\n  current state. The invariant has to hold for all elements remaining and the initial state: @{term \"I (rs.\\<alpha> S) \\<sigma>0\"}. \n  Moreover, the invariant has to be preserved by an iteration step: \n    @{term [display] \"\\<And>x it \\<sigma>. \\<lbrakk>x \\<in> it; it \\<subseteq> rs.\\<alpha> S; I it \\<sigma>\\<rbrakk> \\<Longrightarrow> I (it - {x}) (f x \\<sigma>)\"}\n  And the proposition to be shown for the final state must be a consequence of the invarant for no \n  elements remaining: @{term \"\\<And>\\<sigma>. I {} \\<sigma> \\<Longrightarrow> P \\<sigma>\"}. \n\n  A generalization of iterators are {\\em interruptible iterators} where iteration is only continues while some condition on the state holds.\n  Reasoning over interruptible iterators is also done by invariants: \n    @{thm [source] rs.iteratei_rule_P}: @{thm [display] rs.iteratei_rule_P[no_vars]}\n\n  Here, interruption of the iteration is handled by the premise\n    @{term [display] \"\\<And>\\<sigma> it. \\<lbrakk>it \\<subseteq> rs.\\<alpha> S; it \\<noteq> {}; \\<not> c \\<sigma>; I it \\<sigma>\\<rbrakk> \\<Longrightarrow> P \\<sigma>\"}\n  that shows the proposition from the invariant for any intermediate state of the \n  iteration where the continuation condition \n  does not hold (and thus the iteration is interrupted).\n\\<close>"], ["", "text \\<open>\n  As an example of reasoning about results of iterators, we implement a function\n  that converts a hashset to a list that contains precisely the elements of the set.\n\\<close>"], ["", "definition \"hs_to_list' s == hs.iteratei s (\\<lambda>_. True) (#) []\""], ["", "text \\<open>\n  The correctness proof works by establishing the invariant that the list contains\n  all elements that have already been iterated over.\n  Again @{term \"hs.invar s\"} denotes the invariant for hashsets which defaults to @{term \"True\"}.\n\\<close>"], ["", "lemma hs_to_list'_correct: \n  assumes INV: \"hs.invar s\"\n  shows \"set (hs_to_list' s) = hs.\\<alpha> s\""], ["proof (prove)\ngoal (1 subgoal):\n 1. set (hs_to_list' s) = hs.\\<alpha> s", "apply (unfold hs_to_list'_def)"], ["proof (prove)\ngoal (1 subgoal):\n 1. set (hs.iterate s (#) []) = hs.\\<alpha> s", "apply (rule_tac \n    I=\"\\<lambda>it \\<sigma>. set \\<sigma> = hs.\\<alpha> s - it\"\n    in hs.iterate_rule_P[OF INV])"], ["proof (prove)\ngoal (3 subgoals):\n 1. set [] = hs.\\<alpha> s - hs.\\<alpha> s\n 2. \\<And>x it \\<sigma>.\n       \\<lbrakk>x \\<in> it; it \\<subseteq> hs.\\<alpha> s;\n        set \\<sigma> = hs.\\<alpha> s - it\\<rbrakk>\n       \\<Longrightarrow> set (x # \\<sigma>) = hs.\\<alpha> s - (it - {x})\n 3. \\<And>\\<sigma>.\n       set \\<sigma> = hs.\\<alpha> s - {} \\<Longrightarrow>\n       set \\<sigma> = hs.\\<alpha> s", "txt \\<open>The resulting proof obligations are easily discharged using auto:\\<close>"], ["proof (prove)\ngoal (3 subgoals):\n 1. set [] = hs.\\<alpha> s - hs.\\<alpha> s\n 2. \\<And>x it \\<sigma>.\n       \\<lbrakk>x \\<in> it; it \\<subseteq> hs.\\<alpha> s;\n        set \\<sigma> = hs.\\<alpha> s - it\\<rbrakk>\n       \\<Longrightarrow> set (x # \\<sigma>) = hs.\\<alpha> s - (it - {x})\n 3. \\<And>\\<sigma>.\n       set \\<sigma> = hs.\\<alpha> s - {} \\<Longrightarrow>\n       set \\<sigma> = hs.\\<alpha> s", "apply auto"], ["proof (prove)\ngoal:\nNo subgoals!", "done"], ["", "text \\<open>\n  As an example for an interruptible iterator, \n  we define a bounded existential-quantification over the list elements.\n  As soon as the first element is found that fulfills the predicate,\n  the iteration is interrupted.\n  The state of the iteration is simply a boolean, indicating the (current) result of the quantification:\n\\<close>"], ["", "definition \"hs_bex s P == hs.iteratei s (\\<lambda>\\<sigma>. \\<not> \\<sigma>) (\\<lambda>x \\<sigma>. P x) False\""], ["", "lemma hs_bex_correct: \n  \"hs.invar s \\<Longrightarrow> hs_bex s P \\<longleftrightarrow> (\\<exists>x\\<in>hs.\\<alpha> s. P x)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. hs.invar s \\<Longrightarrow>\n    hs_bex s P = (\\<exists>x\\<in>hs.\\<alpha> s. P x)", "apply (unfold hs_bex_def)"], ["proof (prove)\ngoal (1 subgoal):\n 1. hs.invar s \\<Longrightarrow>\n    hs.iteratei s Not (\\<lambda>x \\<sigma>. P x) False =\n    (\\<exists>x\\<in>hs.\\<alpha> s. P x)", "txt \\<open>The invariant states that the current result matches the result of the quantification\n    over the elements already iterated over:\\<close>"], ["proof (prove)\ngoal (1 subgoal):\n 1. hs.invar s \\<Longrightarrow>\n    hs.iteratei s Not (\\<lambda>x \\<sigma>. P x) False =\n    (\\<exists>x\\<in>hs.\\<alpha> s. P x)", "apply (rule_tac \n    I=\"\\<lambda>it \\<sigma>. \\<sigma> \\<longleftrightarrow> (\\<exists>x\\<in>hs.\\<alpha> s - it. P x)\" \n    in hs.iteratei_rule_P)"], ["proof (prove)\ngoal (5 subgoals):\n 1. hs.invar s \\<Longrightarrow> hs.invar s\n 2. hs.invar s \\<Longrightarrow>\n    False = (\\<exists>x\\<in>hs.\\<alpha> s - hs.\\<alpha> s. P x)\n 3. \\<And>x it \\<sigma>.\n       \\<lbrakk>hs.invar s; \\<not> \\<sigma>; x \\<in> it;\n        it \\<subseteq> hs.\\<alpha> s;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - it. P x)\\<rbrakk>\n       \\<Longrightarrow> P x =\n                         (\\<exists>x\\<in>hs.\\<alpha> s - (it - {x}). P x)\n 4. \\<And>\\<sigma>.\n       \\<lbrakk>hs.invar s;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - {}. P x)\\<rbrakk>\n       \\<Longrightarrow> \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s. P x)\n 5. \\<And>\\<sigma> it.\n       \\<lbrakk>hs.invar s; it \\<subseteq> hs.\\<alpha> s; it \\<noteq> {};\n        \\<not> \\<not> \\<sigma>;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - it. P x)\\<rbrakk>\n       \\<Longrightarrow> \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s. P x)", "txt \\<open>The resulting proof obligations are easily discharged by auto:\\<close>"], ["proof (prove)\ngoal (5 subgoals):\n 1. hs.invar s \\<Longrightarrow> hs.invar s\n 2. hs.invar s \\<Longrightarrow>\n    False = (\\<exists>x\\<in>hs.\\<alpha> s - hs.\\<alpha> s. P x)\n 3. \\<And>x it \\<sigma>.\n       \\<lbrakk>hs.invar s; \\<not> \\<sigma>; x \\<in> it;\n        it \\<subseteq> hs.\\<alpha> s;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - it. P x)\\<rbrakk>\n       \\<Longrightarrow> P x =\n                         (\\<exists>x\\<in>hs.\\<alpha> s - (it - {x}). P x)\n 4. \\<And>\\<sigma>.\n       \\<lbrakk>hs.invar s;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - {}. P x)\\<rbrakk>\n       \\<Longrightarrow> \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s. P x)\n 5. \\<And>\\<sigma> it.\n       \\<lbrakk>hs.invar s; it \\<subseteq> hs.\\<alpha> s; it \\<noteq> {};\n        \\<not> \\<not> \\<sigma>;\n        \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s - it. P x)\\<rbrakk>\n       \\<Longrightarrow> \\<sigma> = (\\<exists>x\\<in>hs.\\<alpha> s. P x)", "apply auto"], ["proof (prove)\ngoal:\nNo subgoals!", "done"], ["", "section \"Structure of the Framework\""], ["", "text_raw \\<open>\\label{sec:userguide.structure}\\<close>"], ["", "text \\<open>\n  The concepts of the framework are roughly based on the object-oriented concepts of interfaces, implementations and generic algorithms.\n\n  The concepts used in the framework are the following:\n  \\begin{description}\n    \\item[Interfaces] An interface describes some concept by providing an abstraction mapping $\\alpha$ to a related Isabelle/HOL-concept.\n      The definition is generic in the datatype used to implement the concept (i.e. the concrete data structure). An interface is specified by means \n      of a locale that fixes the abstraction mapping and an invariant.\n      For example, the set-interface contains an abstraction mapping to sets, and is specified by the locale \\<open>SetSpec.set\\<close>.\n      An interface roughly matches the concept of a (collection) interface in Java, e.g. {\\em java.util.Set}.\n  \n    \\item[Functions] A function specifies some functionality involving interfaces. A function is specified by means of a locale.\n                      For example, membership query for a set is specified by the locale @{const [source] SetSpec.set_memb} and\n                      equality test between two sets is a function specified by @{const [source] SetSpec.set_equal}.\n                      A function roughly matches a method declared in an interface, e.g. {\\em java.util.Set\\#contains, java.util.Set\\#equals}.\n\n    \\item[Operation Records] In order to reference an interface with a standard\n      set of operations, those operations are summarized in a record, and there \n      is a locale that fixes this record, and makes available all operations.\n      For example, the locale @{const [source] SetSpec.StdSet} fixes a record\n      of standard set operations and assumes their correctness. It also defines \n      abbreviations to easily access the members of the record. Internally,\n      all the standard operations, like @{const hs.memb}, are introduced by\n      interpretation of such an operation locale.\n\n    \\item[Generic Algorithms] A generic algorithm specifies, in a generic way,\n      how to implement a function using other functions. Usually, a generic \n      algorithm lives in a locale that imports the necessary operation locales.\n      For example, the locale @{const SetGA.cart_loc} defines a generic \n      algorithm for the cartesian product between two sets.\n\n      There is no direct match of generic algorithms in the Java\n      Collections Framework. The most related concept are abstract\n      collection interfaces, that provide some default algorithms,\n      e.g. {\\em java.util.AbstractSet}.  The concept of {\\em Algorithm} in\n      the C++ Standard Template Library \\cite{C++STL} matches the concept\n      of Generic Algorithm quite well.\n\n\n    \\item[Implementation] An implementation of an interface provides a\n       data structure for that interface together with an abstraction\n       mapping and an invariant. Moreover, it provides implementations\n       for some (or all) functions of that interface.  For example,\n       red-black trees are an implementation of the set-interface,\n       with the abstraction mapping @{const rs.\\<alpha>} and invariant\n       @{const rs.invar}; and the constant @{const rs.ins} implements\n       the insert-function, as can be verified by \n       @{lemma \"set_ins rs.\\<alpha> rs.invar rs.ins\" by unfold_locales}.\n       An implementation matches a concrete collection\n       interface in Java, e.g. {\\em java.util.TreeSet}, and the\n       methods implemented by such an interface, e.g. {\\em\n       java.util.TreeSet\\#add}. \n\n\n    \\item[Instantiation] An instantiation of a generic algorithm\n        provides actual implementations for the used functions. For\n        example, the generic cartesian-product algorithm can be\n        instantiated to use red-black-trees for both arguments, and output\n        a list, as will be illustrated below in Section~\\ref{sec:inst_gen_algo}.\n        While some of the functions\n        of an implementation need to be implemented specifically, many\n        functions may be obtained by instantiating generic algorithms.\n        In Java, instantiation of a generic algorithm is matched most\n        closely by inheriting from an abstract collection\n        interface. In the C++ Standard Template Library instantiation\n        of generic algorithms is done implicitely by the compiler.\n\n  \\end{description}\n\n\\<close>"], ["", "subsection \"Instantiation of Generic Algorithms\""], ["", "text_raw \\<open>\\label{sec:inst_gen_algo}\\<close>"], ["", "text \\<open>A generic algorithm is instantiated by interpreting its locale with \n    the wanted implementations. For example, to obtain a cartesian product\n    between two red-black trees, yielding a list, we can do the following:\\<close>"], ["", "setup Locale_Code.open_block"], ["", "interpretation rrl: cart_loc rs_ops rs_ops ls_ops"], ["proof (prove)\ngoal (1 subgoal):\n 1. cart_loc rs_ops rs_ops ls_ops", "by unfold_locales"], ["", "setup Locale_Code.close_block"], ["", "setup \\<open>ICF_Tools.revert_abbrevs \"rrl\"\\<close>"], ["", "text \\<open>It is then available under the expected name:\\<close>"], ["", "term \"rrl.cart\""], ["", "text \\<open>Note the three lines of boilerplate code, that work around some \n    technical problems of Isabelle/HOL: The \\<open>Locale_Code.open_block\\<close> and\n    \\<open>Locale_Code.close_block\\<close> commands set up code generation for any \n    locale that is interpreted in between them. They also have to be specified\n    if an existing locale that already has interpretations is extended by\n    new definitions.\n\n    The \\<open>ICF_Tools.revert_abbrevs \"rrl\"\\<close> reverts all \n    abbreviations introduced by the locale, such that the displayed \n    information becomes nicer.\n\\<close>"], ["", "subsection \"Naming Conventions\""], ["", "text \\<open>\n    The Isabelle Collections Framework follows these general naming conventions.\n    Each implementation has a two-letter (or three-letter) and a one-letter (or two-letter) abbreviation, that are used as prefixes for the related constants, lemmas and instantiations.\n\n    The two-letter and three-letter abbreviations should be unique over all interfaces and instantiations, the one-letter abbreviations should be unique\n    over all implementations of the same interface.\n    Names that reference the implementation of only one interface are prefixed with that implementation's two-letter abbreviation (e.g. @{const hs.ins} for insertion into a HashSet (hs,h)),\n    names that reference more than one implementation are prefixed with the one-letter (or two-letter) abbreviations (e.g. @{const rrl.cart} for the cartesian \n    product between two RBT-Sets, yielding a list-set)\n    \n    The most important abbreviations are:\n    \\begin{description}\n      \\item[lm,l] List Map\n      \\item[lmi,li] List Map with explicit invariant\n      \\item[rm,r] RB-Tree Map\n      \\item[hm,h] Hash Map\n      \\item[ahm,a] Array-based hash map\n      \\item[tm,t] Trie Map\n      \\item[ls,l] List Set\n      \\item[lsi,li] List Set with explicit invariant\n      \\item[rs,r] RB-Tree Set\n      \\item[hs,h] Hash Set\n      \\item[ahs,a] Array-based hash map\n      \\item[ts,t] Trie Set\n    \\end{description}\n\n    Each function \\<open>name\\<close> of an interface \\<open>interface\\<close> is declared in a locale \\<open>interface_name\\<close>. This locale provides a fact \\<open>name_correct\\<close>. For example, there is the locale @{const set_ins} providing\n    the fact @{thm [source] set_ins.ins_correct}.\n    An implementation instantiates the locales of all implemented functions, using its two-letter abbreviation as instantiation prefix. For example, the HashSet-implementation instantiates the locale @{const set_ins} \n    with the prefix {\\em hs}, yielding the lemma @{thm [source] hs.ins_correct}. Moreover, an implementation with two-letter abbreviation {\\em aa} provides a lemma \\<open>aa.correct\\<close> \n    that summarizes the correctness facts for the basic \n    operations. It should only contain those facts that are safe to be used with the simplifier. E.g., the correctness facts for basic operations on hash sets are available via the lemma @{thm [source] hs.correct}.\n\n\\<close>"], ["", "section \"Extending the Framework\""], ["", "text_raw \\<open>\\label{sec:userguide.ext}\\<close>"], ["", "text \\<open>\n  The best way to add new features, i.e., interfaces, functions, \n  generic algorithms, or implementations to the collection framework is to use \n  one of the existing items as example. \n\\<close>"], ["", "section \"Design Issues\""], ["", "text_raw \\<open>\\label{sec:userguide.design}\\<close>"], ["", "text \\<open>\n    In this section, we motivate some of the design decisions of the Isabelle Collections Framework and report our experience with alternatives.\n    Many of the design decisions are justified by restrictions of Isabelle/HOL and the code generator, so that there may be better\n    options if those restrictions should vanish from future releases of Isabelle/HOL.\n\\<close>"], ["", "text \\<open>\n    The main design goals of this development are:\n    \\begin{enumerate}\n      \\item\\label{dg_unified} Make available various implementations of collections under a unified interface.\n      \\item\\label{dg_extensible} It should be easy to extend the framework by new interfaces, functions, algorithms, and implementations.\n      \\item\\label{dg_concise} Allow simple and concise reasoning over functions using collections.\n      \\item\\label{dg_genalgo} Allow generic algorithms, that are independent of the actual data structure that is used.\n      \\item\\label{dg_exec} Support generation of executable code.\n      \\item\\label{dg_control} Let the user precisely control what data structures are used in the implementation.\n    \\end{enumerate}\n\\<close>"], ["", "subsection \\<open>Data Refinement\\<close>"], ["", "text \\<open>\n    In order to allow simple reasoning over collections, we use a data refinement approach. Each collection\n    interface has an abstraction function that maps it on a related Isabelle/HOL concept (abstract level).\n    The specification of functions are also relative to the abstraction.\n    This allows most of the correctness reasoning to be done on the abstract level. On this level,\n    the tool support is more elaborated and one is not yet fixed to a concrete implementation.\n    In a next step, the abstract specification is refined to use an actual implementation (concrete level). The correctness properties\n    proven on the abstract level usually transfer easily to the concrete level.\n\n    Moreover, the user has precise control how the refinement is done, i.e. what data structures are used. An alternative would be to do refinement\n    completely automatic, as e.g. done in the code generator setup of the Theory~{\\em Executable-Set}. This has the advantage that it induces less writing overhead.\n    The disadvantage is that the user looses a great amount of control over the refinement. For example, in {\\em Executable-Set}, all sets have to be represented by lists,\n    and there is no possibility to represent one set differently from another. \n\n    For a more detailed discussion of the data refinement issue, we refer to\n    the monadic refinement framework, that is available in the AFP \n    (@{url \"http://isa-afp.org/entries/Refine_Monadic.shtml\"})\n\\<close>"], ["", "subsection \\<open>Operation Records\\<close>"], ["", "text \\<open>\n    In order to allow convenient access to the most frequently used functions \n    of an interface,\n    we have grouped them together in a record, and defined a locale that only\n    fixes this record. This greatly reduces the boilerplate required to define\n    a new (generic) algorithm, as only the operation locale (instead of every\n    single function) has to be included in the locale for the generic algorithm.\n\n    Note however, that parameters of locales are monomorphic inside the locale.\n    Thus, we have to import an own instance for the locale for every element\n    type of a set, or key/value type of a map. \n    For iterators, where this problem was most annoying, we have installed a\n    workaround that allows polymorphic iterators even inside locales.\n\\<close>"], ["", "subsection \\<open>Locales for Generic Algorithms\\<close>"], ["", "text \\<open>\n    A generic algorithm is defined within a locale, that includes the required \n    functions (or operation locales). If many instances of the same interface\n    are required, prefixes are used to distinguish between them. This makes\n    the code for a generic algorithm quite consise and readable.\n\n    However, there are some technical issues that one has to consider:\n    \\begin{itemize}\n      \\item  When fixing parameters in the declaration of the locale, their\n        types will be inferred independently of the definitions later done in\n        the locale context. In order to get the correct types, one has to add \n        explicit type constraints.\n      \\item The code generator has problems with generating code from \n        definitions inside a locale. Currently, the \\<open>Locale_Code\\<close>-package\n        provides a rather convenient workaround for that issue: It requires the \n        user to enclose interpretations and definitions of new constants inside\n        already interpreted locales within two special commands, that set up\n        the code generator appropriately.\n    \\end{itemize}\n\\<close>"], ["", "subsection \\<open>Explicit Invariants vs Typedef\\<close>"], ["", "text \\<open>\n    The interfaces of this framework use explicit invariants.\n    This provides a more general specification which allows some operations to\n    be implemented more efficiently, cf. @{const \"lsi.ins_dj\"} \n    in @{theory Collections.ListSetImpl_Invar}.\n    \n    Most implementations, however, hide the invariant in a typedef and setup\n    the code generator appropriately.\n    In that case, the invariant is just @{term \"\\<lambda>_. True\"}, and removed \n    automatically by the simplifier and classical reasoner.\n    However, it still shows up in some premises and conclusions due to\n    uniformity reasons.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"]]}