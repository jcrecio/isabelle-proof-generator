{"file_name": "/home/qj213/afp-2021-10-22/thys/Containers/Containers_Userguide.thy", "working_directory": "/home/qj213/afp-2021-10-22/thys/Containers", "problem_names": ["lemma expr'_rel_eq: \"expr'_rel (=) e\\<^sub>1 e\\<^sub>2 \\<longleftrightarrow> e\\<^sub>1 = e\\<^sub>2\"", "lemma inj_expr [simp]: \"inj Lit\" \"inj Var\" \"inj Add\" \"inj (Add e)\"", "lemma infinite_UNIV_expr: \"\\<not> finite (UNIV :: expr set)\"", "lemma inj_expr' [simp]: \"inj Lit'\" \"inj Var'\" \"inj Add'\" \"inj (Add' e)\"", "lemma infinite_UNIV_expr': \"\\<not> finite (UNIV :: 'a expr' set)\"", "lemmas [code] = trie_lookup_empty trie_lookup_update", "lemma trie_keys_empty [code]: \"trie_keys trie_empty = {}\"", "lemma trie_keys_update [code]:\n  \"trie_keys (trie_update k v t) = insert k (trie_keys t)\"", "lemma lookup_empty: \"lookup empty = Map.empty\"", "lemma lookup_update: \"lookup (update k v t) = (lookup t)(k \\<mapsto> v)\"", "lemma keys_conv_dom_lookup: \"keys t = dom (lookup t)\"", "lemma lookup_Trie_Mapping [code]:\n  \"Mapping.lookup (Trie_Mapping t) = lookup t\"\n  \\<comment> \\<open>Lookup does not need the check on @{term cbl},\n        because we have defined the pseudo-constructor @{term Trie_Mapping} in terms of @{term \"lookup\"}\\<close>", "lemma update_Trie_Mapping [code]:\n  \"Mapping.update k v (Trie_Mapping t) = \n  (case ID cbl :: 'k cbl of\n     None \\<Rightarrow> Code.abort (STR ''update Trie_Mapping: cbl = None'') (\\<lambda>_. Mapping.update k v (Trie_Mapping t))\n   | Some _ \\<Rightarrow> Trie_Mapping (update k v t))\"", "lemma keys_Trie_Mapping [code]:\n  \"Mapping.keys (Trie_Mapping t) =\n  (case ID cbl :: 'k cbl of\n     None \\<Rightarrow> Code.abort (STR ''keys Trie_Mapping: cbl = None'') (\\<lambda>_. Mapping.keys (Trie_Mapping t))\n   | Some _ \\<Rightarrow> keys t)\"", "lemma mapping_empty_choose_code [code]:\n  \"(mapping_empty_choose :: ('a :: {ccompare, cbl}, 'b) mapping) =\n   (case ID CCOMPARE('a) of Some _  \\<Rightarrow> RBT_Mapping RBT_Mapping2.empty\n    | None \\<Rightarrow>\n      case ID (cbl :: 'a cbl) of Some _ \\<Rightarrow> Trie_Mapping empty \n      | None \\<Rightarrow> Assoc_List_Mapping DAList.empty)\"", "lemma mapping_empty_code [code]:\n  \"mapping_empty mapping_Trie = Trie_Mapping empty\"", "lemma mapping_impl_choose2_Trie [code]:\n  \"mapping_impl_choose2 mapping_Trie mapping_Trie = mapping_Trie\"", "lemma mapping_impl_unit_Trie [code]:\n  \"MAPPING_IMPL(unit) = Phantom(unit) mapping_Trie\"", "lemma empty_Set_Monad: \"{} = Set_Monad []\""], "translations": [["", "lemma expr'_rel_eq: \"expr'_rel (=) e\\<^sub>1 e\\<^sub>2 \\<longleftrightarrow> e\\<^sub>1 = e\\<^sub>2\""], ["proof (prove)\ngoal (1 subgoal):\n 1. expr'_rel (=) e\\<^sub>1 e\\<^sub>2 = (e\\<^sub>1 = e\\<^sub>2)", "by(induct e\\<^sub>1 e\\<^sub>2 rule: expr'_rel.induct) simp_all"], ["", "text \\<open>\n  Then, the instantiation is again canonical:\n\\<close>"], ["", "instantiation expr' :: (ceq) ceq begin"], ["", "definition\n  \"CEQ('a expr') =\n  (case ID CEQ('a) of None \\<Rightarrow> None | Some eq \\<Rightarrow> Some (expr'_rel eq))\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS('a expr', ceq_class)", "by(intro_classes)\n    (auto simp add: ceq_expr'_def expr'_rel_eq[abs_def] \n          dest: Collection_Eq.ID_ceq \n          split: option.split_asm)"], ["", "end"], ["", "(*<*)"], ["", "context fixes dummy :: \"'a :: ceq\" begin"], ["", "(*>*)"], ["", "text \\<open>\n  Note the following two points:\n  First, the instantiation should avoid to use @{term \"(=)\"} on terms of the polymorphic type.\n  This keeps the LC framework separate from the type class @{class equal}, i.e., every choice of @{typ \"'a\"}\n  in @{typ \"'a expr'\"} can be of sort @{class \"ceq\"}.\n  The easiest way to achieve this is to obtain the equality test from @{term \"CEQ('a)\"}.\n  Second, we use @{term \"ID CEQ('a)\"} instead of @{term \"CEQ('a)\"}.\n  In proofs, we want that the simplifier uses assumptions like \\<open>CEQ('a) = Some \\<dots>\\<close> for rewriting.\n  However, @{term \"CEQ('a)\"} is a nullary constant, so the simplifier reverses such an equation, i.e., it only rewrites \\<open>Some \\<dots>\\<close> to @{term \"CEQ('a :: ceq)\"}.\n  Applying the identity function @{term \"ID\"} to @{term \"CEQ('a :: ceq)\"} avoids this, and the code generator eliminates all occurrences of @{term \"ID\"}.\n  Although @{thm ID_def} by definition, do not use the conventional @{term \"id\"} instead of @{term ID}, because @{term \"id CEQ('a :: ceq)\"} immediately simplifies to @{term \"CEQ('a :: ceq)\"}.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"], ["", "subsection \\<open>Ordering\\<close>"], ["", "text_raw \\<open>\\label{subsection:ccompare}\\<close>"], ["", "(*<*)"], ["", "context fixes dummy :: \"'a :: {ccompare, ceq}\" begin"], ["", "(*>*)"], ["", "text \\<open>\n  LC takes the order for storing elements in search trees from the type class @{class ccompare} rather than @{class compare}, because we cannot instantiate @{class compare} for some types (e.g., @{typ \"'a set\"} as @{term \"(\\<subseteq>)\"} is not linear).\n  Similar to @{term \"CEQ('a)\"} in class @{term ceq}, the class @{class ccompare} specifies an optional comparator @{term [source] \"CCOMPARE('a) :: (('a \\<Rightarrow> 'a \\<Rightarrow> order)) option\" }.\n  If you cannot or do not want to implement a comparator on your type, you can default to @{term \"None\"}.\n  In that case, you will not be able to use your type as elements of sets or as keys in maps implemented by search trees.\n\n  If the type is a data type or instantiates @{class compare} and we wish to use that comparator also for the search tree, instantiation is again canonical:\n  For our data type @{typ expr}, derive does everything!\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)\n(*<*)(*>*)"], ["", "derive ccompare expr"], ["", "(*<*)(*>*)"], ["", "text \\<open>\n  In general, the pattern for type constructors without parameters looks as follows:\n\\<close>"], ["", "axiomatization where simple_tycon_compare: \"OFCLASS(simple_tycon, compare_class)\""], ["", "instance simple_tycon :: compare"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS(simple_tycon, compare_class)", "by (rule simple_tycon_compare)"], ["", "derive (compare) ccompare simple_tycon"], ["", "text \\<open>\n  For polymorphic types like @{typ \"'a expr'\"}, we should not do everything manually:\n  First, we must define a comparator that takes the comparator on the type variable @{typ \"'a\"} as a parameter.\n  This is necessary to maintain the separation between Isabelle/HOL's type classes (like @{class compare}) and LC's.\n  Such a comparator is again easily defined by derive.\n\\<close>"], ["", "derive ccompare expr'"], ["", "thm ccompare_expr'_def comparator_expr'_simps"], ["", "subsection \\<open>Heuristics for picking an implementation\\<close>"], ["", "text_raw \\<open>\\label{subsection:set_impl} \\label{subsection:mapping_impl}\\<close>"], ["", "(*<*)"], ["", "context fixes dummy :: \"'a :: {ceq, ccompare, set_impl, mapping_impl}\" begin"], ["", "(*>*)"], ["", "text \\<open>\n  Now, we have defined the necessary operations on @{typ expr} and @{typ \"'a expr'\"} to store them in a set \n  or use them as the keys in a map.\n  But before we can actually do so, we also have to say which data structure to use.\n  The type classes @{class set_impl} and @{class mapping_impl} are used for this.\n\n  They define the overloaded operations @{term [source] \"SET_IMPL('a) :: ('a, set_impl) phantom\" } and @{term [source] \"MAPPING_IMPL('a) :: ('a, mapping_impl) phantom\"}, respectively.\n  The phantom type @{typ \"('a, 'b) phantom\"} from theory @{theory \"HOL-Library.Phantom_Type\"} is isomorphic to @{typ \"'b\"}, but formally depends on @{typ \"'a\"}.\n  This way, the type class operations meet the requirement that their type contains exactly one type variable.\n  The Haskell and ML compiler will get rid of the extra type constructor again.\n\n  For sets, you can choose between @{term set_Collect} (characteristic function @{term P} like in @{term \"{x. P x}\"}), @{term set_DList} (distinct list), @{term set_RBT} (red-black tree), and @{term set_Monad} (list with duplicates).\n  Additionally, you can define @{term \"set_impl\"} as @{term \"set_Choose\"} which picks the implementation based on the available operations (RBT if @{term \"CCOMPARE('a)\"} provides a linear order, else distinct lists if @{term \"CEQ('a)\"} provides equality testing, and lists with duplicates otherwise).\n  @{term \"set_Choose\"} is the safest choice because it picks only a data structure when the required operations are actually available.\n  If @{term set_impl} picks a specific implementation, Isabelle does not ensure that all required operations are indeed available.\n\n  For maps, the choices are @{term \"mapping_Assoc_List\"} (associative list without duplicates), @{term \"mapping_RBT\"} (red-black tree), and @{term \"mapping_Mapping\"} (closures with function update).\n  Again, there is also the @{term \"mapping_Choose\"} heuristics.\n  \n  For simple cases, \\<open>derive\\<close> can be used again (even if the type is not a data type).\n  Consider, e.g., the following instantiations:\n  @{typ \"expr set\"} uses RBTs, @{typ \"(expr, _) mapping\"} and @{typ \"'a expr' set\"} use the heuristics, and @{typ \"('a expr', _) mapping\"} uses the same implementation as @{typ \"('a, _) mapping\"}.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"], ["", "derive (rbt) set_impl expr"], ["", "derive (choose) mapping_impl expr"], ["", "derive (choose) set_impl expr'"], ["", "text \\<open>\n  More complex cases such as taking the implementation preference of a type parameter must be done manually.\n\\<close>"], ["", "instantiation expr' :: (mapping_impl) mapping_impl begin"], ["", "definition\n  \"MAPPING_IMPL('a expr') = \n   Phantom('a expr') (of_phantom MAPPING_IMPL('a))\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS('a expr', mapping_impl_class)", ".."], ["", "end"], ["", "(*<*)"], ["", "locale mynamespace begin"], ["", "definition empty where \"empty = Mapping.empty\""], ["", "declare (in -) mynamespace.empty_def [code]"], ["", "(*>*)"], ["", "text \\<open>\n  To see the effect of the different configurations, consider the following examples where @{term [names_short] \"empty\"} refers to @{term \"Mapping.empty\"}.\n  For that, we must disable pretty printing for sets as follows:\n\\<close>"], ["", "declare (*<*)(in -) (*>*)pretty_sets[code_post del]"], ["", "text \\<open>\n  \\begin{center}\n    \\small\n    \\begin{tabular}{ll}\n      \\toprule\n      \\isamarkuptrue\\isacommand{value}\\isamarkupfalse\\ {\\isacharbrackleft}code{\\isacharbrackright}\n      &\n      \\textbf{result}\n      \\\\\n      \\midrule\n      @{term [source] \"{} :: expr set\"}\n      &\n      @{value [names_short] \"{} :: expr set\"}\n      \\\\\n      @{term [source] \"empty :: (expr, unit) mapping\"}\n      &\n      @{value [names_short] \"empty :: (expr, unit) mapping\"}\n      \\\\\n      \\midrule\n      @{term [source] \"{} :: string expr' set\"}\n     &\n      @{value [names_short] \"{} :: string expr' set\"}\n      \\\\\n      @{term [source] \"{} :: (nat \\<Rightarrow> nat) expr' set\"}\n      &\n      @{value [names_short] \"{} :: (nat \\<Rightarrow> nat) expr' set\"}\n      \\\\\n      @{term [source] \"{} :: bool expr' set\"}\n      &\n      @{value [names_short] \"{} :: bool expr' set\"}\n      \\\\\n      @{term [source] \"empty :: (bool expr', unit) mapping\"}\n      &\n      @{value [names_short] \"empty :: (bool expr', unit) mapping\"}\n      \\\\\n      \\bottomrule\n    \\end{tabular}\n  \\end{center}\n  \n  For @{typ expr}, @{term mapping_Choose} picks RBTs, because @{term \"CCOMPARE(expr)\"} provides a comparison operation for @{typ \"expr\"}.\n  For @{typ \"'a expr'\"}, the effect of @{term set_Choose} is more pronounced:\n  @{term \"CCOMPARE(string)\"} is not @{term \"None\"}, so neither is @{term \"CCOMPARE(string expr')\"}, and @{term set_Choose} picks RBTs.\n  As @{typ \"nat \\<Rightarrow> nat\"} neither provides equality tests (@{class ceq}) nor comparisons (@{class ccompare}), neither does @{typ \"(nat \\<Rightarrow> nat) expr'\"}, so we use lists with duplicates.\n  The last two examples show the difference between inheriting a choice and choosing freshly:\n  By default, @{typ bool} prefers distinct (associative) lists over RBTs, because there are just two elements.\n  As @{typ \"bool expr'\"} enherits the choice for maps from @{typ bool}, an associative list implements @{term [source] \"empty :: (bool expr', unit) mapping\"}.\n  For sets, in contrast, @{term \"SET_IMPL('a expr')\"} discards @{typ 'a}'s preferences and picks RBTs, because there is a comparison operation.\n\n  Finally, let's enable pretty-printing for sets again:\n\\<close>"], ["", "declare (*<*)(in -) (*>*)pretty_sets [code_post]"], ["", "(*<*)\n  (* The following value commands ensure that the code generator executes @{value ...} above,\n     I could not find a way to specify [code] to @{value}. *)"], ["", "value [code] \"{} :: expr set\""], ["", "value [code] \"empty :: (expr, unit) mapping\""], ["", "value [code] \"{} :: string expr' set\""], ["", "value [code] \"{} :: (nat \\<Rightarrow> nat) expr' set\""], ["", "value [code] \"{} :: bool expr' set\""], ["", "value [code] \"empty :: (bool expr', unit) mapping\""], ["", "(*>*)   \n(*<*)"], ["", "end"], ["", "(*>*)"], ["", "subsection \\<open>Set comprehensions\\<close>"], ["", "text_raw \\<open>\\label{subsection:cenum}\\<close>"], ["", "(*<*)"], ["", "context fixes dummy :: \"'a :: cenum\" begin"], ["", "(*>*)"], ["", "text \\<open>\n  If you use the default code generator setup that comes with Isabelle, set comprehensions @{term [source] \"{x. P x} :: 'a set\"} are only executable if the type @{typ 'a} has sort @{class enum}.\n  Internally, Isabelle's code generator transforms set comprehensions into an explicit list of elements which it obtains from the list @{term enum} of all of @{typ \"'a\"}'s elements.\n  Thus, the type must be an instance of @{class enum}, i.e., finite in particular.\n  For example, @{term \"{c. CHR ''A'' \\<le> c \\<and> c \\<le> CHR ''D''}\"} evaluates to @{term \"set ''ABCD''\"}, the set of the characters A, B, C, and D.\n\n  For compatibility, LC also implements such an enumeration strategy, but avoids the finiteness restriction.\n  The type class @{class cenum} mimicks @{class enum}, but its single parameter @{term [source] \"cEnum :: ('a list \\<times> (('a \\<Rightarrow> bool) \\<Rightarrow> bool) \\<times> (('a \\<Rightarrow> bool) \\<Rightarrow> bool)) option\"} combines all of @{class enum}'s parameters, namely a list of all elements, a universal and an existential quantifier.\n  \\<open>option\\<close> ensures that every type can be an instance as @{term \"CENUM('a)\"} can always default to @{term None}.\n  \n  For types that define @{term \"CENUM('a)\"}, set comprehensions evaluate to a list of their elements.\n  Otherwise, set comprehensions are represented as a closure.\n  This means that if the generated code contains at least one set comprehension, all element types of a set must instantiate @{class cenum}.\n  Infinite types default to @{term None}, and enumerations for finite types are canoncial, see @{theory Containers.Collection_Enum} for examples.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"], ["", "instantiation expr :: cenum begin"], ["", "definition \"CENUM(expr) = None\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS(expr, cenum_class)", "by(intro_classes)(simp_all add: cEnum_expr_def)"], ["", "end"], ["", "derive (no) cenum expr'"], ["", "derive compare_order expr"], ["", "text_raw \\<open>\\par\\medskip \\isastyletext For example,\\<close>"], ["", "value \"({b. b = True}, {x. compare x (Lit 0) = Lt})\""], ["", "text_raw \\<open>\n  \\isastyletext{}\n  yields @{value \"({b. b = True}, {x. compare x (Lit 0) = Lt})\"}\n\\<close>"], ["", "text \\<open>\n  LC keeps complements of such enumerated set comprehensions, i.e., @{term \"- {b. b = True}\"} evaluates to @{value \"- {b. b = True}\"}.\n  If you want that the complement operation actually computes the elements of the complements, you have to replace the code equations for @{term uminus} as follows:\n\\<close>"], ["", "declare Set_uminus_code[code del] Set_uminus_cenum[code]"], ["", "(*<*)"], ["", "value \"- {b. b = True}\""], ["", "(*>*)"], ["", "text \\<open>\n  Then, @{term \"- {b. b = True}\"} becomes @{value \"- {b. b = True}\"}, but this applies to all complement invocations.\n  For example, @{term [source] \"UNIV :: bool set\"} becomes @{value \"UNIV :: bool set\"}.\n\\<close>"], ["", "(*<*)"], ["", "declare Set_uminus_cenum[code del] Set_uminus_code[code]"], ["", "(*>*)"], ["", "subsection \\<open>Nested sets\\<close>"], ["", "text_raw \\<open>\\label{subsection:finite_UNIV} \\label{subsection:card_UNIV} \\label{subsection:cproper_interval}\\<close>"], ["", "(*<*)"], ["", "context fixes dummy :: \"'a :: {card_UNIV, cproper_interval}\" begin"], ["", "(*>*)"], ["", "text \\<open>\n  To deal with nested sets such as @{typ \"expr set set\"}, the element type must provide three operations from three type classes:\n  \\begin{itemize}\n  \\item @{class finite_UNIV} from theory @{theory \"HOL-Library.Cardinality\"} defines the constant @{term [source] \"finite_UNIV :: ('a, bool) phantom\"} which designates whether the type is finite.\n  \\item @{class card_UNIV} from theory @{theory \"HOL-Library.Cardinality\"} defines the constant @{term [source] \"card_UNIV :: ('a, nat) phantom\"} which returns @{term \"CARD('a)\"}, i.e., the number of values in @{typ 'a}.\n    If @{typ \"'a\"} is infinite, @{term \"CARD('a) = 0\"}.\n  \\item @{class cproper_interval} from theory @{theory Containers.Collection_Order} defines the function @{term [source] \"cproper_interval :: 'a option \\<Rightarrow> 'a option \\<Rightarrow> bool\"}.\n    If the type @{typ \"'a\"} is finite and @{term \"CCOMPARE('a)\"} yields a linear order on @{typ \"'a\"}, then @{term \"cproper_interval x y\"} returns whether the open interval between @{term \"x\"} and @{term \"y\"} is non-empty.\n    The bound @{term \"None\"} denotes unboundedness.\n  \\end{itemize}\n\n  Note that the type class @{class finite_UNIV} must not be confused with the type class @{class finite}.\n  @{class finite_UNIV} allows the generated code to examine whether a type is finite whereas @{class finite} requires that the type in fact is finite.\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"], ["", "text \\<open>\n  For datatypes, the theory @{theory Containers.Card_Datatype} defines some machinery to assist in proving that the type is (in)finite and has a given number of elements -- see @{file \\<open>Examples/Card_Datatype_Ex.thy\\<close>} for examples.\n  With this, it is easy to instantiate @{class card_UNIV} for our running examples:\n\\<close>"], ["", "lemma inj_expr [simp]: \"inj Lit\" \"inj Var\" \"inj Add\" \"inj (Add e)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. (inj Lit &&& inj Var) &&& inj Add &&& inj (Add e)", "by(simp_all add: fun_eq_iff inj_on_def)"], ["", "lemma infinite_UNIV_expr: \"\\<not> finite (UNIV :: expr set)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. infinite UNIV", "including card_datatype"], ["proof (prove)\ngoal (1 subgoal):\n 1. infinite UNIV", "proof -"], ["proof (state)\ngoal (1 subgoal):\n 1. infinite UNIV", "have \"rangeIt (Lit 0) (Add (Lit 0)) \\<subseteq> UNIV\""], ["proof (prove)\ngoal (1 subgoal):\n 1. rangeIt (Lit 0) (Add (Lit 0)) \\<subseteq> UNIV", "by simp"], ["proof (state)\nthis:\n  rangeIt (Lit 0) (Add (Lit 0)) \\<subseteq> UNIV\n\ngoal (1 subgoal):\n 1. infinite UNIV", "from finite_subset[OF this]"], ["proof (chain)\npicking this:\n  finite UNIV \\<Longrightarrow> finite (rangeIt (Lit 0) (Add (Lit 0)))", "show ?thesis"], ["proof (prove)\nusing this:\n  finite UNIV \\<Longrightarrow> finite (rangeIt (Lit 0) (Add (Lit 0)))\n\ngoal (1 subgoal):\n 1. infinite UNIV", "by auto"], ["proof (state)\nthis:\n  infinite UNIV\n\ngoal:\nNo subgoals!", "qed"], ["", "instantiation expr :: card_UNIV begin"], ["", "definition \"finite_UNIV = Phantom(expr) False\""], ["", "definition \"card_UNIV = Phantom(expr) 0\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS(expr, card_UNIV_class)", "by intro_classes\n     (simp_all add: finite_UNIV_expr_def card_UNIV_expr_def infinite_UNIV_expr)"], ["", "end"], ["", "lemma inj_expr' [simp]: \"inj Lit'\" \"inj Var'\" \"inj Add'\" \"inj (Add' e)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. (inj Lit' &&& inj Var') &&& inj Add' &&& inj (Add' e)", "by(simp_all add: fun_eq_iff inj_on_def)"], ["", "lemma infinite_UNIV_expr': \"\\<not> finite (UNIV :: 'a expr' set)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. infinite UNIV", "including card_datatype"], ["proof (prove)\ngoal (1 subgoal):\n 1. infinite UNIV", "proof -"], ["proof (state)\ngoal (1 subgoal):\n 1. infinite UNIV", "have \"rangeIt (Lit' 0) (Add' (Lit' 0)) \\<subseteq> UNIV\""], ["proof (prove)\ngoal (1 subgoal):\n 1. rangeIt (Lit' 0) (Add' (Lit' 0)) \\<subseteq> UNIV", "by simp"], ["proof (state)\nthis:\n  rangeIt (Lit' 0) (Add' (Lit' 0)) \\<subseteq> UNIV\n\ngoal (1 subgoal):\n 1. infinite UNIV", "from finite_subset[OF this]"], ["proof (chain)\npicking this:\n  finite UNIV \\<Longrightarrow> finite (rangeIt (Lit' 0) (Add' (Lit' 0)))", "show ?thesis"], ["proof (prove)\nusing this:\n  finite UNIV \\<Longrightarrow> finite (rangeIt (Lit' 0) (Add' (Lit' 0)))\n\ngoal (1 subgoal):\n 1. infinite UNIV", "by auto"], ["proof (state)\nthis:\n  infinite UNIV\n\ngoal:\nNo subgoals!", "qed"], ["", "instantiation expr' :: (type) card_UNIV begin"], ["", "definition \"finite_UNIV = Phantom('a expr') False\""], ["", "definition \"card_UNIV = Phantom('a expr') 0\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS('a expr', card_UNIV_class)", "by intro_classes\n     (simp_all add: finite_UNIV_expr'_def card_UNIV_expr'_def infinite_UNIV_expr')"], ["", "end"], ["", "text \\<open>\n  As @{typ expr} and @{typ \"'a expr'\"} are infinite, instantiating @{class cproper_interval} is trivial,\n  because @{class cproper_interval} only makes assumptions about its parameters for finite types.\n  Nevertheless, it is important to actually define @{term cproper_interval}, because the\n  code generator requires a code equation.\n\\<close>"], ["", "instantiation expr :: cproper_interval begin"], ["", "definition cproper_interval_expr :: \"expr proper_interval\" \n  where \"cproper_interval_expr _ _ = undefined\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS(expr, cproper_interval_class)", "by(intro_classes)(simp add: infinite_UNIV_expr)"], ["", "end"], ["", "instantiation expr' :: (ccompare) cproper_interval begin"], ["", "definition cproper_interval_expr' :: \"'a expr' proper_interval\" \n  where \"cproper_interval_expr' _ _ = undefined\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS('a expr', cproper_interval_class)", "by(intro_classes)(simp add: infinite_UNIV_expr')"], ["", "end"], ["", "subsubsection \\<open>Instantiation of @{class proper_interval}\\<close>"], ["", "text \\<open>\n  To illustrate what to do with finite types, we instantiate @{class proper_interval} for @{typ expr}.\n  Like @{class ccompare} relates to @{class compare}, the class @{class cproper_interval} has a counterpart @{class proper_interval} without the finiteness assumption.\n  Here, we first have to gather the simplification rules of the comparator from the derive\n  invocation, especially, how the strict order of the comparator, @{term lt_of_comp}, can be defined.\n  \n  Since the order on lists is not yet shown to be consistent with the comparators that are used\n  for lists, this part of the userguide is currently not available.\n  \n\\<close>"], ["", "(*\ninstantiation expr :: proper_interval begin\n\nlemma less_expr_conv: \"(<) = lt_of_comp comparator_expr\" \"(\\<le>) = le_of_comp comparator_expr\"\n  using less_expr_def less_eq_expr_def unfolding compare_expr_def by auto\n\nlemma lt_of_comp_expr: \"lt_of_comp comparator_expr e1 e2 = (\n  case e1 of \n    Var x1 \\<Rightarrow> \n      (case e2 of \n        Var x2 \\<Rightarrow> lt_of_comp (comparator_list comparator_of) x1 x2  \n      | Lit _ \\<Rightarrow> True\n      | Add _ _ \\<Rightarrow> True)\n  | Lit i1 \\<Rightarrow>\n      (case e2 of\n        Var _ \\<Rightarrow> False\n      | Lit i2 \\<Rightarrow> lt_of_comp comparator_of i1 i2\n      | Add _ _ \\<Rightarrow> True)\n  | Add a1 b1 \\<Rightarrow>\n      (case e2 of\n        Var _ \\<Rightarrow> False\n      | Lit _ \\<Rightarrow> False\n      | Add a2 b2 \\<Rightarrow> lt_of_comp comparator_expr a1 a2 \n          \\<or> le_of_comp comparator_expr a1 a2 \\<and> lt_of_comp comparator_expr b1 b2) \n    )\"\n  by (simp add: lt_of_comp_def le_of_comp_def comp_lex_code split: expr.split order.split)\n    \nfun proper_interval_expr :: \"expr option \\<Rightarrow> expr option \\<Rightarrow> bool\"\nwhere\n  \"proper_interval_expr None (Some (Var x)) \\<longleftrightarrow> proper_interval None (Some x)\"\n| \"proper_interval_expr (Some (Var x)) (Some (Var y)) \\<longleftrightarrow> proper_interval (Some x) (Some y)\"\n| \"proper_interval_expr (Some (Lit i)) (Some (Lit j)) \\<longleftrightarrow> proper_interval (Some i) (Some j)\"\n| \"proper_interval_expr (Some (Lit i)) (Some (Var x)) \\<longleftrightarrow> False\"\n| \"proper_interval_expr (Some (Add e1 e2)) (Some (Lit i)) \\<longleftrightarrow> False\"\n| \"proper_interval_expr (Some (Add e1 e2)) (Some (Var x)) \\<longleftrightarrow> False\"\n| \"proper_interval_expr (Some (Add e1 e2)) (Some (Add e1' e2')) \\<longleftrightarrow> \n    (case compare e1 e1' of Lt \\<Rightarrow> True | Eq \\<Rightarrow> proper_interval_expr (Some e2) (Some e2') | Gt \\<Rightarrow> False)\"\n| \"proper_interval_expr _ _ \\<longleftrightarrow> True\"\n\ninstance\nproof(intro_classes)\n  fix x y :: expr\n  show \"proper_interval None (Some y) = (\\<exists>z. z < y)\"\n    unfolding less_expr_conv\n    by (cases y)(auto simp add: lt_of_comp_expr  intro: exI[where x=\"''''\"])\n\n  { fix x y have \"x < Add x y\" unfolding less_expr_conv \n      by(induct x arbitrary: y)(simp_all add: lt_of_comp_expr) }\n  note le_Add = this\n  thus \"proper_interval (Some x) None = (\\<exists>z. x < z)\"\n    by(simp add: less_expr_def exI[where x=\"Add x y\"])\n\n  note [simp] = less_expr_conv lt_of_comp_expr\n\n  show \"proper_interval (Some x) (Some y) = (\\<exists>z. x < z \\<and> z < y)\"\n  proof(induct \"Some x\" \"Some y\" arbitrary: x y rule: proper_interval_expr.induct)\n    case 2\n    show ?case by(auto simp add: proper_interval_list_aux_correct)\n  next\n    case (3 i j)\n    show ?case by(auto intro: exI[where x=\"Lit (i + 1)\"])\n  next\n    case (7 e1 e2 e1' e2')\n    thus ?case by(auto intro: le_Add simp add: le_less)\n  next\n    case (\"8_2\" i e1 e2)\n    show ?case by(auto intro: exI[where x=\"Lit (i + 1)\"])\n  next\n    case (\"8_5\" x i) show ?case\n      by(auto intro: exI[where x=\"Var (x @ [undefined])\"] simp add: less_append_same_iff)\n  next\n    case (\"8_6\" x e1 e2) show ?case\n      by(auto intro: exI[where x=\"Lit 0\"])\n  next\n    case (\"8_7\" i e1 e2) show ?case\n      by(auto intro: exI[where x=\"Lit (i + 1)\"])\n  next\n    case (\"8_10\" x i) show ?case\n      by(auto intro: exI[where x=\"Lit (i - 1)\"])\n  next\n    case (\"8_12\" x e1 e2) show ?case\n      by(auto intro: exI[where x=\"Lit 0\"])\n  next\n    case (\"8_13\" i e1 e2) show ?case\n      by(auto intro: exI[where x=\"Lit (i + 1)\"])\n  qed auto\nqed simp\nend\n*)\n(*<*)"], ["", "value \"{{Lit 1}}\""], ["", "value \"{{{Lit 1}}}\""], ["", "value \"{{{{Lit 1}}}}\""], ["", "(*>*)"], ["", "section \\<open>New implementations for containers\\<close>"], ["", "text_raw \\<open>\\label{section:new:implementation}\\<close>"], ["", "(*<*)"], ["", "typedecl 'v trie_raw"], ["", "(*>*)"], ["", "text \\<open>\n  This section explains how to add a new implementation for a container type.\n  If you do so, please consider to add your implementation to this AFP entry.\n\\<close>"], ["", "subsection \\<open>Model and verify the data structure\\<close>"], ["", "text_raw \\<open>\\label{subsection:implement:data:structure}\\<close>"], ["", "text \\<open>\n  First, you of course have to define the data structure and verify that it has the required properties.\n  As our running example, we use a trie to implement @{typ \"('a, 'b) mapping\"}.\n  A trie is a binary tree whose the nodes store the values, the keys are the paths from the root to the given node.\n  We use lists of @{typ bool}ans for the keys where the @{typ bool}ean indicates whether we should go to the left or right child.\n\n  For brevity, we skip this step and rather assume that the type @{typ \"'v trie_raw\"} of tries has following operations and properties:\n\\<close>"], ["", "type_synonym trie_key = \"bool list\""], ["", "axiomatization\n  trie_empty :: \"'v trie_raw\" and\n  trie_update :: \"trie_key \\<Rightarrow> 'v \\<Rightarrow> 'v trie_raw \\<Rightarrow> 'v trie_raw\" and\n  trie_lookup :: \"'v trie_raw \\<Rightarrow> trie_key \\<Rightarrow> 'v option\" and\n  trie_keys :: \"'v trie_raw \\<Rightarrow> trie_key set\"\nwhere trie_lookup_empty: \"trie_lookup trie_empty = Map.empty\"\n  and trie_lookup_update: \n    \"trie_lookup (trie_update k v t) = (trie_lookup t)(k \\<mapsto> v)\"\n  and trie_keys_dom_lookup: \"trie_keys t = dom (trie_lookup t)\""], ["", "text \\<open>\n  This is only a minimal example.\n  A full-fledged implementation has to provide more operations and -- for efficiency -- should use more than just @{typ bool}eans for the keys.\n\\<close>"], ["", "(*<*) (* Implement trie by free term algebra *)"], ["", "code_datatype trie_empty trie_update"], ["", "lemmas [code] = trie_lookup_empty trie_lookup_update"], ["", "lemma trie_keys_empty [code]: \"trie_keys trie_empty = {}\""], ["proof (prove)\ngoal (1 subgoal):\n 1. trie_keys trie_empty = {}", "by(simp add: trie_keys_dom_lookup trie_lookup_empty)"], ["", "lemma trie_keys_update [code]:\n  \"trie_keys (trie_update k v t) = insert k (trie_keys t)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. trie_keys (trie_update k v t) = insert k (trie_keys t)", "by(simp add: trie_keys_dom_lookup trie_lookup_update)"], ["", "(*>*)"], ["", "subsection \\<open>Generalise the data structure\\<close>"], ["", "text_raw \\<open>\\label{subsection:introduce:type:class}\\<close>"], ["", "text \\<open>\n  As @{typ \"('k, 'v) mapping\"} store keys of arbitrary type @{typ \"'k\"}, not just @{typ \"trie_key\"}, we cannot use @{typ \"'v trie_raw\"} directly.\n  Instead, we must first convert arbitrary types @{typ \"'k\"} into @{typ \"trie_key\"}.\n  Of course, this is not always possbile, but we only have to make sure that we pick tries as implementation only if the types do.\n  This is similar to red-black trees which require an order.\n  Hence, we introduce a type class to convert arbitrary keys into trie keys.\n  We make the conversions optional such that every type can instantiate the type class, just as LC does for @{class ceq} and @{class ccompare}.\n\\<close>"], ["", "type_synonym 'a cbl = \"(('a \\<Rightarrow> bool list) \\<times> (bool list \\<Rightarrow> 'a)) option\""], ["", "class cbl =\n  fixes cbl :: \"'a cbl\"\n  assumes inj_to_bl: \"ID cbl = Some (to_bl, from_bl) \\<Longrightarrow> inj to_bl\"\n  and to_bl_inverse: \"ID cbl = Some (to_bl, from_bl) \\<Longrightarrow> from_bl (to_bl a) = a\"\nbegin"], ["", "abbreviation from_bl where \"from_bl \\<equiv> snd (the (ID cbl))\""], ["", "abbreviation to_bl where \"to_bl \\<equiv> fst (the (ID cbl))\""], ["", "end"], ["", "text \\<open>\n  It is best to immediately provide the instances for as many types as possible.\n  Here, we only present two examples: @{typ unit} provides conversion functions, @{typ \"'a \\<Rightarrow> 'b\"} does not.\n\\<close>"], ["", "instantiation unit :: cbl begin"], ["", "definition \"cbl = Some (\\<lambda>_. [], \\<lambda>_. ())\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS(unit, cbl_class)", "by(intro_classes)(auto simp add: cbl_unit_def ID_Some intro: injI)"], ["", "end"], ["", "instantiation \"fun\" :: (type, type) cbl begin"], ["", "definition \"cbl = (None :: ('a \\<Rightarrow> 'b) cbl)\""], ["", "instance"], ["proof (prove)\ngoal (1 subgoal):\n 1. OFCLASS('a \\<Rightarrow> 'b, cbl_class)", "by intro_classes(simp_all add: cbl_fun_def ID_None)"], ["", "end"], ["", "subsection \\<open>Hide the invariants of the data structure\\<close>"], ["", "text_raw \\<open>\\label{subsection:hide:invariants}\\<close>"], ["", "text \\<open>\n  Many data structures have invariants on which the operations rely.\n  You must hide such invariants in a \\isamarkuptrue\\isacommand{typedef}\\isamarkupfalse{} before connecting to the container, because the code generator cannot handle explicit invariants.\n  The type must be inhabited even if the types of the elements do not provide the required operations.\n  The easiest way is often to ignore all invariants in that case.\n\n  In our example, we require that all keys in the trie represent encoded values.\n\\<close>"], ["", "typedef (overloaded) ('k :: cbl, 'v) trie = \n  \"{t :: 'v trie_raw. \n    trie_keys t \\<subseteq> range (to_bl :: 'k \\<Rightarrow> trie_key) \\<or> ID (cbl :: 'k cbl) = None}\""], ["proof (prove)\ngoal (1 subgoal):\n 1. \\<exists>x.\n       x \\<in> {t. trie_keys t \\<subseteq> range to_bl \\<or> ID cbl = None}", "proof"], ["proof (state)\ngoal (1 subgoal):\n 1. ?x \\<in> {t. trie_keys t \\<subseteq> range to_bl \\<or> ID cbl = None}", "show \"trie_empty \\<in> ?trie\""], ["proof (prove)\ngoal (1 subgoal):\n 1. trie_empty\n    \\<in> {t. trie_keys t \\<subseteq> range to_bl \\<or> ID cbl = None}", "by(simp add: trie_keys_dom_lookup trie_lookup_empty)"], ["proof (state)\nthis:\n  trie_empty\n  \\<in> {t. trie_keys t \\<subseteq> range to_bl \\<or> ID cbl = None}\n\ngoal:\nNo subgoals!", "qed"], ["", "text \\<open>\n  Next, transfer the operations to the new type.\n  The transfer package does a good job here.\n\\<close>"], ["", "setup_lifting type_definition_trie \\<comment> \\<open>also sets up code generation\\<close>"], ["", "lift_definition empty :: \"('k :: cbl, 'v) trie\" \n  is trie_empty"], ["proof (prove)\ngoal (1 subgoal):\n 1. trie_keys trie_empty \\<subseteq> range to_bl \\<or> ID cbl = None", "by(simp add: trie_keys_empty)"], ["", "lift_definition lookup :: \"('k :: cbl, 'v) trie \\<Rightarrow> 'k \\<Rightarrow> 'v option\"\n  is \"\\<lambda>t. trie_lookup t \\<circ> to_bl\""], ["proof (prove)\ngoal:\nNo subgoals!", "."], ["", "lift_definition update :: \"'k \\<Rightarrow> 'v \\<Rightarrow> ('k :: cbl, 'v) trie \\<Rightarrow> ('k, 'v) trie\"\n  is \"trie_update \\<circ> to_bl\""], ["proof (prove)\ngoal (1 subgoal):\n 1. \\<And>k v trie_raw.\n       trie_keys trie_raw \\<subseteq> range to_bl \\<or>\n       ID cbl = None \\<Longrightarrow>\n       trie_keys ((trie_update \\<circ> to_bl) k v trie_raw)\n       \\<subseteq> range to_bl \\<or>\n       ID cbl = None", "by(auto simp add: trie_keys_dom_lookup trie_lookup_update)"], ["", "lift_definition keys :: \"('k :: cbl, 'v) trie \\<Rightarrow> 'k set\"\n  is \"\\<lambda>t. from_bl ` trie_keys t\""], ["proof (prove)\ngoal:\nNo subgoals!", "."], ["", "text \\<open>\n  And now we go for the properties.\n  Note that some properties hold only if the type class operations are actually provided, i.e., @{term \"cbl \\<noteq> None\"} in our example.\n\\<close>"], ["", "lemma lookup_empty: \"lookup empty = Map.empty\""], ["proof (prove)\ngoal (1 subgoal):\n 1. lookup Containers_Userguide.empty = Map.empty", "by transfer(simp add: trie_lookup_empty fun_eq_iff)"], ["", "context\n  fixes t :: \"('k :: cbl, 'v) trie\"\n  assumes ID_cbl: \"ID (cbl :: 'k cbl) \\<noteq> None\"\nbegin"], ["", "lemma lookup_update: \"lookup (update k v t) = (lookup t)(k \\<mapsto> v)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. lookup (update k v t) = lookup t(k \\<mapsto> v)", "using ID_cbl"], ["proof (prove)\nusing this:\n  ID cbl \\<noteq> None\n\ngoal (1 subgoal):\n 1. lookup (update k v t) = lookup t(k \\<mapsto> v)", "by transfer(auto simp add: trie_lookup_update fun_eq_iff dest: inj_to_bl[THEN injD])"], ["", "lemma keys_conv_dom_lookup: \"keys t = dom (lookup t)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. keys t = dom (lookup t)", "using ID_cbl"], ["proof (prove)\nusing this:\n  ID cbl \\<noteq> None\n\ngoal (1 subgoal):\n 1. keys t = dom (lookup t)", "by transfer(force simp add: trie_keys_dom_lookup to_bl_inverse intro: rev_image_eqI)"], ["", "end"], ["", "subsection \\<open>Connecting to the container\\<close>"], ["", "text_raw \\<open>\\label{subsection:connect:container}\\<close>"], ["", "text \\<open>\n  Connecting to the container (@{typ \"('a, 'b) mapping\"} in our example) takes three steps:\n  \\begin{enumerate}\n  \\item Define a new pseudo-constructor\n  \\item Implement the container operations for the new type\n  \\item Configure the heuristics to automatically pick an implementation\n  \\item Test thoroughly\n  \\end{enumerate}\n  Thorough testing is particularly important, because Isabelle does not check whether you have implemented all your operations, whether you have configured your heuristics sensibly, nor whether your implementation always terminates.\n\\<close>"], ["", "subsubsection \\<open>Define a new pseudo-constructor\\<close>"], ["", "text \\<open>\n  Define a function that returns the abstract container view for a data structure value, and declare it as a datatype constructor for code generation with \\isamarkuptrue\\isacommand{code{\\isacharunderscore}datatype}\\isamarkupfalse.\n  Unfortunately, you have to repeat all existing pseudo-constructors, because there is no way to extract the current set of pseudo-constructors from the code generator.\n  We call them pseudo-constructors, because they do not behave like datatype constructors in the logic.\n  For example, ours are neither injective nor disjoint.\n\\<close>"], ["", "definition Trie_Mapping :: \"('k :: cbl, 'v) trie \\<Rightarrow> ('k, 'v) mapping\" \nwhere [simp, code del]: \"Trie_Mapping t = Mapping.Mapping (lookup t)\""], ["", "code_datatype Assoc_List_Mapping RBT_Mapping Mapping Trie_Mapping"], ["", "subsubsection \\<open>Implement the operations\\<close>"], ["", "text \\<open>\n  Next, you have to prove and declare code equations that implement the container operations for the new implementation.\n  Typically, these just dispatch to the operations on the type from \\S\\ref{subsection:hide:invariants}.\n  Some operations depend on the type class operations from \\S\\ref{subsection:introduce:type:class} being defined; then, the code equation must check that the operations are indeed defined.\n  If not, there is usually no way to implement the operation, so the code should raise an exception.\n  Logically, we use the function @{term \"Code.abort\"} of type @{typ \"String.literal \\<Rightarrow> (unit \\<Rightarrow> 'a) \\<Rightarrow> 'a\"} with definition @{term \"\\<lambda>_ f. f ()\"}, but the generated code raises an exception \\texttt{Fail} with the given message (the unit closure avoids non-termination in strict languages).\n  This function gets the exception message and the unit-closure of the equation's left-hand side as argument, because it is then trivial to prove equality.\n\n  Again, we only show a small set of operations; a realistic implementation should cover as many as possible.\n\\<close>"], ["", "context fixes t :: \"('k :: cbl, 'v) trie\" begin"], ["", "lemma lookup_Trie_Mapping [code]:\n  \"Mapping.lookup (Trie_Mapping t) = lookup t\"\n  \\<comment> \\<open>Lookup does not need the check on @{term cbl},\n        because we have defined the pseudo-constructor @{term Trie_Mapping} in terms of @{term \"lookup\"}\\<close>"], ["proof (prove)\ngoal (1 subgoal):\n 1. Mapping.lookup (Trie_Mapping t) = lookup t", "by simp(transfer, simp)"], ["", "lemma update_Trie_Mapping [code]:\n  \"Mapping.update k v (Trie_Mapping t) = \n  (case ID cbl :: 'k cbl of\n     None \\<Rightarrow> Code.abort (STR ''update Trie_Mapping: cbl = None'') (\\<lambda>_. Mapping.update k v (Trie_Mapping t))\n   | Some _ \\<Rightarrow> Trie_Mapping (update k v t))\""], ["proof (prove)\ngoal (1 subgoal):\n 1. Mapping.update k v (Trie_Mapping t) =\n    (case ID cbl of\n     None \\<Rightarrow>\n       Code.abort STR ''update Trie_Mapping: cbl = None''\n        (\\<lambda>_. Mapping.update k v (Trie_Mapping t))\n     | Some x \\<Rightarrow> Trie_Mapping (update k v t))", "by(simp split: option.split add: lookup_update Mapping.update.abs_eq)"], ["", "lemma keys_Trie_Mapping [code]:\n  \"Mapping.keys (Trie_Mapping t) =\n  (case ID cbl :: 'k cbl of\n     None \\<Rightarrow> Code.abort (STR ''keys Trie_Mapping: cbl = None'') (\\<lambda>_. Mapping.keys (Trie_Mapping t))\n   | Some _ \\<Rightarrow> keys t)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. Mapping.keys (Trie_Mapping t) =\n    (case ID cbl of\n     None \\<Rightarrow>\n       Code.abort STR ''keys Trie_Mapping: cbl = None''\n        (\\<lambda>_. Mapping.keys (Trie_Mapping t))\n     | Some x \\<Rightarrow> keys t)", "by(simp add: Mapping.keys.abs_eq keys_conv_dom_lookup split: option.split)"], ["", "end"], ["", "text \\<open>\n  These equations do not replace the existing equations for the other constructors, but they do take precedence over them.\n  If there is already a generic implementation for an operation @{term \"foo\"}, say @{term \"foo A = gen_foo A\"}, and you prove a specialised equation @{term \"foo (Trie_Mapping t) = trie_foo t\"}, then when you call @{term \"foo\"} on some @{term \"Trie_Mapping t\"}, your equation will kick in.\n  LC exploits this sequentiality especially for binary operators on sets like @{term \"(\\<inter>)\"}, where there are generic implementations and faster specialised ones.\n\\<close>"], ["", "subsubsection \\<open>Configure the heuristics\\<close>"], ["", "text \\<open>\n  Finally, you should setup the heuristics that automatically picks a container implementation based on the types of the elements (\\S\\ref{subsection:set_impl}).\n\n  The heuristics uses a type with a single value, e.g., @{typ mapping_impl} with value @{term Mapping_IMPL}, but there is one pseudo-constructor for each container implementation in the generated code.\n  All these pseudo-constructors are the same in the logic, but they are different in the generated code.\n  Hence, the generated code can distinguish them, but we do not have to commit to anything in the logic.\n  This allows to reconfigure and extend the heuristic at any time.\n\n  First, define and declare a new pseudo-constructor for the heuristics.\n  Again, be sure to redeclare all previous pseudo-constructors.\n\\<close>"], ["", "definition mapping_Trie :: mapping_impl \nwhere [simp]: \"mapping_Trie = Mapping_IMPL\""], ["", "code_datatype \n  mapping_Choose mapping_Assoc_List mapping_RBT mapping_Mapping mapping_Trie"], ["", "text \\<open>\n  Then, adjust the implementation of the automatic choice.\n  For every initial value of the container (such as the empty map or the empty set), there is one new constant (e.g., @{term mapping_empty_choose} and @{term set_empty_choose}) equivalent to it.\n  Its code equation, however, checks the available operations from the type classes and picks an appropriate implementation.\n  \n  For example, the following prefers red-black trees over tries, but tries over associative lists:\n\\<close>"], ["", "lemma mapping_empty_choose_code [code]:\n  \"(mapping_empty_choose :: ('a :: {ccompare, cbl}, 'b) mapping) =\n   (case ID CCOMPARE('a) of Some _  \\<Rightarrow> RBT_Mapping RBT_Mapping2.empty\n    | None \\<Rightarrow>\n      case ID (cbl :: 'a cbl) of Some _ \\<Rightarrow> Trie_Mapping empty \n      | None \\<Rightarrow> Assoc_List_Mapping DAList.empty)\""], ["proof (prove)\ngoal (1 subgoal):\n 1. mapping_empty_choose =\n    (case ID ccompare of\n     None \\<Rightarrow>\n       case ID cbl of None \\<Rightarrow> Assoc_List_Mapping DAList.empty\n       | Some x \\<Rightarrow> Trie_Mapping Containers_Userguide.empty\n     | Some x \\<Rightarrow> RBT_Mapping RBT_Mapping2.empty)", "by(auto split: option.split simp add: DAList.lookup_empty[abs_def] Mapping.empty_def lookup_empty)"], ["", "text \\<open>\n  There is also a second function for every such initial value that dispatches on the pseudo-constructors for @{typ mapping_impl}.\n  This function is used to pick the right implementation for types that specify a preference.\n\\<close>"], ["", "lemma mapping_empty_code [code]:\n  \"mapping_empty mapping_Trie = Trie_Mapping empty\""], ["proof (prove)\ngoal (1 subgoal):\n 1. mapping_empty mapping_Trie = Trie_Mapping Containers_Userguide.empty", "by(simp add: lookup_empty Mapping.empty_def)"], ["", "text \\<open>\n  For @{typ \"('k, 'v) mapping\"}, LC also has a function @{term \"mapping_impl_choose2\"} which is given two preferences and returns one (for @{typ \"'a set\"}, it is called @{term \"set_impl_choose2\"}).\n  Polymorphic type constructors like @{typ \"'a + 'b\"} use it to pick an implementation based on the preferences of @{typ \"'a\"} and @{typ \"'b\"}.\n  By default, it returns @{term mapping_Choose}, i.e., ignore the preferences.\n  You should add a code equation like the following that overrides this choice if both preferences are your new data structure:\n\\<close>"], ["", "lemma mapping_impl_choose2_Trie [code]:\n  \"mapping_impl_choose2 mapping_Trie mapping_Trie = mapping_Trie\""], ["proof (prove)\ngoal (1 subgoal):\n 1. mapping_impl_choose2 mapping_Trie mapping_Trie = mapping_Trie", "by(simp add: mapping_Trie_def)"], ["", "text \\<open>\n  If your new data structure is better than the existing ones for some element type, you should reconfigure the type's preferene.\n  As all preferences are logically equal, you can prove (and declare) the appropriate code equation.\n  For example, the following prefers tries for keys of type @{typ \"unit\"}:\n\\<close>"], ["", "lemma mapping_impl_unit_Trie [code]:\n  \"MAPPING_IMPL(unit) = Phantom(unit) mapping_Trie\""], ["proof (prove)\ngoal (1 subgoal):\n 1. mapping_impl = Phantom(unit) mapping_Trie", "by(simp add: mapping_impl_unit_def)"], ["", "value \"Mapping.empty :: (unit, int) mapping\""], ["", "text \\<open>\n  You can also use your new pseudo-constructor with \\<open>derive\\<close> in instantiations, just give its name as option:\n\\<close>"], ["", "derive (mapping_Trie) mapping_impl simple_tycon"], ["", "section \\<open>Changing the configuration\\<close>"], ["", "text \\<open>\n  As containers are connected to data structures only by refinement in the code generator, this can always be adapted later on.\n  You can add new data structures as explained in \\S\\ref{section:new:implementation}.\n  If you want to drop one, you redeclare the remaining pseudo-constructors with \\isamarkuptrue\\isacommand{code{\\isacharunderscore}datatype}\\isamarkupfalse{} and delete all code equations that pattern-match on the obsolete pseudo-constructors.\n  The command \\isamarkuptrue\\isacommand{code{\\isacharunderscore}thms}\\isamarkupfalse{} will tell you which constants have such code equations.\n  You can also freely adapt the heuristics for picking implementations as described in \\S\\ref{subsection:connect:container}.\n\n  One thing, however, you cannot change afterwards, namely the decision whether an element type supports an operation and if so how it does, because this decision is visible in the logic.\n\\<close>"], ["", "section \\<open>New containers types\\<close>"], ["", "text \\<open>\n  We hope that the above explanations and the examples with sets and maps suffice to show what you need to do if you add a new container type, e.g., priority queues.\n  There are three steps:\n  \\begin{enumerate}\n  \\item \\textbf{Introduce a type constructor for the container.}\n    \\\\\n    Your new container type must not be a composite type, like @{typ \"'a \\<Rightarrow> 'b option\"} for maps, because refinement for code generation only works with a single type constructor.\n    Neither should you reuse a type constructor that is used already in other contexts, e.g., do not use @{typ \"'a list\"} to model queues.\n\n    Introduce a new type constructor if necessary (e.g., @{typ \"('a, 'b) mapping\"} for maps) -- if your container type already has its own type constructor, everything is fine.\n\n  \\item \\textbf{Implement the data structures} \n    \\\\\n    and connect them to the container type as described in \\S\\ref{section:new:implementation}.\n\n  \\item \\textbf{Define a heuristics for picking an implementation.}\n    \\\\\n    See \\cite{Lochbihler2013ITP} for an explanation.\n  \\end{enumerate}\n\\<close>"], ["", "section \\<open>Troubleshooting\\<close>"], ["", "text \\<open>\n  This section describes some difficulties in using LC that we have come across, provides some background for them, and discusses how to overcome them.\n  If you experience other difficulties, please contact the author.\n\\<close>"], ["", "subsection \\<open>Nesting of mappings\\<close>"], ["", "text \\<open>\n  Mappings can be arbitrarily nested on the value side, e.g., @{typ \"('a, ('b, 'c) mapping) mapping\"}.\n  However, @{typ \"('a, 'b) mapping\"} cannot currently be the key of a mapping, i.e., code generation fails for @{typ \"(('a, 'b) mapping, 'c) mapping\"}.\n  Simiarly, you cannot have a set of mappings like @{typ \"('a, 'b) mapping set\"} at the moment.\n  There are no issues to make this work, we have just not seen the need for it.\n  If you need to generate code for such types, please get in touch with the author.\n\\<close>"], ["", "subsection \\<open>Wellsortedness errors\\<close>"], ["", "text_raw \\<open>\\label{subsection:well:sortedness}\\<close>"], ["", "text \\<open>\n  LC uses its own hierarchy of type classes which is distinct from Isabelle/HOL's.\n  This ensures that every type can be made an instance of LC's type classes.\n  Consequently, you must instantiate these classes for your own types.\n  The following lists where you can find information about the classes and examples how to instantiate them:\n  \\begin{center}\n    \\begin{tabular}{lll}\n      \\textbf{type class} & \\textbf{user guide} & \\textbf{theory}\n      \\\\\n      @{class card_UNIV} & \\S\\ref{subsection:card_UNIV} & @{theory \"HOL-Library.Cardinality\"} \n      %@{term \"Cardinality.card_UNIV_class\"}\n      \\\\\n      @{class cenum} & \\S\\ref{subsection:cenum} & @{theory Containers.Collection_Enum}\n      %@{term \"Collection_Enum.cenum_class\"}\n      \\\\\n      @{class ceq} & \\S\\ref{subsection:ceq} & @{theory Containers.Collection_Eq}\n      %@{term \"Collection_Eq.ceq_class\"}\n      \\\\\n      @{class ccompare} & \\S\\ref{subsection:ccompare} & @{theory Containers.Collection_Order}\n      %@{term \"Collection_Order.ccompare_class\"}\n      \\\\\n      @{class cproper_interval} & \\S\\ref{subsection:cproper_interval} & @{theory Containers.Collection_Order}\n      %@{term \"Collection_Order.cproper_interval_class\"}\n      \\\\\n      @{class finite_UNIV} & \\S\\ref{subsection:finite_UNIV} & @{theory \"HOL-Library.Cardinality\"}\n      %@{term \"Cardinality.finite_UNIV_class\"}\n      \\\\\n      @{class mapping_impl} & \\S\\ref{subsection:mapping_impl} & @{theory Containers.Mapping_Impl}\n      %@{term \"Mapping_Impl.mapping_impl_class\"}\n      \\\\\n      @{class set_impl} & \\S\\ref{subsection:set_impl} & @{theory Containers.Set_Impl}\n      %@{term \"Set_Impl.set_impl_class\"}\n      \\\\\n    \\end{tabular}\n  \\end{center}\n\n  The type classes @{class card_UNIV} and @{class cproper_interval} are only required to implement the operations on set complements.\n  If your code does not need complements, you can manually delete the code equations involving @{const \"Complement\"}, the theorem list @{thm [source] set_complement_code} collects them.\n  It is also recommended that you remove the pseudo-constructor @{const Complement} from the code generator.\n  Note that some set operations like @{term \"A - B\"} and @{const UNIV} have no code equations any more.\n\\<close>"], ["", "declare set_complement_code[code del]"], ["", "code_datatype Collect_set DList_set RBT_set Set_Monad"], ["", "(*<*)"], ["", "datatype minimal_sorts = Minimal_Sorts bool"], ["", "derive (eq) ceq minimal_sorts"], ["", "derive (no) ccompare minimal_sorts"], ["", "derive (monad) set_impl minimal_sorts"], ["", "derive (no) cenum minimal_sorts"], ["", "value \"{Minimal_Sorts True} \\<union> {} \\<inter> Minimal_Sorts ` {True, False}\""], ["", "(*>*)"], ["", "subsection \\<open>Exception raised at run-time\\<close>"], ["", "text_raw \\<open>\\label{subsection:set_impl_unsupported_operation}\\<close>"], ["", "text \\<open>\n  Not all combinations of data and container implementation are possible.\n  For example, you cannot implement a set of functions with a RBT, because there is no order on @{typ \"'a \\<Rightarrow> 'b\"}.\n  If you try, the code will raise an exception \\texttt{Fail} (with an exception message) or \\texttt{Match}.\n  They can occur in three cases:\n\n  \\begin{enumerate}\n  \\item\n    You have misconfigured the heuristics that picks implementations (\\S\\ref{subsection:set_impl}), or you have manually picked an implementation that requires an operation that the element type does not provide.\n    Printing a stack trace for the exception may help you in locating the error.\n\n  \\item You are trying to invoke an operation on a set complement which cannot be implemented on a complement representation, e.g., @{term \"(`)\"}.\n    If the element type is enumerable, provide an instance of @{class cenum} and choose to represent complements of sets of enumerable types by the elements rather than the elements of the complement (see \\S\\ref{subsection:cenum} for how to do this).\n\n  \\item You use set comprehensions on types which do not provide an enumeration (i.e., they are represented as closures) or you chose to represent a map as a closure.\n\n    A lot of operations are not implementable for closures, in particular those that return some element of the container\n\n    Inspect the code equations with \\isacommand{code{\\isacharunderscore}thms} and look for calls to @{term \"Collect_set\"} and @{term \"Mapping\"} which are LC's constructor for sets and maps as closures.\n\n    Note that the code generator preprocesses set comprehensions like @{term \"{i < 4|i :: int. i > 2}\"} to @{term \"(\\<lambda>i :: int. i < 4) ` {i. i > 2}\"}, so this is a set comprehension over @{typ int} rather than @{typ bool}.\n  \\end{enumerate}\n\\<close>"], ["", "(*<*)"], ["", "definition test_set_impl_unsupported_operation1 :: \"unit \\<Rightarrow> (int \\<Rightarrow> int) set\"\nwhere \"test_set_impl_unsupported_operation1 _ = RBT_set RBT_Set2.empty \\<union> {}\""], ["", "definition test_set_impl_unsupported_operation2 :: \"unit \\<Rightarrow> bool set\"\nwhere \"test_set_impl_unsupported_operation2 _ = {i < 4 | i :: int. i > 2}\""], ["", "definition test_mapping_impl_unsupported_operation :: \"unit \\<Rightarrow> bool\"\nwhere \n  \"test_mapping_impl_unsupported_operation _ = \n   Mapping.is_empty (RBT_Mapping (RBT_Mapping2.empty) :: (Enum.finite_4, unit) mapping)\""], ["", "ML_val \\<open>\nfun test_fail s f =\n  let\n    fun error s' = Fail (\"exception Fail \\\"\" ^ s ^ \"\\\" expected, but got \" ^ s')\n  in\n    (f (); raise (error \"no exception\") )\n    handle\n      Fail s' => if s = s' then () else raise (error s')\n  end;\n\ntest_fail \"union RBT_set Set_Monad: ccompare = None\" @{code test_set_impl_unsupported_operation1};\ntest_fail \"image Collect_set\" @{code test_set_impl_unsupported_operation2};\ntest_fail \"is_empty RBT_Mapping: ccompare = None\" @{code test_mapping_impl_unsupported_operation};\n\\<close>"], ["", "(*>*)"], ["", "subsection \\<open>LC slows down my code\\<close>"], ["", "text \\<open>\n  Normally, this will not happen, because LC's data structures are more efficient than Isabelle's list-based implementations.\n  However, in some rare cases, you can experience a slowdown:\n\\<close>"], ["", "(*<*)"], ["", "definition tiny_set :: \"nat set\"\nwhere tiny_set_code: \"tiny_set = {1, 2}\""], ["", "(*>*)"], ["", "text_raw \\<open>\n  \\isastyletext\n  \\begin{enumerate}\n  \\item \\textbf{Your containers contain just a few elements.}\n    \\\\\n    In that case, the overhead of the heuristics to pick an implementation outweighs the benefits of efficient implementations.\n    You should identify the tiny containers and disable the heuristics locally.\n    You do so by replacing the initial value like @{term \"{}\"} and @{term \"Mapping.empty\"} with low-overhead constructors like @{term \"Set_Monad\"} and @{term \"Mapping\"}.\n    For example, if @{thm [source] tiny_set_code}: @{thm tiny_set_code} is your code equation with a tiny set,\n    the following changes the code equation to directly use the list-based representation, i.e., disables the heuristics:\n    \\par\n\\<close>"], ["", "lemma empty_Set_Monad: \"{} = Set_Monad []\""], ["proof (prove)\ngoal (1 subgoal):\n 1. {} = Set_Monad []", "by simp"], ["", "declare tiny_set_code[code del, unfolded empty_Set_Monad, code]"], ["", "text_raw \\<open>\n    \\isastyletext\n    \\par\n     If you want to globally disable the heuristics, you can also declare an equation like @{thm [source] empty_Set_Monad} as [code].\n\n  \\item \\textbf{The element type contains many type constructors and some type variables.}\n    \\\\\n    LC heavily relies on type classes, and type classes are implemented as dictionaries if the compiler cannot statically resolve them, i.e., if there are type variables.\n    For type constructors with type variables (like @{typ \"'a * 'b\"}), LC's definitions of the type class parameters recursively calls itself on the type variables, i.e., @{typ \"'a\"} and @{typ \"'b\"}.\n    If the element type is polymorphic, the compiler cannot precompute these recursive calls and therefore they have to be constructed repeatedly at run time.\n    If you wrap your complicated type in a new type constructor, you can define optimised equations for the type class parameters.\n  \\end{enumerate}\n\\<close>"], ["", "(*<*)"], ["", "end"], ["", "(*>*)"]]}